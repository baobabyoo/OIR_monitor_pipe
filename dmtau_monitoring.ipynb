{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Plots from Original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Conda environment\n",
    "# conda create --name terada2019 python=3.7\n",
    "# pip install --upgrade pip\n",
    "# pip install astropy scipy\n",
    "# pip install photutils\n",
    "# pip install jupyter matplotlib h5py aplpy pyregion PyAVM healpy\n",
    "# pip install astroquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path\n",
    "sys.path.append('./')\n",
    "\n",
    "import numpy as np\n",
    "from astropy.stats import mad_std\n",
    "\n",
    "from photutils import datasets\n",
    "from photutils import DAOStarFinder\n",
    "from photutils import aperture_photometry, CircularAperture\n",
    "\n",
    "import aplpy\n",
    "from astropy.io.fits import getdata\n",
    "from astropy import wcs\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy import constants as con\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.stats import biweight_location, biweight_scale\n",
    "from scipy.optimize import curve_fit\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.vizier import Vizier\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('PDF')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some used mathematical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x, a, x0, sigma):\n",
    "    return a * np.exp(-(x - x0)**2 / (2 * sigma**2))\n",
    "\n",
    "\n",
    "\n",
    "def gaussfit(x, y):\n",
    "    '''\n",
    "    Function to perform 1D fitting of Gaussian profile.\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "    X      [numpy array]  : X coordiates\n",
    "    Y      [numpy array]  : Y values\n",
    "    \n",
    "    Return:\n",
    "    popt   [float list]   : [amplitude, centroid-X, and sigma]\n",
    "    '''\n",
    "    mean  = sum(x * y) / sum(y)\n",
    "    sigma = np.sqrt(sum( abs(y) * ( (x - mean)**2 ) ) / sum(y) )\n",
    "    \n",
    "    # initial guess\n",
    "    p0    = [max(y), mean, sigma]\n",
    "    try:\n",
    "        popt, pcov = curve_fit(gauss, x, y, p0=p0)\n",
    "    except:\n",
    "        print('Warning. Failed fitting Gaussian profile.')\n",
    "        popt = [0.0,0.0,0.0]\n",
    "    \n",
    "    return popt\n",
    "\n",
    "\n",
    "\n",
    "def angoff_degree(coord1, coord2):\n",
    "    '''\n",
    "    A function to evaluate angular offset (in degree units).\n",
    "    This function assumes that the declinations of the two sources\n",
    "    are not very different.\n",
    "    \n",
    "    Inputs:\n",
    "    coord1,2   [lists of float]  : [ra, dec] in degree unit.\n",
    "    \n",
    "    Return:\n",
    "    Angular offset in degree unit [float].\n",
    "    '''\n",
    "    \n",
    "    dec_off  =  coord1[1] - coord2[1]\n",
    "    mean_dec = (coord1[1] + coord2[1]) / 2.0\n",
    "    ra_off   = ( coord1[0] - coord2[0] ) * \\\n",
    "                 np.cos( mean_dec * (np.pi/180.0) )\n",
    "    \n",
    "    off      = np.sqrt( ra_off**2.0 + dec_off**2.0 )\n",
    "    return off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format of marker file:\n",
    "\n",
    "name, ra_h ra_m ra_s dec_d dec_m dec_s  R:0-1 G:0-1 B:0-1 alpha  size\n",
    "\n",
    "dm_tau  04 33 48.7335659850  +18 10 09.974471722  1 0.2 0.2 1.0 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format of reference star file\n",
    "\n",
    "name, ra dec R:0-1 G:0-1 B:0-1 alpha size band jd count file_name\n",
    "\n",
    "1_8 68.61225456763495 18.265153228501678 1 0 1 1 30 I 2458491.56799249 82873.91795331985 dm tau_3463766_I_015.fits\n",
    "\n",
    "1_10 68.58791728147689 18.313321866312478 1 0 1 1 30 I 2458491.56799249 157532.68915795215 dm tau_3463766_I_015.fits\n",
    "\n",
    "1_12 68.55803592095405 18.35926561721569 1 0 1 1 30 I 2458491.56799249 77123.45560573619 dm tau_3463766_I_015.fits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a aperture photometry pipeline class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended strategy of running this pipeline:\n",
    "\n",
    "1. First produce preview images for all images, and then produce a skip_file_lis after visual inspect.\n",
    "\n",
    "2. Run the rest of the procedures, incorporating skip_file_lis to save time and avoid crashing DAOstarfinder and photoutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class marker:\n",
    "    '''\n",
    "    Class for marker objects.\n",
    "    \n",
    "    It can also be used as objects to store information about aperture photometry,\n",
    "    using the attributes :\n",
    "    \n",
    "\n",
    "    band_list [list of string] : Recording the information of used bands.\n",
    "    \n",
    "    jd_dict   [dictory of (list of double), key: band] : to store jd dates for\n",
    "                                                         measurements at certain bands.\n",
    "    \n",
    "    flux_dict [dictory of (list of double), key: band] : to store fluxes (or counts) for\n",
    "                                                         measurements at certain bands\n",
    "                                                         \n",
    "    mag_dict [dictory of (list of double), key: band] : to store magnitudes for\n",
    "                                                         measurements at certain bands\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, label='unknown_marker'):\n",
    "        self.label = label\n",
    "        self.ra    = 0.0\n",
    "        self.dec   = 0.0\n",
    "        self.color = (0,0,0)\n",
    "        self.alpha = 1.0\n",
    "        self.size  = 1.0\n",
    "        \n",
    "        self.band_list = []\n",
    "        self.jd_dict   = {}\n",
    "        self.flux_dict = {}\n",
    "        self.mag_dict = {}\n",
    "    \n",
    "    def __del__(self):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "\n",
    "class apt_pipe:\n",
    "    '''\n",
    "    Class for apeture photometry pipeline.\n",
    "    \n",
    "    History:\n",
    "    1. Basic version developed.  (Baobab Liu, 2019, Dec.07)\n",
    "    \n",
    "    2 Required Conda enviornment:\n",
    "    # conda create --name terada2019 python=3.7\n",
    "    # pip install --upgrade pip\n",
    "    # pip install astropy scipy\n",
    "    # pip install photutils\n",
    "    # pip install jupyter matplotlib h5py aplpy pyregion PyAVM healpy\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    def __init__(self, data_path = './',\n",
    "                 markerfile   = './markers.txt',\n",
    "                 ascii_report = './ascii_report.txt',\n",
    "                 verbose      = False\n",
    "                ):\n",
    "        '''\n",
    "        Initializer of the class.\n",
    "        It first load image names from the FITS image directory.\n",
    "        Then it checks the integrity of the FITS image headers,\n",
    "        and dump report to an ASCII file.\n",
    "        Finally, it loads the coordinate of the markerfile if any.\n",
    "        \n",
    "        \n",
    "        \n",
    "        Keywords:\n",
    "        \n",
    "        data_path [string] or list of [string] : Default: './'.\n",
    "                  Can either load data from one specified directory or a list of \n",
    "                  specified directory.\n",
    "        \n",
    "        markerfile [string]   : File name of one or a list of markers.\n",
    "                  Format :\n",
    "                  name, ra_h ra_m ra_s dec_d dec_m dec_s R:0-1 G:0-1 B:0-1 alpha size\n",
    "                  Example :\n",
    "                      dm_tau  04 33 48.7335659850 +18 10 09.974471722   1 0.2 0.2 1.0 2.0\n",
    "                      test    04 33 48.7335659850  +18 10 49.974471722  0.0 1.0 0 1.0 30.0\n",
    "        \n",
    "        ascii_report [string] :\n",
    "        \n",
    "        verbose   [True]      : Verbosely dump the status of the data.\n",
    "        \n",
    "        \n",
    "        \n",
    "        Methods:\n",
    "        \n",
    "        plot_preview          : Plotting preview figures for FITS images under the data_path(s)\n",
    "        \n",
    "        do_apt                : Do aperture photometry for loaded marker(s).\n",
    "        \n",
    "        \n",
    "        '''\n",
    "                                        \n",
    "        self.data_path  = data_path\n",
    "        self.markerfile = markerfile\n",
    "        self.verbose    = verbose\n",
    "        self.num_images = 0\n",
    "        self.num_markers = 0\n",
    "        self.ascii_report = ascii_report\n",
    "        \n",
    "        # initialize variables\n",
    "        os.system('rm -rf ' + ascii_report)\n",
    "        F_report = open(ascii_report,\"w+\")\n",
    "        self.data_path_list  = []\n",
    "        self.num_data_path   = 0\n",
    "        self.filterlist      = []\n",
    "        self.images          = []\n",
    "        self.path_dict       = {}\n",
    "        self.band_dict       = {}\n",
    "        self.date_dict       = {}\n",
    "        self.jd_dict         = {}\n",
    "        self.countrange_dict = {} # storing [max(count), min(count)] for individual image_name\n",
    "        self.fwhm_dict       = {}\n",
    "        self.marker_list     = []\n",
    "        \n",
    "        # load image names\n",
    "        if ( type(data_path) == str ):\n",
    "            self.data_path_list.append(data_path)\n",
    "            self.num_data_path = 1\n",
    "            if (verbose==True):\n",
    "                print('Loading FITS image from single directory : ' + data_path)\n",
    "                \n",
    "        if ( type(data_path) == list ):\n",
    "            self.data_path_list.extend(data_path)\n",
    "            self.num_data_path = len( self.data_path_list )\n",
    "            if (verbose==True):\n",
    "                for data_idx in range(0, len(data_path) ):\n",
    "                    print('Loading FITS image from : ' + data_path[data_idx])\n",
    "                            \n",
    "        try:\n",
    "            for data_idx in range(0, self.num_data_path):\n",
    "                self.images.extend(  os.listdir( self.data_path_list[data_idx] )  )\n",
    "                temp_names = os.listdir( self.data_path_list[data_idx] )\n",
    "                # self.num_images = self.num_images + len( temp_names )\n",
    "                for name in temp_names:\n",
    "                    self.path_dict[name] = self.data_path_list[data_idx]\n",
    "            self.num_images = len( self.images )\n",
    "                \n",
    "            if ( verbose == True ):\n",
    "                print('##############################################################')\n",
    "                print('Processing ' + str(self.num_images).strip() + ' images \\n')\n",
    "                print('##############################################################')\n",
    "        except:\n",
    "            print('No image found')\n",
    "            \n",
    "            \n",
    "        # checking integrity of FITS headers\n",
    "        F_report.write('FITS header integrity: \\n')\n",
    "        for i in range(0, self.num_images):\n",
    "            \n",
    "            image_name = self.images[i]\n",
    "            hdulist = fits.open( self.path_dict[image_name] + '/' + image_name)\n",
    "            try:\n",
    "                crval1 = hdulist[0].header['crval1']\n",
    "                crval2 = hdulist[0].header['crval2']\n",
    "            except:\n",
    "                if (verbose == True ):\n",
    "                    print('Warning, coordinate header of ' + image_name + ' does not exist.')\n",
    "                F_report.write( image_name + ' has no coordinate header \\n' )\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                date   = hdulist[0].header['date-obs']\n",
    "                jd     = hdulist[0].header['jd']\n",
    "                self.date_dict[image_name] = date\n",
    "                self.jd_dict[image_name]  = jd\n",
    "            except:\n",
    "                if (verbose == True ):\n",
    "                    print('Warning. Observing date of ' + image_name + ' is not known.')\n",
    "                F_report.write( image_name + ' has no observing time information \\n' )\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                band   = hdulist[0].header['filter']\n",
    "                if (band not in self.filterlist):\n",
    "                    self.filterlist.append(band)\n",
    "                self.band_dict[image_name] = band\n",
    "            except:\n",
    "                if (verbose == True ):\n",
    "                    print('Warning. Filter name of ' + image_name + ' does not exist.')\n",
    "                F_report.write( image_name + ' has unknown filter band. \\n' )\n",
    "                continue\n",
    "                \n",
    "        F_report.write('\\n')\n",
    "        \n",
    "        # load markers if there is\n",
    "        try:\n",
    "            marker_label     = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=0, dtype=np.str)\n",
    "            rah              = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=1 )\n",
    "            ram              = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=2 )\n",
    "            ras              = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=3 )\n",
    "            decd             = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=4 )\n",
    "            decm             = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=5 )\n",
    "            decs             = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=6 )\n",
    "            markerR          = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=7 )\n",
    "            markerG          = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=8 )\n",
    "            markerB          = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=9 )\n",
    "            marker_alpha     = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=10)\n",
    "            marker_size      = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=11)\n",
    "                        \n",
    "            ra  = ( rah + ram / 60.0 + ras / 3600.0 ) * 15.0\n",
    "            dec_sign = np.where( (decd>0), 1.0, -1.0)\n",
    "            dec      = decd + dec_sign * decm / 60.0 + dec_sign * decs / 3600.0\n",
    "                \n",
    "            self.num_markers = np.size(ra)\n",
    "            if (verbose == True):\n",
    "                print('Number of markers : ' + str(self.num_markers).strip() )\n",
    "                \n",
    "            # loading to marker objects\n",
    "            for mid in range(0, self.num_markers):\n",
    "                if (self.num_markers > 1):\n",
    "                    temp_marker       = marker(label=marker_label[mid])\n",
    "                    temp_marker.ra    = ra[mid] \n",
    "                    temp_marker.dec   = dec[mid]\n",
    "                    temp_marker.color = (markerR[mid], markerG[mid], markerB[mid])\n",
    "                    temp_marker.alpha = (marker_alpha[mid])\n",
    "                    temp_marker.size  = (marker_size[mid])\n",
    "                    self.marker_list.append(temp_marker)\n",
    "                else:\n",
    "                    temp_marker       = marker(label=marker_label)\n",
    "                    temp_marker.ra    = ra\n",
    "                    temp_marker.dec   = dec\n",
    "                    temp_marker.color = (markerR, markerG, markerB)\n",
    "                    temp_marker.alpha = (marker_alpha)\n",
    "                    temp_marker.size  = (marker_size)\n",
    "                    self.marker_list.append(temp_marker)\n",
    "            \n",
    "        except:\n",
    "            if (verbose == True):\n",
    "                print('No markers loaded')\n",
    "\n",
    "        # Dumping more information ot the report\n",
    "        # filters\n",
    "        F_report.write('Used filters: \\n')\n",
    "        outstring = ' '\n",
    "        for tempstr in self.filterlist:\n",
    "            outstring = outstring + tempstr + ' '\n",
    "        F_report.write(outstring + '\\n')\n",
    "        \n",
    "        F_report.close()\n",
    "\n",
    "        \n",
    "        \n",
    "    def __del__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    #####################################################################################\n",
    "    FUNCTION\n",
    "    #####################################################################################\n",
    "    '''    \n",
    "    \n",
    "    def background_sub(self, image, option='median'):\n",
    "        '''\n",
    "        Function to subtract background from a image.\n",
    "        \n",
    "        \n",
    "        Keyword :\n",
    "        \n",
    "           option [str]  :\n",
    "              median : subtracting the median value from an image (Default)\n",
    "        \n",
    "        \n",
    "        Return  :\n",
    "           Background subtracted image\n",
    "           \n",
    "        '''\n",
    "        \n",
    "        if ( option == 'median' ):\n",
    "            image = image - np.median(image) \n",
    "        \n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_fwhm(self, image, wcs, ra, dec, \n",
    "                 background_sub_option,\n",
    "                 naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y\n",
    "                ):\n",
    "        '''\n",
    "        From a given image with wcs object (astropy), perform Gaussian fittings to obtain\n",
    "        the fwhm of the point spread function.\n",
    "        The present version fits fwhm in horizontal and vertical directions,\n",
    "        and then return the larger one.\n",
    "        \n",
    "        Inputs :\n",
    "        \n",
    "        image    [numpy array]     : An input 2D image.\n",
    "        \n",
    "        wcs      [astropy wcs]     : An astropy wcs object constructed from the FITS image header.\n",
    "        \n",
    "        ra       [float]           : R.A. in degree unit.\n",
    "        \n",
    "        dec      [float]           : Decl. in degree unit.\n",
    "        \n",
    "        fwhm     [float]           : full width at half maximum of the point spread function.\n",
    "        \n",
    "        background_sub_option [str]: Keyword to specify how background subtraction is made.\n",
    "                                     See description in function: background_sub.\n",
    "        \n",
    "        naxis1,2   [int]           : Dimension of the input image.\n",
    "        \n",
    "        cropbox_halfsize_x,y [int] : Size of the cropped image to measure aperture photometry from,\n",
    "                                     in pixel unit.\n",
    "        \n",
    "        \n",
    "        Return :\n",
    "        \n",
    "        fwhm    [float]           : aperture photometry measurement in image flux/pixel unit.\n",
    "        '''\n",
    "        \n",
    "        fwhm1 = 0.0\n",
    "        fwhm2 = 0.0\n",
    "        \n",
    "        # load pixel coordinates\n",
    "        pixcrd2 = wcs.wcs_world2pix([ [ra,dec] ], 0)\n",
    "        xpix = pixcrd2[0][0]\n",
    "        ypix = pixcrd2[0][1]\n",
    "        xpix_min = int(round(xpix - cropbox_halfsize_x) )\n",
    "        xpix_max = int(round(xpix + cropbox_halfsize_x) )\n",
    "        ypix_min = int(round(ypix - cropbox_halfsize_y) )\n",
    "        ypix_max = int(round(ypix + cropbox_halfsize_y) )\n",
    "\n",
    "        if (xpix_min < 0): xpix_min = 0\n",
    "        if (ypix_min < 0): ypix_min = 0\n",
    "        if (xpix_max > (naxis1-1) ): xpix_max = (naxis1-1)\n",
    "        if (ypix_max > (naxis2-1) ): ypix_max = (naxis2-1)\n",
    "\n",
    "        # crop the image to speed up the source finding\n",
    "        crop = image[ypix_min:(ypix_max+1), xpix_min:(xpix_max+1)].astype(float)\n",
    "\n",
    "        # do background subtraction from the crop\n",
    "        crop = self.background_sub(crop, option=background_sub_option)\n",
    "        \n",
    "        naxis1 = xpix_max - xpix_min + 1\n",
    "        naxis2 = ypix_max - ypix_min + 1\n",
    "        \n",
    "        # do fitting in axis1\n",
    "        x_array = np.arange(0, naxis1, 1)\n",
    "        if ( (naxis2 % 2) == 1 ):\n",
    "            y_array = crop[ int( (naxis2-1)/2), :]\n",
    "        else:\n",
    "            y_array = ( crop[ int( (naxis2)/2 ), :] + crop[ int( (naxis2-2)/2 ), :] ) / 2.0\n",
    "        index = ~(np.isnan(x_array) | np.isnan(y_array))\n",
    "        parms = gaussfit(x_array[index], y_array[index])\n",
    "        fwhm1 = parms[2] * 2.35\n",
    "        \n",
    "        # do fitting in axis2\n",
    "        x_array = np.arange(0, naxis2, 1)\n",
    "        if ( (naxis1 % 2) == 1 ):\n",
    "            y_array = crop[:, int( (naxis1-1)/2) ]\n",
    "        else:\n",
    "            y_array = ( crop[:, int( (naxis1)/2 ) ] + crop[:, int( (naxis1-2)/2 ) ] ) / 2.0\n",
    "        index = ~(np.isnan(x_array) | np.isnan(y_array))\n",
    "        parms = gaussfit(x_array[index], y_array[index])      \n",
    "        fwhm2 = parms[2] * 2.35\n",
    "        \n",
    "        fwhmlist = []\n",
    "        for value in [fwhm1, fwhm2]:\n",
    "            if (np.isfinite(value) == True):\n",
    "                if (value > 0):\n",
    "                    fwhmlist.append(value)\n",
    "                    \n",
    "        if ( len(fwhmlist) > 0 ):\n",
    "            fwhm = np.max(fwhmlist)\n",
    "        else:\n",
    "            fwhm = 0.0\n",
    "        \n",
    "        return fwhm\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_count(self, image, wcs, ra, dec, fwhm, \n",
    "                  background_sub_option, apt_sigmathreshold,\n",
    "                  naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y):\n",
    "        '''\n",
    "        From a given image with wcs object (astropy), \n",
    "        using aperture photometry to measure counts of a specific star around the location \n",
    "        ra and dec, assuming a certain fwhm for the PSF\n",
    "        \n",
    "        Inputs :\n",
    "        \n",
    "        image    [numpy array]     : An input 2D image.\n",
    "        \n",
    "        wcs      [astropy wcs]     : An astropy wcs object constructed from the FITS image header.\n",
    "        \n",
    "        ra       [float]           : R.A. in degree unit.\n",
    "        \n",
    "        dec      [float]           : Decl. in degree unit.\n",
    "        \n",
    "        fwhm     [float]           : full width at half maximum of the point spread function.\n",
    "        \n",
    "        background_sub_option [str]: Keyword to specify how background subtraction is made.\n",
    "                                     See description in function: background_sub.\n",
    "                                     \n",
    "        apt_sigmathreshold [float] : Identify stars which are brighter than the specified\n",
    "                                        sigma threshold.\n",
    "        \n",
    "        naxis1,2   [int]           : Dimension of the input image.\n",
    "        \n",
    "        cropbox_halfsize_x,y [int] : Size of the cropped image to measure aperture photometry from,\n",
    "                                     in pixel unit.\n",
    "        \n",
    "        \n",
    "        Return :\n",
    "        \n",
    "        count    [float]           : aperture photometry measurement in image flux/pixel unit.\n",
    "        \n",
    "        '''\n",
    "\n",
    "        # Initializing the mearurement\n",
    "        count = 0\n",
    "        \n",
    "        # load pixel coordinates\n",
    "        pixcrd2 = wcs.wcs_world2pix([ [ra,dec] ], 0)\n",
    "        xpix = pixcrd2[0][0]\n",
    "        ypix = pixcrd2[0][1]\n",
    "        xpix_min = int(round(xpix - cropbox_halfsize_x) )\n",
    "        xpix_max = int(round(xpix + cropbox_halfsize_x) )\n",
    "        ypix_min = int(round(ypix - cropbox_halfsize_y) )\n",
    "        ypix_max = int(round(ypix + cropbox_halfsize_y) )\n",
    "\n",
    "        if (xpix_min < 0): xpix_min = 0\n",
    "        if (ypix_min < 0): ypix_min = 0\n",
    "        if (xpix_max > (naxis1-1) ): xpix_max = (naxis1-1)\n",
    "        if (ypix_max > (naxis2-1) ): ypix_max = (naxis2-1)\n",
    "\n",
    "        # crop the image to speed up the source finding\n",
    "        crop = image[ypix_min:(ypix_max+1), xpix_min:(xpix_max+1)].astype(float)\n",
    "\n",
    "        # do background subtraction from the crop\n",
    "        crop = self.background_sub(crop, option=background_sub_option)\n",
    "\n",
    "        # estimate robust standard deviation from the cropped image\n",
    "        bkg_sigma = mad_std(crop)\n",
    "\n",
    "        # find stars\n",
    "        daofind = DAOStarFinder(fwhm=fwhm, threshold=apt_sigmathreshold*bkg_sigma)\n",
    "        sources = daofind(crop)\n",
    "        try:\n",
    "            mxcentroid_array = np.array( sources['xcentroid'] )\n",
    "            mycentroid_array = np.array( sources['ycentroid'] )\n",
    "            mpeak_array      = np.array( sources['peak']      )\n",
    "            num_sources      = len(mpeak_array)\n",
    "        except:\n",
    "            num_sources      = 0\n",
    "\n",
    "        # Outputting measurements\n",
    "        if ( num_sources > 0 ):\n",
    "            sortidx    = np.argsort(mpeak_array)\n",
    "            maxidx     = sortidx[-1]\n",
    "            mxcentroid = mxcentroid_array[maxidx]\n",
    "            mycentroid = mycentroid_array[maxidx]\n",
    "            positions = np.transpose((mxcentroid, mycentroid))\n",
    "            apertures = CircularAperture(positions, fwhm*2.0)\n",
    "            phot_table = aperture_photometry(crop, apertures)\n",
    "            count     = phot_table['aperture_sum'][0]\n",
    "               \n",
    "        return count\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    #####################################################################################\n",
    "    METHOD\n",
    "    #####################################################################################\n",
    "    '''    \n",
    "            \n",
    "    def find_ref(self, refimg_list=[], countrange=[0.0, 0.0],\n",
    "                crop_size=1.0/30.0,\n",
    "                background_sub_option = 'median',\n",
    "                apt_sigmathreshold    = 5.0,\n",
    "                fit_fwhm              = True,\n",
    "                fwhm                  = 0.0,\n",
    "                refstar_file          = 'reference_star.txt',\n",
    "                 refstar_color        = (1, 0, 1),\n",
    "                 refstar_symsize      = 30,\n",
    "                skip_file_list        = []\n",
    "                ):\n",
    "        '''\n",
    "        Method to find reference stars.\n",
    "        It looks for stars in a list of images, excluding those which are brighter or dimmer\n",
    "        than the specified countrange, further excluding those which are already in the \n",
    "        markers_list (i.e., those separated from markers by less than one PSF-fwhm),\n",
    "        and then either store to ASCII output,\n",
    "        which can be loaded by the cal_ref method.\n",
    "        \n",
    "        \n",
    "        Keywords :\n",
    "        \n",
    "        refimg_list   [str list]   : A list of image path+name for identifying reference stars.\n",
    "                                     Will use all images if this is not specified.\n",
    "                                    \n",
    "        countrange    [float list] : [count_min, count_max], in image brightness unit. If set,\n",
    "                                     then only use reference stars of which the counts are within\n",
    "                                     the specified range. Otherwise, if \n",
    "                                     (i) refimg_list is specified, will use all found stars\n",
    "                                         (except those in the input marker list).\n",
    "                                     (ii) refimg_list is not specified. In this case, if the \n",
    "                                          countrange_dict for individual images have been evaluated \n",
    "                                          by a preliminary run of do_apt and were stored, then we \n",
    "                                          will use the stored values. It is presently defined as\n",
    "                                          [\n",
    "                                           self.countrange_dict{image_name}[0]/6.25, \n",
    "                                           self.countrange_dict{image_name}[0]*6.25\n",
    "                                          ], i.e., using reference stars in approximately +/2 mag\n",
    "                                          range as compared with all target sources.\n",
    "                                          Otherwise, will use all found\n",
    "                                          stars (except those in the input marker list).\n",
    "                                          \n",
    "        crop_size      [float] : size of the crops for making aperture photometry.\n",
    "                                 Default is 1/30 of the entire image. Need to enlarge the crop\n",
    "                                 if the size is smaller than two times the fwhm (see the fwhm item).\n",
    "                                          \n",
    "        background_sub_option [str]: Keyword to specify how background subtraction is made.\n",
    "                                     See description in function: background_sub.\n",
    "                                     \n",
    "        apt_sigmathreshold    [float] : Identify stars which are brighter than the specified\n",
    "                                        sigma threshold. Default: 5-sigma.\n",
    "\n",
    "        fit_fwhm         [True/False] : Specify whether or not we will fit fwhm from reference\n",
    "                                        stars. If not, will use the specified fwhm \n",
    "                                        (see the fwhm item).\n",
    "                                        If true, and if fwhm is set to 0.0, then we will use the\n",
    "                                        fwhm derived from the preliminary run of do_apt when finding\n",
    "                                        candidate reference stars.\n",
    "                                        \n",
    "        fwhm                  [float] : fwhm of the point-spread-function in units of pixels.\n",
    "                                        If fit_fwhm=False, then this parameter has to be specified.\n",
    "                                        Otherwise, this method will imply report error.\n",
    "                                        If fit_fwhm=True, this fwhm will be used only during initial \n",
    "                                        search of potential sources.\n",
    "                                        \n",
    "        refstar_file          [str]   : Filename to ASCII output the identified reference stars.\n",
    "        \n",
    "        skip_file_list  [list of str] : A list of filename that we do not want to find reference stars\n",
    "                                        from, for example, for some epochs which the PSFs are not round.\n",
    "                                        This helps since the phoutils package is very slow when examining\n",
    "                                        such images. And such images are not useful anyway.\n",
    "        '''\n",
    "        \n",
    "        ##### Initial preparation - - - - - - - - - - - - - - - - - - - - - \n",
    "        \n",
    "        from_input_list = True\n",
    "        \n",
    "        \n",
    "        F_report = open(self.ascii_report,\"a+\")\n",
    "        F_report.write('\\n')\n",
    "        F_report.write('Finding reference stars: \\n')\n",
    "        F_report.write('(only FITS images with compte header information are processed.) \\n')\n",
    "        \n",
    "        F_refstar = open(refstar_file,\"w+\")\n",
    "        F_refstar.write(\"# name, ra dec R:0-1 G:0-1 B:0-1 alpha size band jd count file_name \\n\")\n",
    "        \n",
    "        \n",
    "        if (fit_fwhm == False):\n",
    "            if (fwhm == 0.0):\n",
    "                print('No way to determine fwhm. Return.')\n",
    "                F_report.write('No way to determine fwhm. Returned. \\n')\n",
    "                F_report.close()\n",
    "                return\n",
    "        \n",
    "        if ( len(refimg_list) == 0 ):\n",
    "            from_input_list = False\n",
    "            if (self.verbose == True):\n",
    "                print(\"No input reference image names. Searching for reference stars from all input images.\")\n",
    "            \n",
    "            for i in range(0, self.num_images):\n",
    "                image_name  = self.images[i]\n",
    "                dirstr     = self.path_dict[image_name] + '/' + image_name\n",
    "                refimg_list.append(dirstr)\n",
    "                \n",
    "                \n",
    "        for file_id in range(0, self.num_images):\n",
    "\n",
    "            ##### Identifying reference stars - - - - - - - - - - - - - - - - - - - - - \n",
    "            \n",
    "            # loading image_name in case we need to refer to dictionaries\n",
    "            if (from_input_list == False):\n",
    "                image_name = self.images[file_id]\n",
    "                \n",
    "                if (image_name in skip_file_list):\n",
    "                    F_report.write('Excluding ' + image_name + ' because it is in the skip list \\n')\n",
    "                    continue\n",
    "                \n",
    "                if (self.verbose == True):\n",
    "                    print('######## Finding references from image : ' + image_name)\n",
    "                try:\n",
    "                    band = self.band_dict[image_name]\n",
    "                    jd   = self.jd_dict[image_name]\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # open FITS image\n",
    "            try:\n",
    "                hdulist = fits.open( refimg_list[file_id] )\n",
    "            except:\n",
    "                F_report.write('Failed to open image : ' + image_name + '\\n')\n",
    "                continue\n",
    "                \n",
    "            # load header information\n",
    "            try:\n",
    "                image   = hdulist[0].data\n",
    "                image   = np.array(image)\n",
    "                naxis1  = hdulist[0].header['naxis1']\n",
    "                naxis2  = hdulist[0].header['naxis2']\n",
    "                pixsize = hdulist[0].header['secpix']\n",
    "                crval1  = hdulist[0].header['crval1']\n",
    "                crval2  = hdulist[0].header['crval2']\n",
    "                w       = wcs.WCS(hdulist[0].header)\n",
    "                cropbox_halfsize_x = int((float(naxis1)/2.0) * crop_size)\n",
    "                cropbox_halfsize_y = int((float(naxis2)/2.0) * crop_size)\n",
    "            except:\n",
    "                F_report.write('Failed to load wcs for image : ' + image_name + '\\n')\n",
    "                continue\n",
    "                \n",
    "            # do background subtraction from the crop\n",
    "            image = self.background_sub(image, option=background_sub_option)\n",
    "\n",
    "            # estimate robust standard deviation from the cropped image\n",
    "            bkg_sigma = mad_std(image)\n",
    "\n",
    "            # find stars\n",
    "            if (fit_fwhm==True):\n",
    "                try:\n",
    "                    findstar_fwhm = self.fwhm_dict[image_name]\n",
    "                except:\n",
    "                    findstar_fwhm = 0.0\n",
    "            else:\n",
    "                findstar_fwhm=fwhm\n",
    "            \n",
    "            daofind = DAOStarFinder(fwhm=findstar_fwhm, threshold=apt_sigmathreshold*bkg_sigma)\n",
    "            sources = daofind(image)\n",
    "            try:\n",
    "                mxcentroid_array = np.array( sources['xcentroid'] )\n",
    "                mycentroid_array = np.array( sources['ycentroid'] )\n",
    "                mpeak_array      = np.array( sources['peak']      )\n",
    "                num_sources      = len(mpeak_array)\n",
    "            except:\n",
    "                num_sources      = 0\n",
    "\n",
    "                \n",
    "            # Outputting measurements\n",
    "            self.fwhm_dict[image_name] = 0.0\n",
    "            if ( num_sources > 0 ):\n",
    "                \n",
    "                ref_touse_list  = np.zeros(num_sources) # set to 0 if not use; set to 1 if use\n",
    "                ref_ra_list     = np.zeros(num_sources)\n",
    "                ref_dec_list    = np.zeros(num_sources)\n",
    "                ref_count_list  = np.zeros(num_sources)\n",
    "                \n",
    "                # fit FWHM\n",
    "                if (fit_fwhm == True):\n",
    "                    temp_fwhm_list = []\n",
    "                    # iterate through individual found sources\n",
    "                    for ref_id in range(0, num_sources):\n",
    "                        \n",
    "                        mxcentroid = mxcentroid_array[ref_id]\n",
    "                        mycentroid = mycentroid_array[ref_id]\n",
    "                        world = w.wcs_pix2world([ [mxcentroid,mycentroid] ], 0)\n",
    "                        ref_ra_list[ref_id]  = world[0][0]\n",
    "                        ref_dec_list[ref_id] = world[0][1]\n",
    "                        \n",
    "                        temp_fwhm = self.get_fwhm(image, w, world[0][0], world[0][1], background_sub_option,\n",
    "                                             naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y\n",
    "                                            )\n",
    "                        if ( np.isfinite(temp_fwhm) == True ):\n",
    "                            if ( temp_fwhm > 1 ):\n",
    "                                temp_fwhm_list.append(temp_fwhm)\n",
    "                                ref_touse_list[ref_id] = 1\n",
    "                                \n",
    "                    temp_fwhm_list = np.array(temp_fwhm_list)\n",
    "                    medianfwhm           = np.median(temp_fwhm_list)\n",
    "\n",
    "                    if ( np.isfinite(fwhm) == True ):\n",
    "                        self.fwhm_dict[image_name] = medianfwhm\n",
    "                    else:\n",
    "                        self.fwhm_dict[image_name] = 0.0\n",
    "                else:\n",
    "                    self.fwhm_dict[image_name] = fwhm\n",
    "\n",
    "                        \n",
    "                # do photometry\n",
    "                for ref_id in range(0, num_sources):\n",
    "                    if (ref_touse_list[ref_id]==1):\n",
    "                        count = self.get_count(image, w, ref_ra_list[ref_id], ref_dec_list[ref_id], \n",
    "                                               self.fwhm_dict[image_name], \n",
    "                                               background_sub_option, apt_sigmathreshold,\n",
    "                                               naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y)\n",
    "                        if ( np.isfinite(count) == False ):\n",
    "                            ref_touse_list[ref_id] = 0\n",
    "                        elif ( count <=0 ):\n",
    "                            ref_touse_list[ref_id] = 0\n",
    "                        else:\n",
    "                            ref_count_list[ref_id] = count\n",
    "\n",
    "                \n",
    "                ##### Removing objects which are too bright or too faint - - - - - - - - -\n",
    "                filt_count = False\n",
    "                if ( (countrange[0] > 0) and (countrange[1] > 0 ) ):\n",
    "                    countmin = countrange[0]\n",
    "                    countmax = countrange[1]\n",
    "                    filt_count = True\n",
    "                else:\n",
    "                    countmin = 0.0\n",
    "                    countmax = 0.0\n",
    "                    try:\n",
    "                        countmin = self.countrange_dict[image_name][0] / 6.25\n",
    "                        countmax = self.countrange_dict[image_name][1] * 6.25\n",
    "                        filt_count = True\n",
    "                    except:\n",
    "                        filt_count = False\n",
    "                        \n",
    "                if (filt_count == True):\n",
    "                    for ref_id in range(0, num_sources):\n",
    "                        count = ref_count_list[ref_id]\n",
    "                        if ( (count < countmin) or (count > countmax) ):\n",
    "                            ref_touse_list[ref_id] = 0\n",
    "            \n",
    "                ##### Removing those which are in the markers list - - - - - - - - - - - -\n",
    "                for marker in self.marker_list:\n",
    "                    for ref_id in range(0, num_sources):\n",
    "                        coord1 = [ref_ra_list[ref_id],   ref_dec_list[ref_id]]\n",
    "                        coord2 = [marker.ra,   marker.dec]\n",
    "                        off_degree = angoff_degree(coord1, coord2)\n",
    "                        off        = off_degree * 3600.0\n",
    "\n",
    "                        if ( off <= self.fwhm_dict[image_name]*pixsize ):\n",
    "                            ref_touse_list[ref_id] = 0\n",
    "            \n",
    "            ##### Summarizing results of identification - - - - - - - - - - - - - - - - - -\n",
    "            F_report.write('Use fwhm: ' + str(self.fwhm_dict[image_name]) + ',  Found '  +  str(int(np.sum(ref_touse_list))) + \n",
    "                           ' reference stars in ' + image_name + '\\n')\n",
    "            \n",
    "            if (self.verbose == True):\n",
    "                print('Will export ' +  str(int(np.sum(ref_touse_list))) + \n",
    "                      ' reference stars to file ' + refstar_file + '\\n')\n",
    "            for ref_id in range(0, num_sources):\n",
    "                if ( ref_touse_list[ref_id] > 0 ):\n",
    "                    outstring = ''\n",
    "                    outstring += str(file_id) + '_' + str(ref_id) + ' '\n",
    "                    outstring += str(ref_ra_list[ref_id]) + ' ' + str(ref_dec_list[ref_id]) + ' '\n",
    "                    outstring += str(refstar_color[0])+' '+ str(refstar_color[1])+' '+str(refstar_color[2])+' '\n",
    "                    outstring += '1 ' + str(refstar_symsize) + ' '\n",
    "                    outstring += band + ' ' + str(jd) + ' '\n",
    "                    outstring += str(ref_count_list[ref_id]) + ' '\n",
    "                    outstring += image_name + '\\n'\n",
    "                    F_refstar.write(outstring)\n",
    "                        \n",
    "        F_report.close()\n",
    "        F_refstar.close()\n",
    "    \n",
    "    \n",
    "        \n",
    "    def do_apt(self, crop_size=1.0/30.0,\n",
    "                     background_sub_option = 'median',\n",
    "                     apt_sigmathreshold    = 3.0,\n",
    "                     fit_fwhm              = False,\n",
    "                     use_fwhmfit           = False,\n",
    "                     fwhm                  = 0.0,\n",
    "                     skip_file_list        = []\n",
    "              ):\n",
    "        '''\n",
    "        Method to do aperture photometry for loaded markers.\n",
    "        \n",
    "        \n",
    "        Keywords : \n",
    "        \n",
    "        crop_size      [float] : size of the crops for making aperture photometry.\n",
    "                                 Default is 1/30 of the entire image.\n",
    "                                 \n",
    "        background_sub_option [str]: Keyword to specify how background subtraction is made.\n",
    "                                     See description in function: background_sub.\n",
    "                                     \n",
    "        apt_sigmathreshold    [float] : Identify stars which are brighter than the specified\n",
    "                                        sigma threshold. Default: 5-sigma.\n",
    "                                        \n",
    "        fit_fwhm         [True/False] : Specify whether or not we will fit fwhm from reference\n",
    "                                        stars. If not, will use the specified fwhm \n",
    "                                        (see the fwhm item).\n",
    "                                        \n",
    "        use_fwhmfit      [True/False] : If set to False, then it will not use the fitted fwhm\n",
    "                                        when doing aperture photometry, but will only store the\n",
    "                                        fwhm values to the class. This is useful when making a\n",
    "                                        preliminary run before running find_ref.\n",
    "                                        \n",
    "        fwhm                  [float] : fwhm of the point-spread-function in units of pixels.\n",
    "                                        If not specified, and if fit_fwhm=False, \n",
    "                                        it will take values which are obtained from\n",
    "                                        fitting reference stars.\n",
    "                                        \n",
    "        skip_file_list  [list of str] : A list of filename that we do not want to find reference stars\n",
    "                                from, for example, for some epochs which the PSFs are not round.\n",
    "                                This helps since the phoutils package is very slow when examining\n",
    "                                such images. And such images are not useful anyway.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        F_report = open(self.ascii_report,\"a+\")\n",
    "        F_report.write('\\n')\n",
    "        F_report.write('Photometry: \\n')\n",
    "        F_report.write('(only FITS images with compte header information are processed.) \\n')\n",
    "        \n",
    "        # Re-Initialize markers:\n",
    "        for marker in self.marker_list:\n",
    "            marker.band_list = []\n",
    "            marker.jd_dict   = {}\n",
    "            marker.flux_dict = {}\n",
    "      \n",
    "        # Obtaining the PSF information (fitting the reference stars if necessary)\n",
    "        if (fwhm == 0.0):\n",
    "            if (fit_fwhm == False):\n",
    "                use_fwhmfit = True\n",
    "                if (self.verbose == True):\n",
    "                    print('No input PSF fwhm. Use the fitted values from reference stars')\n",
    "            else:\n",
    "                if (self.verbose == True):\n",
    "                    print('No input PSF fwhm. Will fit fwhm from markers')                \n",
    "        \n",
    "        \n",
    "        # Doing photometry\n",
    "        for i in range(0, self.num_images):\n",
    "            \n",
    "            image_name = self.images[i]\n",
    "            if (image_name in skip_file_list):\n",
    "                print('##### skipping image : ' + image_name)\n",
    "                continue\n",
    "            \n",
    "            temp_count_list   = []\n",
    "            num_found_markers = 0\n",
    "            count_max  = 0.0\n",
    "            count_min  = 0.0\n",
    "            self.countrange_dict[image_name] = [count_min, count_max]\n",
    "            hdulist = fits.open(self.path_dict[image_name] + '/' + image_name)\n",
    "            try:\n",
    "                image  = hdulist[0].data\n",
    "                image  = np.array(image)\n",
    "                naxis1 = hdulist[0].header['naxis1']\n",
    "                naxis2 = hdulist[0].header['naxis2']                \n",
    "                w      = wcs.WCS(hdulist[0].header)\n",
    "                cropbox_halfsize_x = int((float(naxis1)/2.0) * crop_size)\n",
    "                cropbox_halfsize_y = int((float(naxis2)/2.0) * crop_size)\n",
    "            except:\n",
    "                F_report.write('Failed to load wcs for image : ' + image_name + '\\n')\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                band = self.band_dict[image_name]\n",
    "                jd   = self.jd_dict[image_name]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            hdulist.close()\n",
    "            \n",
    "            # Obtain PSF fwhm if necessary\n",
    "            if (fit_fwhm == True):\n",
    "                temp_fwhm_list = []\n",
    "                for marker in self.marker_list:\n",
    "                    temp_fwhm = self.get_fwhm(image, w, marker.ra, marker.dec, background_sub_option,\n",
    "                                         naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y\n",
    "                                        )\n",
    "                    temp_fwhm_list.append(temp_fwhm)\n",
    "                temp_fwhm_list = np.array(temp_fwhm_list)\n",
    "                fwhm           = np.median(temp_fwhm_list)\n",
    "                if ( np.isfinite(fwhm) == True ):\n",
    "                    self.fwhm_dict[image_name] = fwhm\n",
    "                else:\n",
    "                    self.fwhm_dict[image_name] = 0.0\n",
    "\n",
    "            if (use_fwhmfit == True):\n",
    "                fwhm = self.fwhm_dict[image_name]\n",
    "                if (self.verbose==True):\n",
    "                    print('Using fwhm : ' + str(fwhm) + ' for image ' + image_name + '\\n')\n",
    "                        \n",
    "            # Process individual markers\n",
    "            for marker in self.marker_list:\n",
    "                \n",
    "                # get photometry\n",
    "                count = self.get_count(image, w, marker.ra, marker.dec, fwhm, \n",
    "                                       background_sub_option, apt_sigmathreshold,\n",
    "                                       naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y)\n",
    "                if (count > 0):\n",
    "                    temp_count_list.append(count)\n",
    "                    num_found_markers += 1\n",
    "                    if (band not in marker.band_list):\n",
    "                        marker.band_list.append( band )\n",
    "                        # initializing lists to store JD and counts\n",
    "                        marker.jd_dict[ band ]     = []\n",
    "                        marker.flux_dict[ band ]   = []\n",
    "                        \n",
    "                    marker.jd_dict[ band ].append( jd )\n",
    "                    marker.flux_dict[ band ].append( count )    \n",
    "                else:\n",
    "                    F_report.write(\"Cannot find \" + str(marker.label) + \" in \" + image_name + '\\n')\n",
    "              \n",
    "            # Evaluating the maximum and minimum counts from all markers\n",
    "            if (num_found_markers > 0):\n",
    "                temp_count_list = np.array(temp_count_list)\n",
    "                self.countrange_dict[image_name] = [np.min(temp_count_list), \n",
    "                                                    np.max(temp_count_list)]\n",
    "                           \n",
    "        F_report.write('\\n')\n",
    "        F_report.close()\n",
    "\n",
    "        \n",
    "\n",
    "    def get_db(self, refstar_file = '', search_radii_arcsec = 1.0, db='vizier', \n",
    "               outrefdb_file='refdb.txt'):\n",
    "        '''\n",
    "        Method to query database via SIMBAD or Vizier.\n",
    "        It reads the ASCII table of reference stars,\n",
    "        querying the database (simbad or vizier) to obtain the magnitudes of the observed bands,\n",
    "        and then output the query results to an ASCII file.\n",
    "        \n",
    "        \n",
    "        Keywords:\n",
    "        \n",
    "        refstar_file          [str]   : Filename to ASCII input the identified reference stars.\n",
    "        \n",
    "        search_radii_arcsec   [float] : search radius for finding the reference star,\n",
    "                                        in units of arcsecond. Default: 1.0\n",
    "                                        \n",
    "        db                    [str]   : Database. Either 'simbad' or 'vizier'\n",
    "        \n",
    "        outrefdb_file         [str]   : Name of the output query result. The format is similar to\n",
    "                                        that for the reference star file. But instead of tagging\n",
    "                                        the imagename at the end of each row, this method tag the\n",
    "                                        magnitudes and magnitude errors.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # Loading refernce star information\n",
    "        try:\n",
    "            ra               = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=1 )\n",
    "            dec              = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=2 )\n",
    "            band             = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=8, dtype=np.str)\n",
    "            jd               = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=9 )\n",
    "            count            = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=10 )\n",
    "        except:\n",
    "            print(\"Failed to open refstar_file. Return.\")\n",
    "            F_report.write(\"Failed to open refstar_file. Nothing is done.\\n\")\n",
    "            F_report.close()\n",
    "            return\n",
    "        \n",
    "        # removing the duplicated reference stars\n",
    "        unique_ra_list  = []\n",
    "        unique_dec_list = []\n",
    "        for i in range(0, len(ra) ):\n",
    "            if ( len(unique_ra_list) == 0 ):\n",
    "                unique_ra_list.append(ra[i])\n",
    "                unique_dec_list.append(dec[i])\n",
    "            else:\n",
    "                append_refstar = True\n",
    "                for j in range(0, len(unique_ra_list) ):\n",
    "                    coord_1 = [unique_ra_list[j], unique_dec_list[j]]\n",
    "                    coord_2 = [ra[i], dec[i]]\n",
    "                    temp_angoff = angoff_degree(coord_1, coord_2)\n",
    "                    if ( temp_angoff < (search_radii_arcsec / 3600.0) ):\n",
    "                        append_refstar = False\n",
    "                if (append_refstar == True):\n",
    "                    unique_ra_list.append(ra[i])\n",
    "                    unique_dec_list.append(dec[i])\n",
    "                    \n",
    "        if (self.verbose == True):\n",
    "            print('There are ', len(unique_ra_list),  ' unique reference stars')\n",
    "\n",
    "\n",
    "        \n",
    "        # Initialize a list of marker for storing output\n",
    "        dbmarker_list = []\n",
    "        \n",
    "        if ( db == 'simbad' ):\n",
    "            \n",
    "            # initializing a simbad quary object\n",
    "            customSimbad = Simbad()\n",
    "            \n",
    "            # including the bands which we want to get magnitudes\n",
    "            for band in self.filterlist:\n",
    "                field_str = 'flux(' + band + ')'\n",
    "                customSimbad.add_votable_fields(field_str)\n",
    "   \n",
    "            # try making query\n",
    "            try:\n",
    "                result_table = customSimbad.query_region(SkyCoord(ra=unique_ra_list, dec=unique_dec_list,\n",
    "                                                         unit=(u.deg, u.deg), frame='icrs'),\n",
    "                                                         radius=search_radii_arcsec * u.arcsec)\n",
    "            except:\n",
    "                print(\"Failed making query to SIMBAD. Please check network.\")\n",
    "                return\n",
    "            \n",
    "            # loading result to the list of marker to prepare for ASCII output\n",
    "            for i in range(0, len(result_table['RA']) ):\n",
    "                \n",
    "                coordstr = str(result_table['RA'][i])  + ' ' + str(result_table['DEC'][i]) + ' '\n",
    "                c = SkyCoord(coordstr, unit=(u.hourangle, u.deg))\n",
    "                \n",
    "                num_dbmarker = len(dbmarker_list)\n",
    "                if ( num_dbmarker == 0 ):\n",
    "                    new_data = False\n",
    "                    mid = 0\n",
    "                    temp_marker = marker(label='SIMBAD_' + str(mid).strip() )\n",
    "                    temp_marker.ra  = c.ra.degree\n",
    "                    temp_marker.dec = c.dec.degree\n",
    "                    \n",
    "                    # try loading flux values\n",
    "                    for band in self.filterlist:\n",
    "                        magstr    = 'FLUX_'+band\n",
    "                        try:\n",
    "                            temp_mag = float( result_table[magstr][i])\n",
    "                            if ( np.isfinite(temp_mag) == True ):\n",
    "                                new_data = True\n",
    "                                temp_marker.band_list.append(band)\n",
    "                                temp_marker.jd_dict[band]   = [0.0]\n",
    "                                temp_marker.flux_dict[band] = [0.0]\n",
    "                                temp_marker.mag_dict[band]  = [temp_mag]                \n",
    "                        except:\n",
    "                            pass\n",
    "                    if (new_data == True):\n",
    "                        dbmarker_list.append(temp_marker)\n",
    "                else:\n",
    "                    # test if marker already exist\n",
    "                    append_marker = True\n",
    "                    new_data      = False\n",
    "                    for db_marker in dbmarker_list:\n",
    "                        coord_1 = [db_marker.ra, db_marker.dec]\n",
    "                        coord_2 = [c.ra.degree, c.dec.degree]\n",
    "                        temp_angoff = angoff_degree(coord_1, coord_2)\n",
    "                        if ( temp_angoff < (search_radii_arcsec / 3600.0) ):\n",
    "                            append_marker = False\n",
    "                            # append the flux values to this marker\n",
    "                            for band in self.filterlist:\n",
    "                                magstr    = 'FLUX_'+band\n",
    "                                try:\n",
    "                                    temp_mag = float( result_table[magstr][i])\n",
    "                                    if ( np.isfinite(temp_mag) == True ):\n",
    "                                        new_data = True\n",
    "                                        if band in db_marker.band_list:\n",
    "                                            temp_marker.jd_dict[band].append(0.0)\n",
    "                                            temp_marker.flux_dict[band].append(0.0)\n",
    "                                            temp_marker.mag_dict[band].append(temp_mag)\n",
    "                                        else:\n",
    "                                            db_marker.band_list.append(band)\n",
    "                                            temp_marker.jd_dict[band]   = [0.0]\n",
    "                                            temp_marker.flux_dict[band] = [0.0]\n",
    "                                            temp_marker.mag_dict[band]  = [temp_mag]                                      \n",
    "                                except:\n",
    "                                    pass\n",
    "                            \n",
    "                    if (append_marker == True):\n",
    "                        mid = num_dbmarker\n",
    "                        temp_marker = marker(label='SIMBAD_' + str(mid).strip() )\n",
    "                        temp_marker.ra  = c.ra.degree\n",
    "                        temp_marker.dec = c.dec.degree\n",
    "                        for band in self.filterlist:\n",
    "                            magstr    = 'FLUX_'+band\n",
    "                            try:\n",
    "                                temp_mag = float( result_table[magstr][i])\n",
    "                                if ( np.isfinite(temp_mag) == True ):\n",
    "                                    new_data = True\n",
    "                                    temp_marker.band_list.append(band)\n",
    "                                    temp_marker.jd_dict[band]   = [0.0]\n",
    "                                    temp_marker.flux_dict[band] = [0.0]\n",
    "                                    temp_marker.mag_dict[band]  = [temp_mag]                \n",
    "                            except:\n",
    "                                pass\n",
    "                        if (new_data == True):\n",
    "                            dbmarker_list.append(temp_marker)\n",
    "\n",
    "        \n",
    "        if ( db == 'vizier' ):\n",
    "            \n",
    "            # initializing a Vizier quary object, including the bands which we want to get magnitudes\n",
    "            vizier_columns = ['_RAJ2000', '_DEJ2000']\n",
    "            for band in self.filterlist:\n",
    "                vizier_columns.append(band+'mag')\n",
    "            customVizier = Vizier(columns=vizier_columns)\n",
    "   \n",
    "            # try making query\n",
    "            try:\n",
    "                result_table = customVizier.query_region(SkyCoord(ra=unique_ra_list, dec=unique_dec_list,\n",
    "                                                         unit=(u.deg, u.deg), frame='icrs'),\n",
    "                                                         radius=search_radii_arcsec * u.arcsec\n",
    "                                                        )\n",
    "            except:\n",
    "                print(\"Failed making query to Vizier. Please check network.\")\n",
    "                return\n",
    "            \n",
    "            # loading result to the list of marker to prepare for ASCII output\n",
    "            for tabid in range(0, len(result_table) ):\n",
    "                                                         \n",
    "                for i in range(0, len(result_table[tabid]['_RAJ2000']) ):\n",
    "\n",
    "                    coordstr = str(result_table[tabid]['_RAJ2000'][i])  + ' ' + \\\n",
    "                               str(result_table[tabid]['_DEJ2000'][i]) + ' '\n",
    "                    c = SkyCoord(coordstr, unit=(u.hourangle, u.deg))\n",
    "\n",
    "                    num_dbmarker = len(dbmarker_list)\n",
    "                    if ( num_dbmarker == 0 ):\n",
    "                        new_data = False\n",
    "                        mid = 0\n",
    "                        temp_marker = marker(label='SIMBAD_' + str(mid).strip() )\n",
    "                        temp_marker.ra  = c.ra.degree\n",
    "                        temp_marker.dec = c.dec.degree\n",
    "\n",
    "                        # try loading flux values\n",
    "                        for band in self.filterlist:\n",
    "                            magstr_list    = ['_'+band, band+'mag']\n",
    "                            for magstr in magstr_list:\n",
    "                                try:\n",
    "                                    temp_mag = float( result_table[tabid][magstr][i])\n",
    "                                    if ( np.isfinite(temp_mag) == True ):\n",
    "                                        new_data = True\n",
    "                                        temp_marker.band_list.append(band)\n",
    "                                        temp_marker.jd_dict[band]   = [0.0]\n",
    "                                        temp_marker.flux_dict[band] = [0.0]\n",
    "                                        temp_marker.mag_dict[band]  = [temp_mag]                \n",
    "                                except:\n",
    "                                    pass\n",
    "                        if (new_data == True):\n",
    "                            dbmarker_list.append(temp_marker)\n",
    "                    else:\n",
    "                        # test if marker already exist\n",
    "                        append_marker = True\n",
    "                        new_data = False\n",
    "                        for db_marker in dbmarker_list:\n",
    "                            coord_1 = [db_marker.ra, db_marker.dec]\n",
    "                            coord_2 = [c.ra.degree, c.dec.degree]\n",
    "                            temp_angoff = angoff_degree(coord_1, coord_2)\n",
    "                            if ( temp_angoff < (search_radii_arcsec / 3600.0) ):\n",
    "                                append_marker = False\n",
    "                                \n",
    "                                # append the flux values to this marker\n",
    "                                for band in self.filterlist:\n",
    "                                    magstr_list    = ['_'+band, band+'mag']\n",
    "                                    for magstr in magstr_list:\n",
    "                                        try:\n",
    "                                            temp_mag = float( result_table[tabid][magstr][i])\n",
    "                                            if ( np.isfinite(temp_mag) == True ):\n",
    "                                                new_data = True\n",
    "                                                if band in db_marker.band_list:\n",
    "                                                    temp_marker.jd_dict[band].append(0.0)\n",
    "                                                    temp_marker.flux_dict[band].append(0.0)\n",
    "                                                    temp_marker.mag_dict[band].append(temp_mag)\n",
    "                                                else:\n",
    "                                                    db_marker.band_list.append(band)\n",
    "                                                    temp_marker.jd_dict[band]   = [0.0]\n",
    "                                                    temp_marker.flux_dict[band] = [0.0]\n",
    "                                                    temp_marker.mag_dict[band]  = [temp_mag]                                      \n",
    "                                        except:\n",
    "                                            pass\n",
    "\n",
    "                        if (append_marker == True):\n",
    "                            mid = num_dbmarker\n",
    "                            temp_marker = marker(label='SIMBAD_' + str(mid).strip() )\n",
    "                            temp_marker.ra  = c.ra.degree\n",
    "                            temp_marker.dec = c.dec.degree\n",
    "                            for band in self.filterlist:\n",
    "                                magstr_list    = ['_'+band, band+'mag']\n",
    "                                for magstr in magstr_list:\n",
    "                                    try:\n",
    "                                        temp_mag = float( result_table[tabid][magstr][i])\n",
    "                                        if ( np.isfinite(temp_mag) == True ):\n",
    "                                            new_data = True\n",
    "                                            temp_marker.band_list.append(band)\n",
    "                                            temp_marker.jd_dict[band]   = [0.0]\n",
    "                                            temp_marker.flux_dict[band] = [0.0]\n",
    "                                            temp_marker.mag_dict[band]  = [temp_mag]                \n",
    "                                    except:\n",
    "                                        pass\n",
    "                            if(new_data == True):\n",
    "                                dbmarker_list.append(temp_marker)\n",
    "        \n",
    "        \n",
    "        # ASCII output\n",
    "        if (self.verbose == True):\n",
    "            print('number of reference stars ', len(dbmarker_list))\n",
    "            \n",
    "        F_db = open(outrefdb_file,\"w+\")\n",
    "        headerstr = \"# name, ra dec R:0-1 G:0-1 B:0-1 alpha size band jd count \"\n",
    "        for band in self.filterlist:\n",
    "            headerstr += band + '_mag ' + band + '_mag_Err '\n",
    "        headerstr += '\\n'\n",
    "        F_db.write(headerstr)\n",
    "        \n",
    "        for db_marker in dbmarker_list:\n",
    "            outstring = ''\n",
    "            outstring += db_marker.label + ' '\n",
    "            outstring += str(db_marker.ra) + ' ' + str(db_marker.dec) + ' '\n",
    "            outstring += '0 1 1 1 80 X 0.0 0.0     ' # R, G, B, alpha, size, band, jd, count (place holder)\n",
    "            for band in self.filterlist:\n",
    "                if band in db_marker.band_list:\n",
    "                    mag_array    = np.array( db_marker.mag_dict[band] )\n",
    "                    reduced_flux_array = 100.0**( (-1.0/5.0) * mag_array )\n",
    "                    mean_reduced_flux   = biweight_location( reduced_flux_array )\n",
    "                    stddec_reduced_flux = biweight_scale( reduced_flux_array )\n",
    "                    mean_mag            = -2.5 * np.log10(mean_reduced_flux)\n",
    "                    stddev_mag          = -2.5 * np.log10(mean_reduced_flux + stddec_reduced_flux)\n",
    "                    stddev_mag          = mean_mag - stddev_mag\n",
    "                    outstring += str( mean_mag ) + ' '\n",
    "                    outstring += str( stddev_mag )    + ' '\n",
    "                else:\n",
    "                    outstring += 'NaN NaN '\n",
    "            outstring += '\\n'\n",
    "            F_db.write(outstring)        \n",
    "        \n",
    "        F_db.close()\n",
    "        #else:\n",
    "        #    print('No data base specified. Nothing is done.')\n",
    "        \n",
    "        \n",
    "        \n",
    "    #customVizier = Vizier(columns=['_RAJ2000', '_DEJ2000','Imag', 'Rmag', 'Vmag'])\n",
    "        \n",
    "    def magcal(self, refstar_file = '', search_radii_arcsec = 1.0):\n",
    "        '''\n",
    "        Method to calibrate the photometry for reference stars.\n",
    "        It reads the ASCII table of reference stars,\n",
    "        querying SIMBAD to obtain the magnitudes of the observed bands,\n",
    "        deriving how to convert counts to magnitudes for a specific epoch\n",
    "        at a specific band, and then store the derived magnitudes of individual \n",
    "        markers in the class.\n",
    "        \n",
    "        \n",
    "        Keywords:\n",
    "        \n",
    "        refstar_file          [str]   : Filename to ASCII input the identified reference stars.\n",
    "        \n",
    "        search_radii_arcsec   [float] : search radius for finding the reference star,\n",
    "                                        in units of arcsecond. Default: 1.0\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        F_report = open(self.ascii_report,\"a+\")\n",
    "        F_report.write('\\n')\n",
    "        F_report.write('Calibrating from counts to magnitude: \\n')\n",
    "\n",
    "        # Loading refernce star information\n",
    "        try:\n",
    "            ra               = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=1 )\n",
    "            dec              = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=2 )\n",
    "            band             = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=8, dtype=np.str)\n",
    "            jd               = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=9 )\n",
    "            count            = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=10 )\n",
    "        except:\n",
    "            print(\"Failed to open refstar_file. Return.\")\n",
    "            F_report.write(\"Failed to open refstar_file. Nothing is done.\\n\")\n",
    "            F_report.close()\n",
    "            return\n",
    "        \n",
    "        # Initializing the magnitudes of markers\n",
    "        if ( len(self.marker_list)==0 ):\n",
    "            print(\"No data need calibration. Return.\")\n",
    "            F_report.write(\"No data need calibration. Nothing is done.\\n\")\n",
    "            F_report.close()\n",
    "            return\n",
    "        else:\n",
    "            for marker in self.marker_list:\n",
    "                for m_filter in marker.band_list:\n",
    "                    marker.mag_dict[m_filter] = []\n",
    "                    \n",
    "        ## Making query to SIMBAD\n",
    "        # initializing a simbad quary object\n",
    "        customSimbad = Simbad()\n",
    "        # including the bands which we want to get magnitudes\n",
    "        for band in self.filterlist:\n",
    "            field_str = 'flux(' + band + ')'\n",
    "            customSimbad.add_votable_fields(field_str)\n",
    "            \n",
    "        # try making query\n",
    "        try:\n",
    "            result_table = customSimbad.query_region(SkyCoord(ra=ra, dec=dec,\n",
    "                                                     unit=(u.deg, u.deg), frame='icrs'),\n",
    "                                                     radius=search_radii_arcsec * u.arcsec)\n",
    "        except:\n",
    "            print(\"Failed making query to SIMBAD. Please check network.\")\n",
    "            F_report.write(\"Failed making query to SIMBAD. Please check network. Nothing is done.\\n\")\n",
    "            F_report.close()\n",
    "            return\n",
    "\n",
    "        # ASCII output\n",
    "        ref_report = open('simbad.txt',\"w+\")\n",
    "        for i in range(0, len( result_table['FLUX_V'] ) ):\n",
    "            coordstr = str(result_table['RA'][i])  + ' ' + str(result_table['DEC'][i]) + ' '\n",
    "            c = SkyCoord(coordstr, unit=(u.hourangle, u.deg))\n",
    "            ref_report.write(\n",
    "                             'SIMBAD_' + str(i)  + ' ' +\n",
    "                             str(c.ra.degree)    + ' ' + \n",
    "                             str(c.dec.degree)   + ' ' + \n",
    "                             '0 1 1 1 80 X 0.0 0.0 \\n'\n",
    "                             #str(result_table['FLUX_V'][i]) + ' ' + \n",
    "                             #str(result_table['FLUX_R'][i]) + ' ' +\n",
    "                             #str(result_table['FLUX_I'][i]) + ' ' + \"\\n\"\n",
    "                            )\n",
    "            \n",
    "        ref_report.close()\n",
    "\n",
    "                \n",
    "        F_report.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def export_apt(self, outfile_name = 'photometry.txt'):\n",
    "        '''\n",
    "        Method to output time-sorted photometric measurements to an ascii file.\n",
    "        For a specific epoch, if a specific band was not observed, then\n",
    "        the output flux of that band will be 0.0. \n",
    "        \n",
    "        \n",
    "        Keyword:\n",
    "        \n",
    "        outfile_name      [str]  : name of the output file. Default: photometry.txt\n",
    "        '''\n",
    "\n",
    "        # Prepare output file\n",
    "        os.system('rm -rf ' + outfile_name)\n",
    "        F_out = open(outfile_name,\"a+\")\n",
    "        outheader = '# JD     source_name     fwhm     '\n",
    "        for band in self.filterlist:\n",
    "            outheader = outheader + band + '_band_counts     '\n",
    "        outheader = outheader + '\\n'\n",
    "        F_out.write(outheader)\n",
    "        \n",
    "        # collect all possible dates\n",
    "        temp_jd_list = []\n",
    "        for marker in self.marker_list:\n",
    "            for band in marker.band_list:\n",
    "                temp_jd_list += marker.jd_dict[band]\n",
    "            # avoid repetition (set) and sort()\n",
    "            temp_jd_list = list( set(temp_jd_list) )\n",
    "            temp_jd_list = np.array( temp_jd_list )\n",
    "            temp_jd_list = np.sort( temp_jd_list )\n",
    "            \n",
    "        for jd in temp_jd_list:\n",
    "            for marker in self.marker_list:\n",
    "                outstring  = str(jd) + '     ' + str(marker.label) + '     '\n",
    "                \n",
    "                fwhm_str = '0.0'\n",
    "                for image_name in self.images:\n",
    "                    try:\n",
    "                        img_jd = self.jd_dict[image_name]\n",
    "                        if (self.jd_dict[image_name] == jd):\n",
    "                            try:\n",
    "                                fwhm_str = str( self.fwhm_dict[image_name] )\n",
    "                            except:\n",
    "                                pass\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "\n",
    "                outstring  = outstring + fwhm_str + '     '\n",
    "                \n",
    "                datastring = ''\n",
    "                temp_flux_dict = {}\n",
    "                to_output  = False\n",
    "                \n",
    "                for band in self.filterlist:\n",
    "                    temp_flux_dict[band] = 0.0\n",
    "                \n",
    "                for band in marker.band_list:\n",
    "                    try:\n",
    "                        for record_idx in range( len(marker.jd_dict[band]) ):\n",
    "                            epoch = marker.jd_dict[band][record_idx]\n",
    "                            if(epoch==jd):\n",
    "                                temp_flux_dict[band] = marker.flux_dict[band][record_idx] \n",
    "                                to_output = True\n",
    "                    except:\n",
    "                        pass\n",
    "                                \n",
    "                if ( to_output == True ):\n",
    "                    for band in self.filterlist:\n",
    "                        datastring = datastring + str(temp_flux_dict[band]) + '     '\n",
    "                    outstring = outstring + datastring + '\\n'\n",
    "                    F_out.write(outstring)\n",
    "        \n",
    "        F_out.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot_preview(self, output_directory='./preview_images',\n",
    "                     label_marker=True,\n",
    "                     refstar_file='',\n",
    "                     simbad_file='',\n",
    "                     fig_format='png'\n",
    "                    ):\n",
    "        '''\n",
    "        Method to plot the preview figures for FITS imagfes.\n",
    "        It will produce figures for the observed images (one sub-directory for each band),\n",
    "        and collect them into an output_directory.\n",
    "        \n",
    "        \n",
    "        Keywords:\n",
    "        \n",
    "        output_directory [string] : The directory to collect the output images.\n",
    "        \n",
    "        label_marker [True/False] : If True, label the names of the markers on the figure.\n",
    "        \n",
    "        refstar_file              : If exist, load reference stars from file and plot them.\n",
    "        \n",
    "        simbad_file              : If exist, load reference stars from file and plot them.\n",
    "        \n",
    "        fig_format   [string]     : 'png' or 'pdf'\n",
    "        '''\n",
    "        \n",
    "        F_report = open(self.ascii_report,\"a+\")\n",
    "        F_report.write('\\n')\n",
    "        F_report.write('Image preview summary: \\n')\n",
    "        \n",
    "        os.system('rm -rf ' + output_directory)\n",
    "        os.system('mkdir '  + output_directory)\n",
    "        \n",
    "        output_path_dict = {}\n",
    "        for tempstr in self.filterlist:\n",
    "            output_path_dict[tempstr] = './' + tempstr + 'band_maps'\n",
    "            \n",
    "        for key in output_path_dict.keys():\n",
    "            os.system('rm -rf ' + output_path_dict[key] )\n",
    "            os.system('mkdir '  + output_path_dict[key] )\n",
    "            \n",
    "        # plot images\n",
    "        for i in range(0, self.num_images):\n",
    "            image_name = self.images[i]\n",
    "            try:\n",
    "                band       = self.band_dict[image_name]\n",
    "                jd         = self.jd_dict[image_name]\n",
    "            except:\n",
    "                F_report.write('Warning. Image ' +  image_name + ' is not saved. \\n')\n",
    "                continue\n",
    "            \n",
    "            # plot image\n",
    "            fig = aplpy.FITSFigure( self.path_dict[image_name] + '/' + image_name)\n",
    "            fig.show_grayscale(invert=False)\n",
    "            \n",
    "            # plot symbol\n",
    "            \n",
    "            # define output figure name\n",
    "            try:\n",
    "                outfig_name = \\\n",
    "                              band + '_' + \\\n",
    "                              str( round(jd,5) ) + '.' + fig_format\n",
    "                # fig.set_xaxis_coord_type('longitude')\n",
    "                # fig.set_yaxis_coord_type('latitude')\n",
    "                fig.axis_labels.hide()\n",
    "                fig.show_grayscale(invert=False)\n",
    "            except:\n",
    "                if (self.verbose == True):\n",
    "                    F_report.write('Warning. Image ' +  image_name + ' is not saved. \\n')\n",
    "                    \n",
    "            # plot markers\n",
    "            \n",
    "            for marker in self.marker_list:\n",
    "                # plot markers in the png figure\n",
    "                fig.show_markers(\n",
    "                                 marker.ra, marker.dec, \n",
    "                                 edgecolor=marker.color, \n",
    "                                 # facecolor=facecolor[plot_id],\n",
    "                                 marker='o', s=marker.size, \n",
    "                                 alpha=marker.alpha\n",
    "                                )\n",
    "                \n",
    "                if (label_marker == True):\n",
    "                    label = marker.label\n",
    "                    fig.add_label(marker.ra, marker.dec, '  ' + label,\n",
    "                                  color=marker.color, fontsize=12, horizontalalignment='left')\n",
    "                    \n",
    "            if (len(refstar_file) > 0):\n",
    "                try:\n",
    "                    refra         = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=1 )\n",
    "                    refdec        = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=2 )\n",
    "                    refR          = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=3 )\n",
    "                    refG          = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=4 )\n",
    "                    refB          = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=5 )\n",
    "                    ref_alpha     = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=6 )\n",
    "                    ref_size      = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=7 )\n",
    "                    ref_band      = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=8, dtype=np.str)\n",
    "                    ref_jd        = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=9 )\n",
    "                    \n",
    "                    for ref_id in range(0, np.size(refra) ):\n",
    "                        \n",
    "                        if ( jd == ref_jd[ref_id] ): # separated by less than 1s\n",
    "                            if (band == ref_band[ref_id].strip() ):\n",
    "                                fig.show_markers(\n",
    "                                         refra[ref_id], refdec[ref_id], \n",
    "                                         edgecolor=(refR[ref_id], refG[ref_id], refB[ref_id]), \n",
    "                                         marker='o', s=ref_size[ref_id], \n",
    "                                         alpha=ref_alpha[ref_id]\n",
    "                                        )                           \n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                \n",
    "            if (len(simbad_file) > 0):\n",
    "                try:\n",
    "                    refra         = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=1 )\n",
    "                    refdec        = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=2 )\n",
    "                    refR          = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=3 )\n",
    "                    refG          = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=4 )\n",
    "                    refB          = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=5 )\n",
    "                    ref_alpha     = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=6 )\n",
    "                    ref_size      = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=7 )\n",
    "                    ref_band      = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=8, dtype=np.str)\n",
    "\n",
    "                    for ref_id in range(0, np.size(refra) ):\n",
    "                        \n",
    "                        fig.show_markers(\n",
    "                                 refra[ref_id], refdec[ref_id], \n",
    "                                 edgecolor=(refR[ref_id], refG[ref_id], refB[ref_id]), \n",
    "                                 marker='o', \n",
    "                                 s=ref_size[ref_id], \n",
    "                                 alpha=ref_alpha[ref_id]\n",
    "                                )                           \n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            # label date\n",
    "            try:\n",
    "                date = self.date_dict[image_name].strip()\n",
    "            except:\n",
    "                date = 'unknown_date'\n",
    "                \n",
    "            date_label = 'Date : ' + date + '  JD : ' \\\n",
    "                         +  str(jd).strip()                    \\\n",
    "                         + '   Band : ' + band  \n",
    "            fig.add_label(0.02, 0.95, date_label, relative=True, \n",
    "                         color=(0,1,1,1),\n",
    "                         fontsize=9, horizontalalignment='left')\n",
    "            \n",
    "            # label image name\n",
    "            fig.add_label(0.02, 0.92, image_name, relative=True, \n",
    "                         color=(0,1,1,1),\n",
    "                         fontsize=9, horizontalalignment='left')\n",
    "                    \n",
    "            fig.axis_labels.hide()\n",
    "            fig.save(outfig_name)    \n",
    "            os.system('mv ' + outfig_name + ' ' + output_path_dict[band] )\n",
    "            \n",
    "        # pack output maps to be under the same directory\n",
    "        for key in output_path_dict.keys():\n",
    "            os.system('mv ' + output_path_dict[key] + ' ./' +  output_directory)   \n",
    "\n",
    "        F_report.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndmtau = apt_pipe(data_path = r\"../problem_images\",\\n                 markerfile   = \\'./markers.txt\\', verbose=True)\\ndmtau.plot_preview(label_marker=False)\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dmtau = apt_pipe(data_path = r\"../problem_images\",\n",
    "                 markerfile   = './markers.txt', verbose=True)\n",
    "dmtau.plot_preview(label_marker=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FITS image from : ../problem_images\n",
      "##############################################################\n",
      "Processing 13 images \n",
      "\n",
      "##############################################################\n",
      "Warning, coordinate header of dm tau_3463766_I_006.fits does not exist.\n",
      "Number of markers : 1\n",
      "##### skipping image : dm tau_3488473_R_040.fits\n",
      "##### skipping image : dm tau_3488473_I_056.fits\n",
      "##### skipping image : dm tau_3488473_V_075.fits\n",
      "##### skipping image : dm tau_3463766_I_034.fits\n",
      "##### skipping image : dm tau_3463766_R_022.fits\n",
      "##### skipping image : dm tau_3463766_V_029.fits\n",
      "##### skipping image : dm tau_3463766_I_035.fits\n",
      "No input PSF fwhm. Use the fitted values from reference stars\n",
      "Using fwhm : 4.2319388302882865 for image dm tau_3463766_I_015.fits\n",
      "\n",
      "##### skipping image : dm tau_3488473_R_040.fits\n",
      "Using fwhm : 3.0862700874025863 for image dm tau_3488473_R_064.fits\n",
      "\n",
      "Using fwhm : 3.9888853313298065 for image dm tau_3488473_I_038.fits\n",
      "\n",
      "##### skipping image : dm tau_3488473_I_056.fits\n",
      "##### skipping image : dm tau_3488473_V_075.fits\n",
      "##### skipping image : dm tau_3463766_I_034.fits\n",
      "##### skipping image : dm tau_3463766_R_022.fits\n",
      "Using fwhm : 2.8596430143831517 for image dm tau_3488473_V_018.fits\n",
      "\n",
      "##### skipping image : dm tau_3463766_V_029.fits\n",
      "##### skipping image : dm tau_3463766_I_035.fits\n",
      "Using fwhm : 3.275741050186997 for image dm tau_3488473_V_027.fits\n",
      "\n",
      "There are  70  unique reference stars\n",
      "number of reference stars  18\n",
      "V [11.399999618530273]\n",
      "R [15.489999771118164]\n",
      "V [15.90999984741211]\n",
      "V [11.75]\n",
      "V [13.5]\n",
      "V [11.210000038146973]\n",
      "V [14.0]\n",
      "V [13.0]\n",
      "V [13.0]\n",
      "V [13.5]\n",
      "V [11.390000343322754]\n",
      "V [12.5]\n",
      "V [13.5]\n",
      "V [13.5]\n",
      "V [13.5]\n",
      "R [13.699999809265137]\n",
      "V [13.899999618530273]\n",
      "V [13.0]\n",
      "V [13.0]\n",
      "V [13.5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 3 raised an error (recorded in the `errors` attribute of the result table): '4:34:39.9493 +18:05:33.5886': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 6 raised an error (recorded in the `errors` attribute of the result table): '4:34:28.4867 +18:22:35.8368': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 9 raised an error (recorded in the `errors` attribute of the result table): '4:34:21.0916 +18:18:47.9929': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 11 raised an error (recorded in the `errors` attribute of the result table): '4:34:12.8204 +18:19:53.9432': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 13 raised an error (recorded in the `errors` attribute of the result table): '4:33:54.2248 +18:01:59.5045': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 17 raised an error (recorded in the `errors` attribute of the result table): '4:33:30.6383 +18:24:30.3289': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 26 raised an error (recorded in the `errors` attribute of the result table): '4:33:10.9399 +18:01:24.8694': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 33 raised an error (recorded in the `errors` attribute of the result table): '4:32:47.0108 +18:05:00.9962': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 35 raised an error (recorded in the `errors` attribute of the result table): '4:32:53.3755 +18:02:27.6419': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 37 raised an error (recorded in the `errors` attribute of the result table): '4:33:01.3094 +18:00:34.1429': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 39 raised an error (recorded in the `errors` attribute of the result table): '4:33:07.2411 +17:59:39.8496': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 41 raised an error (recorded in the `errors` attribute of the result table): '4:33:10.6081 +17:55:24.2307': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 43 raised an error (recorded in the `errors` attribute of the result table): '4:33:12.1011 +18:13:55.8889': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 46 raised an error (recorded in the `errors` attribute of the result table): '4:33:15.915 +17:58:19.7379': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 48 raised an error (recorded in the `errors` attribute of the result table): '4:33:19.0119 +18:17:13.5057': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 51 raised an error (recorded in the `errors` attribute of the result table): '4:33:31.0406 +17:56:28.6094': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 53 raised an error (recorded in the `errors` attribute of the result table): '4:33:34.9052 +17:56:28.8158': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 55 raised an error (recorded in the `errors` attribute of the result table): '4:33:37.7458 +18:02:17.4822': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 57 raised an error (recorded in the `errors` attribute of the result table): '4:33:52.2705 +17:54:45.36': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 59 raised an error (recorded in the `errors` attribute of the result table): '4:34:13.9821 +17:54:55.1635': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 61 raised an error (recorded in the `errors` attribute of the result table): '4:34:18.9888 +17:57:47.2366': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 63 raised an error (recorded in the `errors` attribute of the result table): '4:34:27.4118 +17:54:24.6219': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 65 raised an error (recorded in the `errors` attribute of the result table): '4:34:29.2013 +18:16:55.6604': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 67 raised an error (recorded in the `errors` attribute of the result table): '4:33:27.838 +17:54:14.93': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 69 raised an error (recorded in the `errors` attribute of the result table): '4:34:42.2999 +18:03:56.0214': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/astroquery/simbad/core.py:138: UserWarning: Warning: The script line number 71 raised an error (recorded in the `errors` attribute of the result table): '4:33:03.358 +18:04:52.1317': No astronomical object found :  \n",
      "  (error.line, error.msg))\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/ipykernel_launcher.py:1015: UserWarning: Warning: converting a masked element to nan.\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/ipykernel_launcher.py:1063: UserWarning: Warning: converting a masked element to nan.\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/ipykernel_launcher.py:1040: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    }
   ],
   "source": [
    "dmtau = apt_pipe(data_path = [\n",
    "                              #r\"../3463766-dm tau\",\n",
    "                              #r\"../3486034-dm tau\",\n",
    "                              #r\"../3488473-dm tau\",\n",
    "                              r\"../problem_images\",\n",
    "                             ],\n",
    "                 markerfile   = './markers.txt', verbose=True)\n",
    "\n",
    "skip_file_list = [\n",
    "                 'dm tau_3463766_R_022.fits',  # PSF not round\n",
    "                 'dm tau_3463766_I_033.fits',  # PSF not round\n",
    "                 'dm tau_3463766_I_034.fits',  # PSF not round\n",
    "                 'dm tau_3463766_I_035.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_018.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_019.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_020.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_027.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_028.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_029.fits',  # PSF not round\n",
    "                 'dm tau_3488473_V_024.fits',  # Very extended bright emission. Crashed DAOStarFinder.\n",
    "                 'dm tau_3488473_V_075.fits',  # Very bright sky and not round PSF. Crashed DAOStarFinder.\n",
    "                 'dm tau_3488473_V_075.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_I_014.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_I_041.fits',  # Very elongated PSF.\n",
    "                 'dm tau_3488473_I_044.fits',  # Very elongated PSF.\n",
    "                 'dm tau_3488473_I_050.fits',  # High noise. Target not detected.\n",
    "                 'dm tau_3488473_I_053.fits',  # High noise. Target not detected.\n",
    "                 'dm tau_3488473_I_056.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_I_059.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_013.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_R_040.fits',  # Very elongated PSF. Crashed DAOStarFinder.\n",
    "                 'dm tau_3488473_R_046.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_049.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_052.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_055.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_058.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_V_012.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_V_015.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_V_039.fits',  # Very elongated PSF.\n",
    "                 'dm tau_3488473_V_042.fits',  # Very elongated PSF.\n",
    "                 'dm tau_3488473_V_045.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_V_048.fits',  # High noise. No reference star detected.\n",
    "                 'dm tau_3488473_V_054.fits',  # High noise. No reference star detected.\n",
    "                 'dm tau_3488473_V_057.fits',  # High noise. No reference star detected.\n",
    "                ]\n",
    "\n",
    "# preliminary run on target sources to obtain count range\n",
    "dmtau.do_apt(fwhm=5.0, fit_fwhm=True, use_fwhmfit=False, skip_file_list = skip_file_list)\n",
    "\n",
    "\n",
    "# Finding reference stars\n",
    "#dmtau.find_ref(fit_fwhm=True, fwhm=0.0, apt_sigmathreshold=100,\n",
    "#               refstar_file ='reference_star.txt',\n",
    "#               skip_file_list = skip_file_list)\n",
    "\n",
    "# Plotting preview images\n",
    "#dmtau.plot_preview(label_marker=False,\n",
    "#                   refstar_file='reference_star.txt',\n",
    "#                   simbad_file='refdb.txt'\n",
    "#                   )\n",
    "\n",
    "# doing aperture photometry\n",
    "dmtau.do_apt(fwhm=0.0, fit_fwhm=False, skip_file_list=skip_file_list)\n",
    "\n",
    "# Converting counts to magnitudes based on making query to SIMBAD\n",
    "dmtau.get_db(refstar_file = 'reference_star.txt', search_radii_arcsec = 15.0, \n",
    "             db='simbad', outrefdb_file='refdb_simbad.txt'\n",
    "             #db='vizier',  outrefdb_file='refdb_vizier.txt'\n",
    "            )\n",
    "# dmtau.magcal(refstar_file = 'reference_star.txt', search_radii_arcsec = 10.0)\n",
    "\n",
    "# export photometry\n",
    "dmtau.export_apt()\n",
    "\n",
    "\n",
    "\n",
    "#for marker in dmtau.marker_list:\n",
    "#    print(marker.label, ':', marker.band_list)\n",
    "#    for band in marker.band_list:\n",
    "#        print('Band : ', band)\n",
    "#        print(marker.jd_dict[band])\n",
    "#        print(marker.flux_dict[band])\n",
    "#        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Directory for input image\\ndata_path   = r\"../3488473-dm tau\"\\n\\n# Defining output directories\\noutput_path_dict = {}\\noutput_path_dict[\\'R\\'] = \\'./R_maps\\'\\noutput_path_dict[\\'V\\'] = \\'./V_maps\\'\\noutput_path_dict[\\'I\\'] = \\'./I_maps\\'\\n\\n# set if we want to do photometry for objects in the markers list\\ndophotometry     = True\\naperature_r_pix  = 10.0 # pixels\\nif (dophotometry == True):\\n    print(\"Will output photometry. Please define the output filename if not yet.\")\\n    photometry_file_dict = {}\\n    photometry_file_dict[\\'R\\'] = \\'./R_phot.txt\\'\\n    photometry_file_dict[\\'V\\'] = \\'./V_phot.txt\\'\\n    photometry_file_dict[\\'I\\'] = \\'./I_phot.txt\\'\\n    \\n\\n# Output ASCII list for FITS images which do not possess coordinate headers\\nf = open(\"NO_COORD_HEADER_list.txt\",\"w\")    \\n    \\nmarkerfile = \\'./markers.txt\\'\\n    \\n# Preparation ##############################################################\\nfor key in output_path_dict.keys():\\n    os.system(\\'rm -rf \\' + output_path_dict[key] )\\n    os.system(\\'mkdir \\'  + output_path_dict[key] )\\n    \\nif (dophotometry == True):\\n    for key in photometry_file_dict.keys():\\n        os.system(\\'rm -rf \\' + photometry_file_dict[key] )\\n        photo_file = open(photometry_file_dict[key],\"a+\")\\n        photo_file.write(\"# Data  target_name  JD  Counts\")\\n\\nnum_markers = 0\\ntry:\\n    marker_label = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=0, dtype=np.str)\\n    rah, ram, ras = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=(1,2,3) )\\n    decd, decm, decs = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=(4,5,6) )\\n    markerR, markerG, markerB = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=(7,8,9) )\\n    marker_alpha = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=10)\\n    marker_size  = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=11)\\n    \\n    ra  = ( rah + ram / 60.0 + ras / 3600.0 ) * 15.0\\n    if (decd > 0 ):\\n        dec = decd + decm / 60.0 + decs / 3600.0\\n    else:\\n        dec = decd - decm / 60.0 - decs / 3600.0\\n    num_markers = np.size(ra)\\n    \\nexcept:\\n    print(\\'No markers found\\')\\n    \\nimages     = os.listdir( data_path )\\nnum_images = len(images)\\n############################################################################\\n    \\n\\nfor i in range(0, num_images):\\n    image_name = images[i]\\n    \\n    info = image_name.strip(\\'.fits\\').split(\\'_\\')\\n    target_name    = info[0]\\n    directory_name = info[1]\\n    band           = info[2]\\n    epoch_idx      = info[3]\\n    \\n    # open FITS image\\n    hdulist = fits.open(data_path + \\'/\\' + image_name)\\n    try:\\n        crval1 = hdulist[0].header[\\'crval1\\']\\n        crval2 = hdulist[0].header[\\'crval2\\']\\n        date   = hdulist[0].header[\\'date-obs\\']\\n        jd     = hdulist[0].header[\\'jd\\']\\n    except:\\n        print(\\'Error, coordinate header of \\' + image_name + \\' does not exist.\\')\\n        f.write( image_name + \\'\\n\\' )\\n        continue\\n\\n    # loading image\\n    if (dophotometry == True):\\n        try:\\n            image = hdulist[0].data\\n            w = wcs.WCS(hdulist[0].header)\\n        except:\\n            print(\"Error loading image \" + directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n        \\n    \\n    fig = aplpy.FITSFigure(data_path + \\'/\\' + image_name)\\n    #fig.set_xaxis_coord_type(\\'longitude\\')\\n    #fig.set_yaxis_coord_type(\\'latitude\\')\\n    fig.axis_labels.hide()\\n    fig.show_grayscale(invert=False)\\n    \\n    # mark stars\\n    for j in range(0, num_markers):\\n        # plot markers in the png figure\\n        if (num_markers==1):\\n            x, y = ra, dec\\n            pixcrd2 = w.wcs_world2pix([ [x,y] ], 0)\\n            xpix = pixcrd2[0][0]\\n            ypix = pixcrd2[0][1]\\n            mcolor = (markerR, markerG, markerB)\\n            malpha = marker_alpha\\n            msize  = marker_size\\n            mlabel = str(marker_label)\\n        else:\\n            x, y = ra[j], dec[j]\\n            mcolor = (markerR[j], markerG[j], markerB[j])\\n            malpha = marker_alpha[j]\\n            msize = marker_size[j]\\n            mlabel = str(marker_label[j])\\n        \\n        fig.show_markers(\\n                         x, y, \\n                         edgecolor=mcolor, \\n                         # facecolor=facecolor[plot_id],\\n                         marker=\\'o\\', s=msize, \\n                         alpha=malpha\\n                        )\\n        fig.add_label(x, y, \\'  \\' + mlabel, \\n                      color=mcolor, fontsize=12, horizontalalignment=\\'left\\')\\n        \\n        # optionally, do aperture photometry\\n        if (dophotometry == True):              \\n            # making photometry\\n            xpix_min = int(round(xpix - aperature_r_pix*3) )\\n            xpix_max = int(round(xpix + aperature_r_pix*3) )\\n            ypix_min = int(round(ypix - aperature_r_pix*3) )\\n            ypix_max = int(round(ypix + aperature_r_pix*3) )\\n            try:\\n                print(directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n                crop = image[ypix_min:ypix_max, xpix_min:xpix_max].astype(float)\\n                \\n                # background subtraction\\n                crop -= np.median(crop)\\n                \\n                # estimate pixel statistics\\n                bkg_sigma = mad_std(crop)\\n                \\n                # find stars\\n                daofind = DAOStarFinder(fwhm= aperature_r_pix/2.0, threshold=5.*bkg_sigma)\\n                sources = daofind(crop)\\n\\n                \\n                mxcentroid_array = np.array( sources[\\'xcentroid\\'] )\\n                mycentroid_array = np.array( sources[\\'ycentroid\\'] )\\n                mpeak_array      = np.array( sources[\\'peak\\']      )\\n                \\n                if ( len(mpeak_array) > 0 ):\\n                    # Very ugly code here due to unfamiliar with python.\\n                    # need to update. Baobab, 2019.Dec.25\\n                    index_array = range(0, len(mpeak_array) )\\n                    xindex = np.max(np.where( mpeak_array == np.max(mpeak_array), index_array, -1))\\n                    yindex = np.max(np.where( mpeak_array == np.max(mpeak_array), index_array, -1))\\n                    mxcentroid = mxcentroid_array[xindex]\\n                    mycentroid = mycentroid_array[yindex]\\n                    positions = np.transpose((mxcentroid, mycentroid))\\n                    apertures = CircularAperture(positions, aperature_r_pix)\\n                    phot_table = aperture_photometry(crop, apertures)\\n                    counts    = phot_table[\\'aperture_sum\\'][0]\\n\\n                    try:\\n                        photo_file = open(photometry_file_dict[band],\"a+\")\\n                        outtext     = directory_name + \\'_\\' + band + \\'_\\' + epoch_idx + \\'  \\' +                                       str(marker_label) + \\'   \\' +                                       str(jd).strip() + \\'   \\' +                                       str(counts) + \\'   \\n\\'\\n                        photo_file.write(outtext)\\n                        photo_file.close()\\n                    except:\\n                        print(\\'Error opening output file. \\' + directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n                    \\n                else:\\n                    print(\"No source found in\" + directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n                    \\n                \\n            except:\\n                print(\"Error making photometry \" + directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n                \\n            \\n        \\n    # label date\\n    date_label = \\'Date : \\' + date + \\'  JD : \\' + str(jd).strip() + \\'   Band : \\' + band  \\n    fig.add_label(0.02, 0.95, date_label, relative=True, \\n                  color=(0,1,1,1),\\n                  fontsize=9, horizontalalignment=\\'left\\')\\n\\n\\n    \\n    outfig_name = directory_name + \\'_\\' + band + \\'_\\' + epoch_idx + \\'.png\\'\\n    \\n    fig.save(outfig_name)    \\n    os.system(\\'mv \\' + outfig_name + \\' \\' + output_path_dict[band] )\\n    \\n    # close FITS image\\n    hdulist.close()\\n    \\nf.close()\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Directory for input image\n",
    "data_path   = r\"../3488473-dm tau\"\n",
    "\n",
    "# Defining output directories\n",
    "output_path_dict = {}\n",
    "output_path_dict['R'] = './R_maps'\n",
    "output_path_dict['V'] = './V_maps'\n",
    "output_path_dict['I'] = './I_maps'\n",
    "\n",
    "# set if we want to do photometry for objects in the markers list\n",
    "dophotometry     = True\n",
    "aperature_r_pix  = 10.0 # pixels\n",
    "if (dophotometry == True):\n",
    "    print(\"Will output photometry. Please define the output filename if not yet.\")\n",
    "    photometry_file_dict = {}\n",
    "    photometry_file_dict['R'] = './R_phot.txt'\n",
    "    photometry_file_dict['V'] = './V_phot.txt'\n",
    "    photometry_file_dict['I'] = './I_phot.txt'\n",
    "    \n",
    "\n",
    "# Output ASCII list for FITS images which do not possess coordinate headers\n",
    "f = open(\"NO_COORD_HEADER_list.txt\",\"w\")    \n",
    "    \n",
    "markerfile = './markers.txt'\n",
    "    \n",
    "# Preparation ##############################################################\n",
    "for key in output_path_dict.keys():\n",
    "    os.system('rm -rf ' + output_path_dict[key] )\n",
    "    os.system('mkdir '  + output_path_dict[key] )\n",
    "    \n",
    "if (dophotometry == True):\n",
    "    for key in photometry_file_dict.keys():\n",
    "        os.system('rm -rf ' + photometry_file_dict[key] )\n",
    "        photo_file = open(photometry_file_dict[key],\"a+\")\n",
    "        photo_file.write(\"# Data  target_name  JD  Counts\")\n",
    "\n",
    "num_markers = 0\n",
    "try:\n",
    "    marker_label = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=0, dtype=np.str)\n",
    "    rah, ram, ras = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=(1,2,3) )\n",
    "    decd, decm, decs = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=(4,5,6) )\n",
    "    markerR, markerG, markerB = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=(7,8,9) )\n",
    "    marker_alpha = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=10)\n",
    "    marker_size  = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=11)\n",
    "    \n",
    "    ra  = ( rah + ram / 60.0 + ras / 3600.0 ) * 15.0\n",
    "    if (decd > 0 ):\n",
    "        dec = decd + decm / 60.0 + decs / 3600.0\n",
    "    else:\n",
    "        dec = decd - decm / 60.0 - decs / 3600.0\n",
    "    num_markers = np.size(ra)\n",
    "    \n",
    "except:\n",
    "    print('No markers found')\n",
    "    \n",
    "images     = os.listdir( data_path )\n",
    "num_images = len(images)\n",
    "############################################################################\n",
    "    \n",
    "\n",
    "for i in range(0, num_images):\n",
    "    image_name = images[i]\n",
    "    \n",
    "    info = image_name.strip('.fits').split('_')\n",
    "    target_name    = info[0]\n",
    "    directory_name = info[1]\n",
    "    band           = info[2]\n",
    "    epoch_idx      = info[3]\n",
    "    \n",
    "    # open FITS image\n",
    "    hdulist = fits.open(data_path + '/' + image_name)\n",
    "    try:\n",
    "        crval1 = hdulist[0].header['crval1']\n",
    "        crval2 = hdulist[0].header['crval2']\n",
    "        date   = hdulist[0].header['date-obs']\n",
    "        jd     = hdulist[0].header['jd']\n",
    "    except:\n",
    "        print('Error, coordinate header of ' + image_name + ' does not exist.')\n",
    "        f.write( image_name + '\\n' )\n",
    "        continue\n",
    "\n",
    "    # loading image\n",
    "    if (dophotometry == True):\n",
    "        try:\n",
    "            image = hdulist[0].data\n",
    "            w = wcs.WCS(hdulist[0].header)\n",
    "        except:\n",
    "            print(\"Error loading image \" + directory_name + '_' + band + '_' + epoch_idx)\n",
    "        \n",
    "    \n",
    "    fig = aplpy.FITSFigure(data_path + '/' + image_name)\n",
    "    #fig.set_xaxis_coord_type('longitude')\n",
    "    #fig.set_yaxis_coord_type('latitude')\n",
    "    fig.axis_labels.hide()\n",
    "    fig.show_grayscale(invert=False)\n",
    "    \n",
    "    # mark stars\n",
    "    for j in range(0, num_markers):\n",
    "        # plot markers in the png figure\n",
    "        if (num_markers==1):\n",
    "            x, y = ra, dec\n",
    "            pixcrd2 = w.wcs_world2pix([ [x,y] ], 0)\n",
    "            xpix = pixcrd2[0][0]\n",
    "            ypix = pixcrd2[0][1]\n",
    "            mcolor = (markerR, markerG, markerB)\n",
    "            malpha = marker_alpha\n",
    "            msize  = marker_size\n",
    "            mlabel = str(marker_label)\n",
    "        else:\n",
    "            x, y = ra[j], dec[j]\n",
    "            mcolor = (markerR[j], markerG[j], markerB[j])\n",
    "            malpha = marker_alpha[j]\n",
    "            msize = marker_size[j]\n",
    "            mlabel = str(marker_label[j])\n",
    "        \n",
    "        fig.show_markers(\n",
    "                         x, y, \n",
    "                         edgecolor=mcolor, \n",
    "                         # facecolor=facecolor[plot_id],\n",
    "                         marker='o', s=msize, \n",
    "                         alpha=malpha\n",
    "                        )\n",
    "        fig.add_label(x, y, '  ' + mlabel, \n",
    "                      color=mcolor, fontsize=12, horizontalalignment='left')\n",
    "        \n",
    "        # optionally, do aperture photometry\n",
    "        if (dophotometry == True):              \n",
    "            # making photometry\n",
    "            xpix_min = int(round(xpix - aperature_r_pix*3) )\n",
    "            xpix_max = int(round(xpix + aperature_r_pix*3) )\n",
    "            ypix_min = int(round(ypix - aperature_r_pix*3) )\n",
    "            ypix_max = int(round(ypix + aperature_r_pix*3) )\n",
    "            try:\n",
    "                print(directory_name + '_' + band + '_' + epoch_idx)\n",
    "                crop = image[ypix_min:ypix_max, xpix_min:xpix_max].astype(float)\n",
    "                \n",
    "                # background subtraction\n",
    "                crop -= np.median(crop)\n",
    "                \n",
    "                # estimate pixel statistics\n",
    "                bkg_sigma = mad_std(crop)\n",
    "                \n",
    "                # find stars\n",
    "                daofind = DAOStarFinder(fwhm= aperature_r_pix/2.0, threshold=5.*bkg_sigma)\n",
    "                sources = daofind(crop)\n",
    "\n",
    "                \n",
    "                mxcentroid_array = np.array( sources['xcentroid'] )\n",
    "                mycentroid_array = np.array( sources['ycentroid'] )\n",
    "                mpeak_array      = np.array( sources['peak']      )\n",
    "                \n",
    "                if ( len(mpeak_array) > 0 ):\n",
    "                    # Very ugly code here due to unfamiliar with python.\n",
    "                    # need to update. Baobab, 2019.Dec.25\n",
    "                    index_array = range(0, len(mpeak_array) )\n",
    "                    xindex = np.max(np.where( mpeak_array == np.max(mpeak_array), index_array, -1))\n",
    "                    yindex = np.max(np.where( mpeak_array == np.max(mpeak_array), index_array, -1))\n",
    "                    mxcentroid = mxcentroid_array[xindex]\n",
    "                    mycentroid = mycentroid_array[yindex]\n",
    "                    positions = np.transpose((mxcentroid, mycentroid))\n",
    "                    apertures = CircularAperture(positions, aperature_r_pix)\n",
    "                    phot_table = aperture_photometry(crop, apertures)\n",
    "                    counts    = phot_table['aperture_sum'][0]\n",
    "\n",
    "                    try:\n",
    "                        photo_file = open(photometry_file_dict[band],\"a+\")\n",
    "                        outtext     = directory_name + '_' + band + '_' + epoch_idx + '  ' + \\\n",
    "                                      str(marker_label) + '   ' + \\\n",
    "                                      str(jd).strip() + '   ' + \\\n",
    "                                      str(counts) + '   \\n'\n",
    "                        photo_file.write(outtext)\n",
    "                        photo_file.close()\n",
    "                    except:\n",
    "                        print('Error opening output file. ' + directory_name + '_' + band + '_' + epoch_idx)\n",
    "                    \n",
    "                else:\n",
    "                    print(\"No source found in\" + directory_name + '_' + band + '_' + epoch_idx)\n",
    "                    \n",
    "                \n",
    "            except:\n",
    "                print(\"Error making photometry \" + directory_name + '_' + band + '_' + epoch_idx)\n",
    "                \n",
    "            \n",
    "        \n",
    "    # label date\n",
    "    date_label = 'Date : ' + date + '  JD : ' + str(jd).strip() + '   Band : ' + band  \n",
    "    fig.add_label(0.02, 0.95, date_label, relative=True, \n",
    "                  color=(0,1,1,1),\n",
    "                  fontsize=9, horizontalalignment='left')\n",
    "\n",
    "\n",
    "    \n",
    "    outfig_name = directory_name + '_' + band + '_' + epoch_idx + '.png'\n",
    "    \n",
    "    fig.save(outfig_name)    \n",
    "    os.system('mv ' + outfig_name + ' ' + output_path_dict[band] )\n",
    "    \n",
    "    # close FITS image\n",
    "    hdulist.close()\n",
    "    \n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.vizier import Vizier\n",
    "from astropy.coordinates import SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_RAJ2000', '_DEJ2000', 'Vmag', 'Imag', 'Rmag']\n",
      "TableList with 53 tables:\n",
      "\t'0:I/252/out' with 5 column(s) and 3 row(s) \n",
      "\t'1:I/254/out' with 4 column(s) and 3 row(s) \n",
      "\t'2:I/267/out' with 4 column(s) and 3 row(s) \n",
      "\t'3:I/271/out' with 6 column(s) and 4 row(s) \n",
      "\t'4:I/272/m2000' with 4 column(s) and 3 row(s) \n",
      "\t'5:I/283A/npm2' with 4 column(s) and 2 row(s) \n",
      "\t'6:I/284/out' with 5 column(s) and 4 row(s) \n",
      "\t'7:I/289/out' with 4 column(s) and 3 row(s) \n",
      "\t'8:I/293/npm2cros' with 4 column(s) and 2 row(s) \n",
      "\t'9:I/297/out' with 5 column(s) and 5 row(s) \n",
      "\t'10:I/300/pm2000' with 4 column(s) and 3 row(s) \n",
      "\t'11:I/305/out' with 4 column(s) and 4 row(s) \n",
      "\t'12:I/312/sample' with 5 column(s) and 3 row(s) \n",
      "\t'13:I/317/sample' with 4 column(s) and 4 row(s) \n",
      "\t'14:I/319/xpm' with 5 column(s) and 3 row(s) \n",
      "\t'15:I/322A/out' with 4 column(s) and 3 row(s) \n",
      "\t'16:I/324/igsl3' with 4 column(s) and 5 row(s) \n",
      "\t'17:I/327/cmc15' with 4 column(s) and 4 row(s) \n",
      "\t'18:I/329/urat1' with 4 column(s) and 4 row(s) \n",
      "\t'19:I/337/gaia' with 4 column(s) and 4 row(s) \n",
      "\t'20:I/339/hsoy' with 5 column(s) and 3 row(s) \n",
      "\t'21:I/340/ucac5' with 5 column(s) and 3 row(s) \n",
      "\t'22:I/342/f3' with 4 column(s) and 3 row(s) \n",
      "\t'23:I/343/gps1' with 4 column(s) and 3 row(s) \n",
      "\t'24:I/345/gaia2' with 4 column(s) and 5 row(s) \n",
      "\t'25:I/347/gaia2dis' with 4 column(s) and 4 row(s) \n",
      "\t'26:II/246/out' with 5 column(s) and 4 row(s) \n",
      "\t'27:II/271A/patch2' with 5 column(s) and 2 row(s) \n",
      "\t'28:II/311/wise' with 4 column(s) and 3 row(s) \n",
      "\t'29:II/314/gcs8' with 4 column(s) and 17 row(s) \n",
      "\t'30:II/319/gcs9' with 4 column(s) and 17 row(s) \n",
      "\t'31:II/328/allwise' with 4 column(s) and 3 row(s) \n",
      "\t'32:II/336/apass9' with 4 column(s) and 3 row(s) \n",
      "\t'33:II/340/xmmom2_1' with 4 column(s) and 1 row(s) \n",
      "\t'34:II/349/ps1' with 4 column(s) and 9 row(s) \n",
      "\t'35:II/356/xmmom41s' with 4 column(s) and 1 row(s) \n",
      "\t'36:IV/34/epic' with 4 column(s) and 4 row(s) \n",
      "\t'37:VI/145/attitude' with 4 column(s) and 3 row(s) \n",
      "\t'38:B/mk/mktypes' with 4 column(s) and 2 row(s) \n",
      "\t'39:J/A+A/564/A79/pm_ucac4' with 4 column(s) and 2 row(s) \n",
      "\t'40:J/AJ/158/93/table2' with 4 column(s) and 4 row(s) \n",
      "\t'41:J/MNRAS/463/4210/ucac4rpm' with 4 column(s) and 2 row(s) \n",
      "\t'42:II/294/sdss7' with 4 column(s) and 5 row(s) \n",
      "\t'43:V/139/sdss9' with 4 column(s) and 5 row(s) \n",
      "\t'44:V/147/sdss12' with 4 column(s) and 5 row(s) \n",
      "\t'45:VI/135/table16' with 4 column(s) and 2 row(s) \n",
      "\t'46:J/ApJS/194/40/table4' with 5 column(s) and 1 row(s) \n",
      "\t'47:J/ApJS/194/40/table3' with 4 column(s) and 7 row(s) \n",
      "\t'48:J/ApJS/223/20/catalog' with 4 column(s) and 1 row(s) \n",
      "\t'49:J/AJ/141/189/table4' with 4 column(s) and 1 row(s) \n",
      "\t'50:J/MNRAS/486/1377/catalog' with 4 column(s) and 1 row(s) \n",
      "\t'51:I/348/catalog' with 4 column(s) and 1 row(s) \n",
      "\t'52:J/A+A/568/A51/stars' with 4 column(s) and 2 row(s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n",
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n"
     ]
    }
   ],
   "source": [
    "# columns = ['_RAJ2000', '_DEJ2000', 'Imag', 'Rmag', 'Vmag']\n",
    "columns = ['_RAJ2000', '_DEJ2000', 'Vmag', 'Imag', 'Rmag']\n",
    "\n",
    "columns = ['_RAJ2000', '_DEJ2000']\n",
    "for band in ['V', 'I', 'R']:\n",
    "    columns.append(band+'mag')\n",
    "\n",
    "#columns = ['_RAJ2000', '_DEJ2000', 'Imag']\n",
    "# columns.append('Imag')\n",
    "print(columns)\n",
    "\n",
    "customVizier = Vizier(columns=columns)\n",
    "result = customVizier.query_region(\n",
    "                             SkyCoord(ra=[68.35450458333332, 68.19259209571902, 68.58789394186934], dec=[17.927644722222222, 18.154446278314083, 18.31325656473308],\n",
    "                                      unit=(u.deg, u.deg),frame='icrs'), \n",
    "                             radius='10s'\n",
    "                            )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.699999809265137 0 R mag \n",
      "\n",
      "13.100000381469727 1 R mag \n",
      "\n",
      "12.78 0 R mag \n",
      "\n",
      "nan 0 V mag \n",
      "\n",
      "nan 0 I mag \n",
      "\n",
      "13.08 1 R mag \n",
      "\n",
      "nan 1 V mag \n",
      "\n",
      "nan 1 I mag \n",
      "\n",
      "13.527999877929688 0 V mag \n",
      "\n",
      "14.145000457763672 1 V mag \n",
      "\n",
      "13.489999771118164 0 I mag \n",
      "\n",
      "13.640000343322754 1 I mag \n",
      "\n",
      "13.470000267028809 0 R mag \n",
      "\n",
      "13.079999923706055 0 V mag \n",
      "\n",
      "14.170000076293945 1 R mag \n",
      "\n",
      "13.539999961853027 1 V mag \n",
      "\n",
      "13.425999641418457 0 V mag \n",
      "\n",
      "14.008000373840332 1 V mag \n",
      "\n",
      "13.380000114440918 0 V mag \n",
      "\n",
      "13.789999961853027 1 V mag \n",
      "\n",
      "12.838000297546387 0 R mag \n",
      "\n",
      "nan 0 V mag \n",
      "\n",
      "13.156999588012695 1 R mag \n",
      "\n",
      "nan 1 V mag \n",
      "\n",
      "12.699999809265137 0 R mag \n",
      "\n",
      "13.378000259399414 0 V mag \n",
      "\n",
      "13.100000381469727 1 R mag \n",
      "\n",
      "13.786999702453613 1 V mag \n",
      "\n",
      "13.472000122070312 0 V mag \n",
      "\n",
      "13.904000282287598 1 V mag \n",
      "\n",
      "13.508999824523926 0 V mag \n",
      "\n",
      "13.904000282287598 1 V mag \n",
      "\n",
      "13.489999771118164 0 I mag \n",
      "\n",
      "13.640000343322754 1 I mag \n",
      "\n",
      "13.470000267028809 0 R mag \n",
      "\n",
      "14.170000076293945 1 R mag \n",
      "\n",
      "13.472000122070312 0 V mag \n",
      "\n",
      "13.904000282287598 1 V mag \n",
      "\n",
      "12.699999809265137 0 R mag \n",
      "\n",
      "13.100000381469727 1 R mag \n",
      "\n",
      "13.571999549865723 0 V mag \n",
      "\n",
      "12.53499984741211 0 I mag \n",
      "\n",
      "13.529000282287598 1 V mag \n",
      "\n",
      "12.050000190734863 1 I mag \n",
      "\n",
      "13.472000122070312 0 V mag \n",
      "\n",
      "13.904000282287598 1 V mag \n",
      "\n",
      "nan 0 V mag \n",
      "\n",
      "13.472000122070312 0 V mag \n",
      "\n",
      "13.904000282287598 1 V mag \n",
      "\n",
      "13.472000122070312 0 V mag \n",
      "\n",
      "13.904000282287598 1 V mag \n",
      "\n",
      "13.472000122070312 0 V mag \n",
      "\n",
      "13.571999549865723 1 V mag \n",
      "\n",
      "13.101099967956543 0 R mag \n",
      "\n",
      "13.754500389099121 0 V mag \n",
      "\n",
      "nan 0 V mag \n",
      "\n",
      "11.899999618530273 1 V mag \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Warning: converting a masked element to nan.\n",
      "  \n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/ipykernel_launcher.py:24: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(result)):\n",
    "    for j in [0,1]:\n",
    "        try:\n",
    "            print(float(result[i]['Rmag'][j]),j, 'R mag \\n')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            print(float(result[i]['_R'][j]),j, r'x_R mag \\n')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            print(float(result[i]['Vmag'][j]),j, 'V mag \\n')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            print(float(result[i]['_V'][j]),j, r'x_V mag \\n')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            print(float(result[i]['Imag'][j]),j, 'I mag \\n')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            print(float(result[i]['_I'][j]),j, r'x_I mag \\n')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _q    _RAJ2000     _DEJ2000    _V  Rmag\n",
      "         deg          deg           mag \n",
      "---- ------------ ------------ ---- ----\n",
      "  28  68.35458900  17.92776400 Vmag 12.7\n",
      " 538  68.19264200  18.15451400 Vmag 13.1\n",
      "1235  68.58788900  18.31336200 Vmag 11.9 \n",
      "\n",
      " _q    _RAJ2000    _DEJ2000   _V \n",
      "         deg         deg         \n",
      "---- ----------- ----------- ----\n",
      "  29  68.3544800  17.9276800 Vmag\n",
      " 539  68.1926300  18.1544200 Vmag\n",
      "1236  68.5879900  18.3132100 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      "  44  68.35452000  17.92777000 Vmag\n",
      " 553  68.19257500  18.15452300 Vmag\n",
      "1250  68.58781700  18.31342000 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000   Vmag Imag  Rmag\n",
      "         deg          deg      mag  mag   mag \n",
      "---- ------------ ------------ ---- ---- -----\n",
      "  46  68.35455900  17.92766400   --   -- 12.78\n",
      " 554  68.19265100  18.15441200   --   -- 13.08\n",
      "1251  68.58798700  18.31324100   --   -- 12.30\n",
      "1251  68.58732600  18.31485300   --   --    -- \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    Vmag \n",
      "          deg           deg       mag  \n",
      "---- ------------- ------------- ------\n",
      "  47  68.354510556  17.927639167 13.528\n",
      " 555  68.192597500  18.154382778 14.145\n",
      "1252  68.587972222  18.313128611 13.662 \n",
      "\n",
      " _q   _RAJ2000     _DEJ2000    _V \n",
      "        deg          deg          \n",
      "--- ------------ ------------ ----\n",
      " 53  68.35455000  17.92773611 Vmag\n",
      "558  68.19269167  18.15440833 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V   Imag\n",
      "         deg          deg            mag \n",
      "---- ------------ ------------ ---- -----\n",
      "  54  68.35442500  17.92766200 Vmag 13.49\n",
      " 559  68.19257000  18.15440300 Vmag 13.64\n",
      "1256  68.58785000  18.31335900 Vmag 11.36\n",
      "1256  68.58828700  18.31074500 Vmag    -- \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    _V \n",
      "          deg           deg          \n",
      "---- ------------- ------------- ----\n",
      "  55  68.354493300  17.927637800 Vmag\n",
      " 560  68.192596500  18.154401400 Vmag\n",
      "1257  68.587973900  18.313129500 Vmag \n",
      "\n",
      " _q  _RAJ2000   _DEJ2000   _V \n",
      "       deg        deg         \n",
      "--- ---------- ---------- ----\n",
      " 57  68.354167  17.927500 Vmag\n",
      "562  68.192500  18.154167 Vmag \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    Vmag   Rmag \n",
      "          deg           deg       mag    mag  \n",
      "---- ------------- ------------- ------ ------\n",
      "  59  68.354493300  17.927637800 13.080 13.470\n",
      " 563  68.192596400  18.154401400 13.540 14.170\n",
      "1261  68.587275000  18.314933300 15.890     --\n",
      "1261  68.587973900  18.313129400 13.130 13.210\n",
      "1261  68.588286100  18.310744400     -- 19.160 \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    Vmag \n",
      "          deg           deg       mag  \n",
      "---- ------------- ------------- ------\n",
      "  62  68.354506190  17.927643489 13.426\n",
      " 566  68.192598966  18.154376213 14.008\n",
      "1264  68.587978263  18.313108046 13.457 \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    Vmag\n",
      "         deg          deg       mag \n",
      "---- ------------ ------------ -----\n",
      "  63  68.35456000  17.92766400 13.38\n",
      " 567  68.19265200  18.15441200 13.79\n",
      "1265  68.58798800  18.31324200 13.15\n",
      "1265  68.58732700  18.31485400    -- \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000   Vmag  Rmag \n",
      "         deg          deg      mag   mag  \n",
      "---- ------------ ------------ ---- ------\n",
      "  66  68.35449600  17.92764100   -- 12.838\n",
      " 570  68.19260400  18.15439700   -- 13.157\n",
      "1268  68.58797900  18.31312900   -- 12.663 \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      "  67  68.35449700  17.92765900 Vmag\n",
      " 571  68.19259100  18.15438500 Vmag\n",
      "1269  68.58778400  18.31064000 Vmag\n",
      "1269  68.58792900  18.31326400 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    Vmag  Rmag\n",
      "         deg          deg       mag   mag \n",
      "---- ------------ ------------ ------ ----\n",
      "  68  68.35450100  17.92768000 13.378 12.7\n",
      " 572  68.19258800  18.15439600 13.787 13.1\n",
      "1270  68.58803600  18.31314500 13.146 11.9 \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    Vmag \n",
      "          deg           deg       mag  \n",
      "---- ------------- ------------- ------\n",
      "  69  68.354503000  17.927640300 13.472\n",
      " 573  68.192603000  18.154402000 13.904\n",
      "1271  68.587977100  18.313125000 13.572 \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      "  70  68.35450300  17.92764000 Vmag\n",
      " 574  68.19260300  18.15440200 Vmag\n",
      " 574  68.19152100  18.15500700 Vmag\n",
      "1272  68.58797700  18.31312500 Vmag\n",
      "1272  68.58723300  18.31491900 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      "  71  68.35450600  17.92763800 Vmag\n",
      " 575  68.19262500  18.15438600 Vmag\n",
      "1273  68.58726900  18.31489000 Vmag\n",
      "1273  68.58798000  18.31311800 Vmag \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    Vmag \n",
      "          deg           deg       mag  \n",
      "---- ------------- ------------- ------\n",
      "  73  68.354504267  17.927665581 13.509\n",
      " 576  68.192588805  18.154391454 13.904\n",
      "1274  68.587274382  18.314923852     --\n",
      "1274  68.588031507  18.313142048 13.572 \n",
      "\n",
      " _q      _RAJ2000         _DEJ2000      _V \n",
      "           deg              deg            \n",
      "---- ---------------- ---------------- ----\n",
      "  77  68.354494455600  17.927607296800 Vmag\n",
      " 580  68.192592042500  18.154361350900 Vmag\n",
      "1278  68.588010203100  18.313108964600 Vmag\n",
      "1278  68.587245293900  18.314931540300 Vmag \n",
      "\n",
      " _q      _RAJ2000         _DEJ2000      _V   Imag\n",
      "           deg              deg              mag \n",
      "---- ---------------- ---------------- ---- -----\n",
      "  83  68.354506484000  17.927650890700 Vmag 13.49\n",
      " 586  68.192603631800  18.154396844700 Vmag 13.64\n",
      "1284  68.587958965500  18.313190234500 Vmag 11.36 \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    _V   Rmag \n",
      "          deg           deg            mag  \n",
      "---- ------------- ------------- ---- ------\n",
      "  84  68.354504199  17.927643655 Vmag 13.470\n",
      " 587  68.192601172  18.154396601 Vmag 14.170\n",
      "1285  68.587981347  18.313122207 Vmag 13.210 \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    Vmag \n",
      "          deg           deg       mag  \n",
      "---- ------------- ------------- ------\n",
      "  85  68.354464026  17.927591915 13.472\n",
      " 588  68.192590786  18.154402616 13.904\n",
      "1286  68.587970026  18.313211326 13.572 \n",
      "\n",
      " _q      _RAJ2000        _DEJ2000     _V \n",
      "           deg             deg           \n",
      "---- --------------- --------------- ----\n",
      "  86  68.35447885499  17.92765054000 Vmag\n",
      " 589  68.19257563394  18.15439835289 Vmag\n",
      "1287  68.58722121918  18.31495456144 Vmag \n",
      "\n",
      " _q       _RAJ2000          _DEJ2000      _V \n",
      "            deg               deg            \n",
      "---- ----------------- ----------------- ----\n",
      "  87  68.3545049556091  17.9276448532368 Vmag\n",
      " 590  68.1915493426616  18.1549633709441 Vmag\n",
      " 590  68.1926024434550  18.1543929417508 Vmag\n",
      "1288  68.5872431843990  18.3149168734906 Vmag\n",
      "1288  68.5879863248848  18.3131245728248 Vmag \n",
      "\n",
      " _q       _RAJ2000          _DEJ2000      _V \n",
      "            deg               deg            \n",
      "---- ----------------- ----------------- ----\n",
      "  94  68.3544939541100  17.9276061305800 Vmag\n",
      " 597  68.1925916391700  18.1543602950900 Vmag\n",
      "1295  68.5872454407200  18.3149319523400 Vmag\n",
      "1295  68.5880107452100  18.3131086219900 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V   Rmag\n",
      "         deg          deg            mag \n",
      "---- ------------ ------------ ---- -----\n",
      " 114  68.35450500  17.92767000 Vmag 12.70\n",
      " 612  68.19258900  18.15439000 Vmag 13.10\n",
      "1311  68.58803400  18.31314500 Vmag 11.90\n",
      "1311  68.58727700  18.31492400 Vmag    -- \n",
      "\n",
      " _q    _RAJ2000    _DEJ2000   Vmag   Imag \n",
      "         deg         deg      mag    mag  \n",
      "---- ----------- ----------- ------ ------\n",
      " 115  68.3547100  17.9277000 13.572 12.535\n",
      "1313  68.5880700  18.3131500 13.529 12.050 \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      " 121  68.35446900  17.92763400 Vmag\n",
      " 624  68.19256200  18.15441300 Vmag\n",
      "1319  68.58799200  18.31315400 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      " 123  68.35262700  17.92585600 Vmag\n",
      " 123  68.35297800  17.92622100 Vmag\n",
      " 123  68.35279700  17.92653100 Vmag\n",
      " 123  68.35446500  17.92766900 Vmag\n",
      " 626  68.19458500  18.15402700 Vmag\n",
      " 626  68.19509000  18.15412700 Vmag\n",
      " 626  68.19256600  18.15441700 Vmag\n",
      " 626  68.19149800  18.15505200 Vmag\n",
      " 626  68.19249500  18.15539100 Vmag\n",
      " 626  68.19296200  18.15696000 Vmag\n",
      "1321  68.58821400  18.31075000 Vmag\n",
      "1321  68.58815700  18.31132900 Vmag\n",
      "1321  68.58804000  18.31315700 Vmag\n",
      "1321  68.58946800  18.31358700 Vmag\n",
      "1321  68.58698100  18.31430600 Vmag\n",
      "1321  68.58728000  18.31496800 Vmag\n",
      "1321  68.58792300  18.31537500 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      " 126  68.35262700  17.92585600 Vmag\n",
      " 126  68.35297800  17.92622100 Vmag\n",
      " 126  68.35279700  17.92653100 Vmag\n",
      " 126  68.35446500  17.92766900 Vmag\n",
      " 629  68.19458500  18.15402700 Vmag\n",
      " 629  68.19509000  18.15412700 Vmag\n",
      " 629  68.19256600  18.15441700 Vmag\n",
      " 629  68.19149800  18.15505200 Vmag\n",
      " 629  68.19249500  18.15539100 Vmag\n",
      " 629  68.19296200  18.15696000 Vmag\n",
      "1324  68.58821400  18.31075000 Vmag\n",
      "1324  68.58815700  18.31132900 Vmag\n",
      "1324  68.58804000  18.31315700 Vmag\n",
      "1324  68.58946800  18.31358700 Vmag\n",
      "1324  68.58698100  18.31430600 Vmag\n",
      "1324  68.58728000  18.31496800 Vmag\n",
      "1324  68.58792300  18.31537500 Vmag \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    _V \n",
      "          deg           deg          \n",
      "---- ------------- ------------- ----\n",
      " 128  68.354482300  17.927612500 Vmag\n",
      " 632  68.192571000  18.154383300 Vmag\n",
      "1326  68.587999000  18.313130800 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    Vmag \n",
      "         deg          deg       mag  \n",
      "---- ------------ ------------ ------\n",
      " 135  68.35450000  17.92759000 13.472\n",
      " 634  68.19262500  18.15436000 13.904\n",
      "1328  68.58795700  18.31315200 13.572 \n",
      "\n",
      " _q   _RAJ2000     _DEJ2000   Vmag\n",
      "        deg          deg      mag \n",
      "--- ------------ ------------ ----\n",
      "137  68.35482823  17.92754252   -- \n",
      "\n",
      " _q      _RAJ2000        _DEJ2000     _V \n",
      "           deg             deg           \n",
      "---- --------------- --------------- ----\n",
      " 141  68.35449754000  17.92760785000 Vmag\n",
      " 640  68.19126243000  18.15527057000 Vmag\n",
      " 640  68.19259269000  18.15436177000 Vmag\n",
      " 640  68.19337135000  18.15421382000 Vmag\n",
      " 640  68.19147797000  18.15503081000 Vmag\n",
      "1334  68.58967889000  18.31156649000 Vmag\n",
      "1334  68.58800861000  18.31310827000 Vmag\n",
      "1334  68.58647798000  18.31556009000 Vmag\n",
      "1334  68.58724560000  18.31493195000 Vmag \n",
      "\n",
      " _q   _RAJ2000     _DEJ2000    _V \n",
      "        deg          deg          \n",
      "--- ------------ ------------ ----\n",
      "144  68.35435194  17.92762111 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    Vmag \n",
      "         deg          deg       mag  \n",
      "---- ------------ ------------ ------\n",
      " 175  68.35450300  17.92764000 13.472\n",
      " 670  68.19260300  18.15440200 13.904\n",
      "1365  68.58797700  18.31312500 13.572\n",
      "1365  68.58727700  18.31492400     -- \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      " 219  68.35450300  17.92764000 Vmag\n",
      " 720  68.19260300  18.15440200 Vmag\n",
      "1405  68.58797700  18.31312500 Vmag \n",
      "\n",
      " _q   _RAJ2000    _DEJ2000   _V \n",
      "        deg         deg         \n",
      "--- ----------- ----------- ----\n",
      "270  68.3545833  17.9277778 Vmag\n",
      "790  68.1925000  18.1544444 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    Vmag \n",
      "         deg          deg       mag  \n",
      "---- ------------ ------------ ------\n",
      " 396  68.35450306  17.92764028 13.472\n",
      "1021  68.19260306  18.15440194 13.904 \n",
      "\n",
      " _q       _RAJ2000          _DEJ2000      _V \n",
      "            deg               deg            \n",
      "---- ----------------- ----------------- ----\n",
      " 482  68.3544939541148  17.9276061305773 Vmag\n",
      "1158  68.1925916391658  18.1543602950901 Vmag\n",
      "1717  68.5872454407180  18.3149319523402 Vmag\n",
      "1717  68.5880107452109  18.3131086219916 Vmag \n",
      "\n",
      " _q     _RAJ2000      _DEJ2000    Vmag \n",
      "          deg           deg       mag  \n",
      "---- ------------- ------------- ------\n",
      " 507  68.354503100  17.927640300 13.472\n",
      "1747  68.587976900  18.313125000 13.572 \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      " 621  68.19152300  18.15498700 Vmag\n",
      " 621  68.19258895  18.15437024 Vmag\n",
      " 621  68.19470900  18.15623200 Vmag\n",
      "1317  68.58723200  18.31491700 Vmag\n",
      "1317  68.58796976  18.31314073 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      " 680  68.19152100  18.15500700 Vmag\n",
      " 680  68.19258100  18.15435800 Vmag\n",
      " 680  68.19471100  18.15620500 Vmag\n",
      "1374  68.58723300  18.31491800 Vmag\n",
      "1374  68.58798300  18.31311100 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      " 687  68.19152100  18.15500800 Vmag\n",
      " 687  68.19471100  18.15620500 Vmag\n",
      " 687  68.19258100  18.15435800 Vmag\n",
      "1376  68.58798300  18.31311100 Vmag\n",
      "1376  68.58723300  18.31491900 Vmag \n",
      "\n",
      " _q    _RAJ2000    _DEJ2000   _V \n",
      "         deg         deg         \n",
      "---- ----------- ----------- ----\n",
      " 718  68.1925800  18.1543600 Vmag\n",
      "1403  68.5879800  18.3131100 Vmag \n",
      "\n",
      " _q   _RAJ2000     _DEJ2000     Vmag    Rmag \n",
      "        deg          deg        mag     mag  \n",
      "--- ------------ ------------ ------- -------\n",
      "938  68.19264667  18.15450056 13.7545 13.1011 \n",
      "\n",
      " _q   _RAJ2000     _DEJ2000    _V \n",
      "        deg          deg          \n",
      "--- ------------ ------------ ----\n",
      "940  68.19264667  18.15450111 Vmag\n",
      "940  68.19264667  18.15450111 Vmag\n",
      "940  68.19264667  18.15450111 Vmag\n",
      "940  68.19264667  18.15450111 Vmag\n",
      "940  68.19264667  18.15450111 Vmag\n",
      "940  68.19264667  18.15450111 Vmag\n",
      "940  68.19264667  18.15450111 Vmag \n",
      "\n",
      " _q   _RAJ2000    _DEJ2000   _V \n",
      "        deg         deg         \n",
      "--- ----------- ----------- ----\n",
      "956  68.1915967  18.1549639 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      "1108  68.19257900  18.15435700 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000    _V \n",
      "         deg          deg          \n",
      "---- ------------ ------------ ----\n",
      "1199  68.19152306  18.15498694 Vmag \n",
      "\n",
      " _q       _RAJ2000          _DEJ2000      _V \n",
      "            deg               deg            \n",
      "---- ----------------- ----------------- ----\n",
      "1296  68.5880107452109  18.3131086219916 Vmag \n",
      "\n",
      " _q    _RAJ2000     _DEJ2000     Vmag  \n",
      "         deg          deg        mag   \n",
      "---- ------------ ------------ --------\n",
      "1600  68.58727556  18.31492417       --\n",
      "1600  68.58803222  18.31314528   11.900 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(result)):\n",
    "    print(result[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(float(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "10.0**x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
