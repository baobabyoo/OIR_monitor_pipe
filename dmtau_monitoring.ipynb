{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Plots from Original images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Conda environment\n",
    "# conda create --name terada2019 python=3.7\n",
    "# pip install --upgrade pip\n",
    "# pip install astropy scipy\n",
    "# pip install photutils\n",
    "# pip install jupyter matplotlib h5py aplpy pyregion PyAVM healpy\n",
    "# pip install astroquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "sys.path\n",
    "sys.path.append('./')\n",
    "\n",
    "import numpy as np\n",
    "from astropy.stats import mad_std\n",
    "\n",
    "from photutils import datasets\n",
    "from photutils import DAOStarFinder\n",
    "from photutils import aperture_photometry, CircularAperture\n",
    "\n",
    "import aplpy\n",
    "from astropy.io.fits import getdata\n",
    "from astropy import wcs\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "from astropy import constants as con\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.stats import biweight_location, biweight_scale\n",
    "from scipy.optimize import curve_fit\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.vizier import Vizier\n",
    "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('PDF')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some used mathematical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x, a, x0, sigma):\n",
    "    return a * np.exp(-(x - x0)**2 / (2 * sigma**2))\n",
    "\n",
    "\n",
    "\n",
    "def gaussfit(x, y):\n",
    "    '''\n",
    "    Function to perform 1D fitting of Gaussian profile.\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "    X      [numpy array]  : X coordiates\n",
    "    Y      [numpy array]  : Y values\n",
    "    \n",
    "    Return:\n",
    "    popt   [float list]   : [amplitude, centroid-X, and sigma]\n",
    "    '''\n",
    "    mean  = sum(x * y) / sum(y)\n",
    "    sigma = np.sqrt(sum( abs(y) * ( (x - mean)**2 ) ) / sum(y) )\n",
    "    \n",
    "    # initial guess\n",
    "    p0    = [max(y), mean, sigma]\n",
    "    try:\n",
    "        popt, pcov = curve_fit(gauss, x, y, p0=p0)\n",
    "    except:\n",
    "        print('Warning. Failed fitting Gaussian profile.')\n",
    "        popt = [0.0,0.0,0.0]\n",
    "    \n",
    "    return popt\n",
    "\n",
    "\n",
    "\n",
    "def angoff_degree(coord1, coord2):\n",
    "    '''\n",
    "    A function to evaluate angular offset (in degree units).\n",
    "    This function assumes that the declinations of the two sources\n",
    "    are not very different.\n",
    "    \n",
    "    Inputs:\n",
    "    coord1,2   [lists of float]  : [ra, dec] in degree unit.\n",
    "    \n",
    "    Return:\n",
    "    Angular offset in degree unit [float].\n",
    "    '''\n",
    "    \n",
    "    dec_off  =  coord1[1] - coord2[1]\n",
    "    mean_dec = (coord1[1] + coord2[1]) / 2.0\n",
    "    ra_off   = ( coord1[0] - coord2[0] ) * \\\n",
    "                 np.cos( mean_dec * (np.pi/180.0) )\n",
    "    \n",
    "    off      = np.sqrt( ra_off**2.0 + dec_off**2.0 )\n",
    "    return off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format of marker file:\n",
    "\n",
    "name, ra_h ra_m ra_s dec_d dec_m dec_s  R:0-1 G:0-1 B:0-1 alpha  size\n",
    "\n",
    "dm_tau  04 33 48.7335659850  +18 10 09.974471722  1 0.2 0.2 1.0 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format of reference star file\n",
    "\n",
    "name, ra dec R:0-1 G:0-1 B:0-1 alpha size band jd count file_name\n",
    "\n",
    "1_8 68.61225456763495 18.265153228501678 1 0 1 1 30 I 2458491.56799249 82873.91795331985 dm tau_3463766_I_015.fits\n",
    "\n",
    "1_10 68.58791728147689 18.313321866312478 1 0 1 1 30 I 2458491.56799249 157532.68915795215 dm tau_3463766_I_015.fits\n",
    "\n",
    "1_12 68.55803592095405 18.35926561721569 1 0 1 1 30 I 2458491.56799249 77123.45560573619 dm tau_3463766_I_015.fits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a aperture photometry pipeline class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommended strategy of running this pipeline:\n",
    "\n",
    "1. First produce preview images for all images, and then produce a skip_file_lis after visual inspect.\n",
    "\n",
    "2. Run the rest of the procedures, incorporating skip_file_lis to save time and avoid crashing DAOstarfinder and photoutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class marker:\n",
    "    '''\n",
    "    Class for marker objects.\n",
    "    \n",
    "    It can also be used as objects to store information about aperture photometry,\n",
    "    using the attributes :\n",
    "    \n",
    "\n",
    "    band_list [list of string] : Recording the information of used bands.\n",
    "    \n",
    "    jd_dict   [dictory of (list of double), key: band] : to store jd dates for\n",
    "                                                         measurements at certain bands.\n",
    "    \n",
    "    flux_dict [dictory of (list of double), key: band] : to store fluxes (or counts) for\n",
    "                                                         measurements at certain bands\n",
    "                                                         \n",
    "    mag_dict [dictory of (list of double), key: band] : to store magnitudes for\n",
    "                                                         measurements at certain bands\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, label='unknown_marker'):\n",
    "        self.label = label\n",
    "        self.ra    = 0.0\n",
    "        self.dec   = 0.0\n",
    "        self.color = (0,0,0)\n",
    "        self.alpha = 1.0\n",
    "        self.size  = 1.0\n",
    "        \n",
    "        self.band_list   = []\n",
    "        self.jd_dict     = {}\n",
    "        self.flux_dict   = {}\n",
    "        self.mag_dict    = {}\n",
    "        self.magerr_dict = {}\n",
    "    \n",
    "    def __del__(self):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "\n",
    "class apt_pipe:\n",
    "    '''\n",
    "    Class for apeture photometry pipeline.\n",
    "    \n",
    "    History:\n",
    "    1. Basic version developed.  (Baobab Liu, 2019, Dec.07)\n",
    "    \n",
    "    2 Required Conda enviornment:\n",
    "    # conda create --name terada2019 python=3.7\n",
    "    # pip install --upgrade pip\n",
    "    # pip install astropy scipy\n",
    "    # pip install photutils\n",
    "    # pip install jupyter matplotlib h5py aplpy pyregion PyAVM healpy\n",
    "    \n",
    "    '''\n",
    "\n",
    "    \n",
    "    def __init__(self, data_path = './',\n",
    "                 markerfile   = './markers.txt',\n",
    "                 ascii_report = './ascii_report.txt',\n",
    "                 verbose      = False\n",
    "                ):\n",
    "        '''\n",
    "        Initializer of the class.\n",
    "        It first load image names from the FITS image directory.\n",
    "        Then it checks the integrity of the FITS image headers,\n",
    "        and dump report to an ASCII file.\n",
    "        Finally, it loads the coordinate of the markerfile if any.\n",
    "        \n",
    "        \n",
    "        \n",
    "        Keywords:\n",
    "        \n",
    "        data_path [string] or list of [string] : Default: './'.\n",
    "                  Can either load data from one specified directory or a list of \n",
    "                  specified directory.\n",
    "        \n",
    "        markerfile [string]   : File name of one or a list of markers.\n",
    "                  Format :\n",
    "                  name, ra_h ra_m ra_s dec_d dec_m dec_s R:0-1 G:0-1 B:0-1 alpha size\n",
    "                  Example :\n",
    "                      dm_tau  04 33 48.7335659850 +18 10 09.974471722   1 0.2 0.2 1.0 2.0\n",
    "                      test    04 33 48.7335659850  +18 10 49.974471722  0.0 1.0 0 1.0 30.0\n",
    "        \n",
    "        ascii_report [string] :\n",
    "        \n",
    "        verbose   [True]      : Verbosely dump the status of the data.\n",
    "        \n",
    "        \n",
    "        \n",
    "        Methods:\n",
    "        \n",
    "        plot_preview          : Plotting preview figures for FITS images under the data_path(s)\n",
    "        \n",
    "        do_apt                : Do aperture photometry for loaded marker(s).\n",
    "        \n",
    "        \n",
    "        '''\n",
    "                                        \n",
    "        self.data_path  = data_path\n",
    "        self.markerfile = markerfile\n",
    "        self.verbose    = verbose\n",
    "        self.num_images = 0\n",
    "        self.num_markers = 0\n",
    "        self.ascii_report = ascii_report\n",
    "        \n",
    "        # initialize variables\n",
    "        os.system('rm -rf ' + ascii_report)\n",
    "        F_report = open(ascii_report,\"w+\")\n",
    "        self.data_path_list  = []\n",
    "        self.num_data_path   = 0\n",
    "        self.filterlist      = []\n",
    "        self.images          = []\n",
    "        self.path_dict       = {}\n",
    "        self.band_dict       = {}\n",
    "        self.date_dict       = {}\n",
    "        self.jd_dict         = {}\n",
    "        self.countrange_dict = {} # storing [max(count), min(count)] for individual image_name\n",
    "        self.fwhm_dict       = {}\n",
    "        self.marker_list     = []\n",
    "        \n",
    "        # load image names\n",
    "        if ( type(data_path) == str ):\n",
    "            self.data_path_list.append(data_path)\n",
    "            self.num_data_path = 1\n",
    "            if (verbose==True):\n",
    "                print('Loading FITS image from single directory : ' + data_path)\n",
    "                \n",
    "        if ( type(data_path) == list ):\n",
    "            self.data_path_list.extend(data_path)\n",
    "            self.num_data_path = len( self.data_path_list )\n",
    "            if (verbose==True):\n",
    "                for data_idx in range(0, len(data_path) ):\n",
    "                    print('Loading FITS image from : ' + data_path[data_idx])\n",
    "                            \n",
    "        try:\n",
    "            for data_idx in range(0, self.num_data_path):\n",
    "                self.images.extend(  os.listdir( self.data_path_list[data_idx] )  )\n",
    "                temp_names = os.listdir( self.data_path_list[data_idx] )\n",
    "                # self.num_images = self.num_images + len( temp_names )\n",
    "                for name in temp_names:\n",
    "                    self.path_dict[name] = self.data_path_list[data_idx]\n",
    "            self.num_images = len( self.images )\n",
    "                \n",
    "            if ( verbose == True ):\n",
    "                print('##############################################################')\n",
    "                print('Processing ' + str(self.num_images).strip() + ' images \\n')\n",
    "                print('##############################################################')\n",
    "        except:\n",
    "            print('No image found')\n",
    "            \n",
    "            \n",
    "        # checking integrity of FITS headers\n",
    "        F_report.write('FITS header integrity: \\n')\n",
    "        for i in range(0, self.num_images):\n",
    "            \n",
    "            image_name = self.images[i]\n",
    "            hdulist = fits.open( self.path_dict[image_name] + '/' + image_name)\n",
    "            try:\n",
    "                crval1 = hdulist[0].header['crval1']\n",
    "                crval2 = hdulist[0].header['crval2']\n",
    "            except:\n",
    "                if (verbose == True ):\n",
    "                    print('Warning, coordinate header of ' + image_name + ' does not exist.')\n",
    "                F_report.write( image_name + ' has no coordinate header \\n' )\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                date   = hdulist[0].header['date-obs']\n",
    "                jd     = hdulist[0].header['jd']\n",
    "                self.date_dict[image_name] = date\n",
    "                self.jd_dict[image_name]  = jd\n",
    "            except:\n",
    "                if (verbose == True ):\n",
    "                    print('Warning. Observing date of ' + image_name + ' is not known.')\n",
    "                F_report.write( image_name + ' has no observing time information \\n' )\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                band   = hdulist[0].header['filter']\n",
    "                if (band not in self.filterlist):\n",
    "                    self.filterlist.append(band)\n",
    "                self.band_dict[image_name] = band\n",
    "            except:\n",
    "                if (verbose == True ):\n",
    "                    print('Warning. Filter name of ' + image_name + ' does not exist.')\n",
    "                F_report.write( image_name + ' has unknown filter band. \\n' )\n",
    "                continue\n",
    "                \n",
    "        F_report.write('\\n')\n",
    "        \n",
    "        # load markers if there is\n",
    "        try:\n",
    "            marker_label     = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=0, dtype=np.str)\n",
    "            rah              = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=1 )\n",
    "            ram              = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=2 )\n",
    "            ras              = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=3 )\n",
    "            decd             = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=4 )\n",
    "            decm             = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=5 )\n",
    "            decs             = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=6 )\n",
    "            markerR          = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=7 )\n",
    "            markerG          = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=8 )\n",
    "            markerB          = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=9 )\n",
    "            marker_alpha     = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=10)\n",
    "            marker_size      = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=11)\n",
    "                        \n",
    "            ra  = ( rah + ram / 60.0 + ras / 3600.0 ) * 15.0\n",
    "            dec_sign = np.where( (decd>0), 1.0, -1.0)\n",
    "            dec      = decd + dec_sign * decm / 60.0 + dec_sign * decs / 3600.0\n",
    "                \n",
    "            self.num_markers = np.size(ra)\n",
    "            if (verbose == True):\n",
    "                print('Number of markers : ' + str(self.num_markers).strip() )\n",
    "                \n",
    "            # loading to marker objects\n",
    "            for mid in range(0, self.num_markers):\n",
    "                if (self.num_markers > 1):\n",
    "                    temp_marker       = marker(label=marker_label[mid])\n",
    "                    temp_marker.ra    = ra[mid] \n",
    "                    temp_marker.dec   = dec[mid]\n",
    "                    temp_marker.color = (markerR[mid], markerG[mid], markerB[mid])\n",
    "                    temp_marker.alpha = (marker_alpha[mid])\n",
    "                    temp_marker.size  = (marker_size[mid])\n",
    "                    self.marker_list.append(temp_marker)\n",
    "                else:\n",
    "                    temp_marker       = marker(label=marker_label)\n",
    "                    temp_marker.ra    = ra\n",
    "                    temp_marker.dec   = dec\n",
    "                    temp_marker.color = (markerR, markerG, markerB)\n",
    "                    temp_marker.alpha = (marker_alpha)\n",
    "                    temp_marker.size  = (marker_size)\n",
    "                    self.marker_list.append(temp_marker)\n",
    "            \n",
    "        except:\n",
    "            if (verbose == True):\n",
    "                print('No markers loaded')\n",
    "\n",
    "        # Dumping more information ot the report\n",
    "        # filters\n",
    "        F_report.write('Used filters: \\n')\n",
    "        outstring = ' '\n",
    "        for tempstr in self.filterlist:\n",
    "            outstring = outstring + tempstr + ' '\n",
    "        F_report.write(outstring + '\\n')\n",
    "        \n",
    "        F_report.close()\n",
    "\n",
    "        \n",
    "        \n",
    "    def __del__(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    #####################################################################################\n",
    "    FUNCTION\n",
    "    #####################################################################################\n",
    "    '''    \n",
    "    \n",
    "    def background_sub(self, image, option='median'):\n",
    "        '''\n",
    "        Function to subtract background from a image.\n",
    "        \n",
    "        \n",
    "        Keyword :\n",
    "        \n",
    "           option [str]  :\n",
    "              median : subtracting the median value from an image (Default)\n",
    "        \n",
    "        \n",
    "        Return  :\n",
    "           Background subtracted image\n",
    "           \n",
    "        '''\n",
    "        \n",
    "        if ( option == 'median' ):\n",
    "            image = image - np.median(image) \n",
    "        \n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_fwhm(self, image, wcs, ra, dec, \n",
    "                 background_sub_option,\n",
    "                 naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y\n",
    "                ):\n",
    "        '''\n",
    "        From a given image with wcs object (astropy), perform Gaussian fittings to obtain\n",
    "        the fwhm of the point spread function.\n",
    "        The present version fits fwhm in horizontal and vertical directions,\n",
    "        and then return the larger one.\n",
    "        \n",
    "        Inputs :\n",
    "        \n",
    "        image    [numpy array]     : An input 2D image.\n",
    "        \n",
    "        wcs      [astropy wcs]     : An astropy wcs object constructed from the FITS image header.\n",
    "        \n",
    "        ra       [float]           : R.A. in degree unit.\n",
    "        \n",
    "        dec      [float]           : Decl. in degree unit.\n",
    "        \n",
    "        fwhm     [float]           : full width at half maximum of the point spread function.\n",
    "        \n",
    "        background_sub_option [str]: Keyword to specify how background subtraction is made.\n",
    "                                     See description in function: background_sub.\n",
    "        \n",
    "        naxis1,2   [int]           : Dimension of the input image.\n",
    "        \n",
    "        cropbox_halfsize_x,y [int] : Size of the cropped image to measure aperture photometry from,\n",
    "                                     in pixel unit.\n",
    "        \n",
    "        \n",
    "        Return :\n",
    "        \n",
    "        fwhm    [float]           : aperture photometry measurement in image flux/pixel unit.\n",
    "        '''\n",
    "        \n",
    "        fwhm1 = 0.0\n",
    "        fwhm2 = 0.0\n",
    "        \n",
    "        # load pixel coordinates\n",
    "        pixcrd2 = wcs.wcs_world2pix([ [ra,dec] ], 0)\n",
    "        xpix = pixcrd2[0][0]\n",
    "        ypix = pixcrd2[0][1]\n",
    "        xpix_min = int(round(xpix - cropbox_halfsize_x) )\n",
    "        xpix_max = int(round(xpix + cropbox_halfsize_x) )\n",
    "        ypix_min = int(round(ypix - cropbox_halfsize_y) )\n",
    "        ypix_max = int(round(ypix + cropbox_halfsize_y) )\n",
    "\n",
    "        if (xpix_min < 0): xpix_min = 0\n",
    "        if (ypix_min < 0): ypix_min = 0\n",
    "        if (xpix_max > (naxis1-1) ): xpix_max = (naxis1-1)\n",
    "        if (ypix_max > (naxis2-1) ): ypix_max = (naxis2-1)\n",
    "\n",
    "        # crop the image to speed up the source finding\n",
    "        crop = image[ypix_min:(ypix_max+1), xpix_min:(xpix_max+1)].astype(float)\n",
    "\n",
    "        # do background subtraction from the crop\n",
    "        crop = self.background_sub(crop, option=background_sub_option)\n",
    "        \n",
    "        naxis1 = xpix_max - xpix_min + 1\n",
    "        naxis2 = ypix_max - ypix_min + 1\n",
    "        \n",
    "        # do fitting in axis1\n",
    "        x_array = np.arange(0, naxis1, 1)\n",
    "        if ( (naxis2 % 2) == 1 ):\n",
    "            y_array = crop[ int( (naxis2-1)/2), :]\n",
    "        else:\n",
    "            y_array = ( crop[ int( (naxis2)/2 ), :] + crop[ int( (naxis2-2)/2 ), :] ) / 2.0\n",
    "        index = ~(np.isnan(x_array) | np.isnan(y_array))\n",
    "        parms = gaussfit(x_array[index], y_array[index])\n",
    "        fwhm1 = parms[2] * 2.35\n",
    "        \n",
    "        # do fitting in axis2\n",
    "        x_array = np.arange(0, naxis2, 1)\n",
    "        if ( (naxis1 % 2) == 1 ):\n",
    "            y_array = crop[:, int( (naxis1-1)/2) ]\n",
    "        else:\n",
    "            y_array = ( crop[:, int( (naxis1)/2 ) ] + crop[:, int( (naxis1-2)/2 ) ] ) / 2.0\n",
    "        index = ~(np.isnan(x_array) | np.isnan(y_array))\n",
    "        parms = gaussfit(x_array[index], y_array[index])      \n",
    "        fwhm2 = parms[2] * 2.35\n",
    "        \n",
    "        fwhmlist = []\n",
    "        for value in [fwhm1, fwhm2]:\n",
    "            if (np.isfinite(value) == True):\n",
    "                if (value > 0):\n",
    "                    fwhmlist.append(value)\n",
    "                    \n",
    "        if ( len(fwhmlist) > 0 ):\n",
    "            fwhm = np.max(fwhmlist)\n",
    "        else:\n",
    "            fwhm = 0.0\n",
    "        \n",
    "        return fwhm\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_count(self, image, wcs, ra, dec, fwhm, \n",
    "                  background_sub_option, apt_sigmathreshold,\n",
    "                  naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y):\n",
    "        '''\n",
    "        From a given image with wcs object (astropy), \n",
    "        using aperture photometry to measure counts of a specific star around the location \n",
    "        ra and dec, assuming a certain fwhm for the PSF\n",
    "        \n",
    "        Inputs :\n",
    "        \n",
    "        image    [numpy array]     : An input 2D image.\n",
    "        \n",
    "        wcs      [astropy wcs]     : An astropy wcs object constructed from the FITS image header.\n",
    "        \n",
    "        ra       [float]           : R.A. in degree unit.\n",
    "        \n",
    "        dec      [float]           : Decl. in degree unit.\n",
    "        \n",
    "        fwhm     [float]           : full width at half maximum of the point spread function.\n",
    "        \n",
    "        background_sub_option [str]: Keyword to specify how background subtraction is made.\n",
    "                                     See description in function: background_sub.\n",
    "                                     \n",
    "        apt_sigmathreshold [float] : Identify stars which are brighter than the specified\n",
    "                                        sigma threshold.\n",
    "        \n",
    "        naxis1,2   [int]           : Dimension of the input image.\n",
    "        \n",
    "        cropbox_halfsize_x,y [int] : Size of the cropped image to measure aperture photometry from,\n",
    "                                     in pixel unit.\n",
    "        \n",
    "        \n",
    "        Return :\n",
    "        \n",
    "        count    [float]           : aperture photometry measurement in image flux/pixel unit.\n",
    "        \n",
    "        '''\n",
    "\n",
    "        # Initializing the mearurement\n",
    "        count = 0\n",
    "        \n",
    "        # load pixel coordinates\n",
    "        pixcrd2 = wcs.wcs_world2pix([ [ra,dec] ], 0)\n",
    "        xpix = pixcrd2[0][0]\n",
    "        ypix = pixcrd2[0][1]\n",
    "        xpix_min = int(round(xpix - cropbox_halfsize_x) )\n",
    "        xpix_max = int(round(xpix + cropbox_halfsize_x) )\n",
    "        ypix_min = int(round(ypix - cropbox_halfsize_y) )\n",
    "        ypix_max = int(round(ypix + cropbox_halfsize_y) )\n",
    "\n",
    "        if (xpix_min < 0): xpix_min = 0\n",
    "        if (ypix_min < 0): ypix_min = 0\n",
    "        if (xpix_max > (naxis1-1) ): xpix_max = (naxis1-1)\n",
    "        if (ypix_max > (naxis2-1) ): ypix_max = (naxis2-1)\n",
    "\n",
    "        # crop the image to speed up the source finding\n",
    "        crop = image[ypix_min:(ypix_max+1), xpix_min:(xpix_max+1)].astype(float)\n",
    "\n",
    "        # do background subtraction from the crop\n",
    "        crop = self.background_sub(crop, option=background_sub_option)\n",
    "\n",
    "        # estimate robust standard deviation from the cropped image\n",
    "        bkg_sigma = mad_std(crop)\n",
    "\n",
    "        # find stars\n",
    "        daofind = DAOStarFinder(fwhm=fwhm, threshold=apt_sigmathreshold*bkg_sigma)\n",
    "        sources = daofind(crop)\n",
    "        try:\n",
    "            mxcentroid_array = np.array( sources['xcentroid'] )\n",
    "            mycentroid_array = np.array( sources['ycentroid'] )\n",
    "            mpeak_array      = np.array( sources['peak']      )\n",
    "            num_sources      = len(mpeak_array)\n",
    "        except:\n",
    "            num_sources      = 0\n",
    "\n",
    "        # Outputting measurements\n",
    "        if ( num_sources > 0 ):\n",
    "            sortidx    = np.argsort(mpeak_array)\n",
    "            maxidx     = sortidx[-1]\n",
    "            mxcentroid = mxcentroid_array[maxidx]\n",
    "            mycentroid = mycentroid_array[maxidx]\n",
    "            positions = np.transpose((mxcentroid, mycentroid))\n",
    "            apertures = CircularAperture(positions, fwhm*2.0)\n",
    "            phot_table = aperture_photometry(crop, apertures)\n",
    "            count     = phot_table['aperture_sum'][0]\n",
    "               \n",
    "        return count\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    #####################################################################################\n",
    "    METHOD\n",
    "    #####################################################################################\n",
    "    '''    \n",
    "            \n",
    "    def find_ref(self, refimg_list=[], countrange=[0.0, 0.0],\n",
    "                crop_size=1.0/30.0,\n",
    "                background_sub_option = 'median',\n",
    "                apt_sigmathreshold    = 5.0,\n",
    "                fit_fwhm              = True,\n",
    "                fwhm                  = 0.0,\n",
    "                refstar_file          = 'reference_star.txt',\n",
    "                 refstar_color        = (1, 0, 1),\n",
    "                 refstar_symsize      = 30,\n",
    "                skip_file_list        = []\n",
    "                ):\n",
    "        '''\n",
    "        Method to find reference stars.\n",
    "        It looks for stars in a list of images, excluding those which are brighter or dimmer\n",
    "        than the specified countrange, further excluding those which are already in the \n",
    "        markers_list (i.e., those separated from markers by less than one PSF-fwhm),\n",
    "        and then either store to ASCII output,\n",
    "        which can be loaded by the cal_ref method.\n",
    "        \n",
    "        \n",
    "        Keywords :\n",
    "        \n",
    "        refimg_list   [str list]   : A list of image path+name for identifying reference stars.\n",
    "                                     Will use all images if this is not specified.\n",
    "                                    \n",
    "        countrange    [float list] : [count_min, count_max], in image brightness unit. If set,\n",
    "                                     then only use reference stars of which the counts are within\n",
    "                                     the specified range. Otherwise, if \n",
    "                                     (i) refimg_list is specified, will use all found stars\n",
    "                                         (except those in the input marker list).\n",
    "                                     (ii) refimg_list is not specified. In this case, if the \n",
    "                                          countrange_dict for individual images have been evaluated \n",
    "                                          by a preliminary run of do_apt and were stored, then we \n",
    "                                          will use the stored values. It is presently defined as\n",
    "                                          [\n",
    "                                           self.countrange_dict{image_name}[0]/2.5, \n",
    "                                           self.countrange_dict{image_name}[0]*2.5\n",
    "                                          ], i.e., using reference stars in approximately +/1 mag\n",
    "                                          range as compared with all target sources.\n",
    "                                          Otherwise, will use all found\n",
    "                                          stars (except those in the input marker list).\n",
    "                                          \n",
    "        crop_size      [float] : size of the crops for making aperture photometry.\n",
    "                                 Default is 1/30 of the entire image. Need to enlarge the crop\n",
    "                                 if the size is smaller than two times the fwhm (see the fwhm item).\n",
    "                                          \n",
    "        background_sub_option [str]: Keyword to specify how background subtraction is made.\n",
    "                                     See description in function: background_sub.\n",
    "                                     \n",
    "        apt_sigmathreshold    [float] : Identify stars which are brighter than the specified\n",
    "                                        sigma threshold. Default: 5-sigma.\n",
    "\n",
    "        fit_fwhm         [True/False] : Specify whether or not we will fit fwhm from reference\n",
    "                                        stars. If not, will use the specified fwhm \n",
    "                                        (see the fwhm item).\n",
    "                                        If true, and if fwhm is set to 0.0, then we will use the\n",
    "                                        fwhm derived from the preliminary run of do_apt when finding\n",
    "                                        candidate reference stars.\n",
    "                                        \n",
    "        fwhm                  [float] : fwhm of the point-spread-function in units of pixels.\n",
    "                                        If fit_fwhm=False, then this parameter has to be specified.\n",
    "                                        Otherwise, this method will imply report error.\n",
    "                                        If fit_fwhm=True, this fwhm will be used only during initial \n",
    "                                        search of potential sources.\n",
    "                                        \n",
    "        refstar_file          [str]   : Filename to ASCII output the identified reference stars.\n",
    "        \n",
    "        skip_file_list  [list of str] : A list of filename that we do not want to find reference stars\n",
    "                                        from, for example, for some epochs which the PSFs are not round.\n",
    "                                        This helps since the phoutils package is very slow when examining\n",
    "                                        such images. And such images are not useful anyway.\n",
    "        '''\n",
    "        \n",
    "        ##### Initial preparation - - - - - - - - - - - - - - - - - - - - - \n",
    "        \n",
    "        from_input_list = True\n",
    "        \n",
    "        \n",
    "        F_report = open(self.ascii_report,\"a+\")\n",
    "        F_report.write('\\n')\n",
    "        F_report.write('Finding reference stars: \\n')\n",
    "        F_report.write('(only FITS images with compte header information are processed.) \\n')\n",
    "        \n",
    "        F_refstar = open(refstar_file,\"w+\")\n",
    "        F_refstar.write(\"# name, ra dec R:0-1 G:0-1 B:0-1 alpha size band jd count file_name \\n\")\n",
    "        \n",
    "        \n",
    "        if (fit_fwhm == False):\n",
    "            if (fwhm == 0.0):\n",
    "                print('No way to determine fwhm. Return.')\n",
    "                F_report.write('No way to determine fwhm. Returned. \\n')\n",
    "                F_report.close()\n",
    "                return\n",
    "        \n",
    "        if ( len(refimg_list) == 0 ):\n",
    "            from_input_list = False\n",
    "            if (self.verbose == True):\n",
    "                print(\"No input reference image names. Searching for reference stars from all input images.\")\n",
    "            \n",
    "            for i in range(0, self.num_images):\n",
    "                image_name  = self.images[i]\n",
    "                dirstr     = self.path_dict[image_name] + '/' + image_name\n",
    "                refimg_list.append(dirstr)\n",
    "                \n",
    "                \n",
    "        for file_id in range(0, self.num_images):\n",
    "\n",
    "            ##### Identifying reference stars - - - - - - - - - - - - - - - - - - - - - \n",
    "            \n",
    "            # loading image_name in case we need to refer to dictionaries\n",
    "            if (from_input_list == False):\n",
    "                image_name = self.images[file_id]\n",
    "                \n",
    "                if (image_name in skip_file_list):\n",
    "                    F_report.write('Excluding ' + image_name + ' because it is in the skip list \\n')\n",
    "                    continue\n",
    "                \n",
    "                if (self.verbose == True):\n",
    "                    print('######## Finding references from image : ' + image_name)\n",
    "                try:\n",
    "                    band = self.band_dict[image_name]\n",
    "                    jd   = self.jd_dict[image_name]\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # open FITS image\n",
    "            try:\n",
    "                hdulist = fits.open( refimg_list[file_id] )\n",
    "            except:\n",
    "                F_report.write('Failed to open image : ' + image_name + '\\n')\n",
    "                continue\n",
    "                \n",
    "            # load header information\n",
    "            try:\n",
    "                image   = hdulist[0].data\n",
    "                image   = np.array(image)\n",
    "                naxis1  = hdulist[0].header['naxis1']\n",
    "                naxis2  = hdulist[0].header['naxis2']\n",
    "                pixsize = hdulist[0].header['secpix']\n",
    "                crval1  = hdulist[0].header['crval1']\n",
    "                crval2  = hdulist[0].header['crval2']\n",
    "                w       = wcs.WCS(hdulist[0].header)\n",
    "                cropbox_halfsize_x = int((float(naxis1)/2.0) * crop_size)\n",
    "                cropbox_halfsize_y = int((float(naxis2)/2.0) * crop_size)\n",
    "            except:\n",
    "                F_report.write('Failed to load wcs for image : ' + image_name + '\\n')\n",
    "                continue\n",
    "                \n",
    "            # do background subtraction from the crop\n",
    "            image = self.background_sub(image, option=background_sub_option)\n",
    "\n",
    "            # estimate robust standard deviation from the cropped image\n",
    "            bkg_sigma = mad_std(image)\n",
    "\n",
    "            # find stars\n",
    "            if (fit_fwhm==True):\n",
    "                try:\n",
    "                    findstar_fwhm = self.fwhm_dict[image_name]\n",
    "                except:\n",
    "                    findstar_fwhm = 0.0\n",
    "            else:\n",
    "                findstar_fwhm=fwhm\n",
    "            \n",
    "            daofind = DAOStarFinder(fwhm=findstar_fwhm, threshold=apt_sigmathreshold*bkg_sigma)\n",
    "            sources = daofind(image)\n",
    "            try:\n",
    "                mxcentroid_array = np.array( sources['xcentroid'] )\n",
    "                mycentroid_array = np.array( sources['ycentroid'] )\n",
    "                mpeak_array      = np.array( sources['peak']      )\n",
    "                num_sources      = len(mpeak_array)\n",
    "            except:\n",
    "                num_sources      = 0\n",
    "\n",
    "                \n",
    "            # Outputting measurements\n",
    "            self.fwhm_dict[image_name] = 0.0\n",
    "            if ( num_sources > 0 ):\n",
    "                \n",
    "                ref_touse_list  = np.zeros(num_sources) # set to 0 if not use; set to 1 if use\n",
    "                ref_ra_list     = np.zeros(num_sources)\n",
    "                ref_dec_list    = np.zeros(num_sources)\n",
    "                ref_count_list  = np.zeros(num_sources)\n",
    "                \n",
    "                # fit FWHM\n",
    "                if (fit_fwhm == True):\n",
    "                    temp_fwhm_list = []\n",
    "                    # iterate through individual found sources\n",
    "                    for ref_id in range(0, num_sources):\n",
    "                        \n",
    "                        mxcentroid = mxcentroid_array[ref_id]\n",
    "                        mycentroid = mycentroid_array[ref_id]\n",
    "                        world = w.wcs_pix2world([ [mxcentroid,mycentroid] ], 0)\n",
    "                        ref_ra_list[ref_id]  = world[0][0]\n",
    "                        ref_dec_list[ref_id] = world[0][1]\n",
    "                        \n",
    "                        temp_fwhm = self.get_fwhm(image, w, world[0][0], world[0][1], background_sub_option,\n",
    "                                             naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y\n",
    "                                            )\n",
    "                        if ( np.isfinite(temp_fwhm) == True ):\n",
    "                            if ( temp_fwhm > 1 ):\n",
    "                                temp_fwhm_list.append(temp_fwhm)\n",
    "                                ref_touse_list[ref_id] = 1\n",
    "                                \n",
    "                    temp_fwhm_list = np.array(temp_fwhm_list)\n",
    "                    medianfwhm           = np.median(temp_fwhm_list)\n",
    "\n",
    "                    if ( np.isfinite(fwhm) == True ):\n",
    "                        self.fwhm_dict[image_name] = medianfwhm\n",
    "                    else:\n",
    "                        self.fwhm_dict[image_name] = 0.0\n",
    "                else:\n",
    "                    self.fwhm_dict[image_name] = fwhm\n",
    "\n",
    "                        \n",
    "                # do photometry\n",
    "                for ref_id in range(0, num_sources):\n",
    "                    if (ref_touse_list[ref_id]==1):\n",
    "                        count = self.get_count(image, w, ref_ra_list[ref_id], ref_dec_list[ref_id], \n",
    "                                               self.fwhm_dict[image_name], \n",
    "                                               background_sub_option, apt_sigmathreshold,\n",
    "                                               naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y)\n",
    "                        if ( np.isfinite(count) == False ):\n",
    "                            ref_touse_list[ref_id] = 0\n",
    "                        elif ( count <=0 ):\n",
    "                            ref_touse_list[ref_id] = 0\n",
    "                        else:\n",
    "                            ref_count_list[ref_id] = count\n",
    "\n",
    "                \n",
    "                ##### Removing objects which are too bright or too faint - - - - - - - - -\n",
    "                filt_count = False\n",
    "                if ( (countrange[0] > 0) and (countrange[1] > 0 ) ):\n",
    "                    countmin = countrange[0]\n",
    "                    countmax = countrange[1]\n",
    "                    filt_count = True\n",
    "                else:\n",
    "                    countmin = 0.0\n",
    "                    countmax = 0.0\n",
    "                    try:\n",
    "                        countmin = self.countrange_dict[image_name][0] / 2.5\n",
    "                        countmax = self.countrange_dict[image_name][1] * 2.5\n",
    "                        filt_count = True\n",
    "                    except:\n",
    "                        filt_count = False\n",
    "                        \n",
    "                if (filt_count == True):\n",
    "                    for ref_id in range(0, num_sources):\n",
    "                        count = ref_count_list[ref_id]\n",
    "                        if ( (count < countmin) or (count > countmax) ):\n",
    "                            ref_touse_list[ref_id] = 0\n",
    "            \n",
    "                ##### Removing those which are in the markers list - - - - - - - - - - - -\n",
    "                for marker in self.marker_list:\n",
    "                    for ref_id in range(0, num_sources):\n",
    "                        coord1 = [ref_ra_list[ref_id],   ref_dec_list[ref_id]]\n",
    "                        coord2 = [marker.ra,   marker.dec]\n",
    "                        off_degree = angoff_degree(coord1, coord2)\n",
    "                        off        = off_degree * 3600.0\n",
    "\n",
    "                        if ( off <= self.fwhm_dict[image_name]*pixsize ):\n",
    "                            ref_touse_list[ref_id] = 0\n",
    "            \n",
    "            ##### Summarizing results of identification - - - - - - - - - - - - - - - - - -\n",
    "            F_report.write('Use fwhm: ' + str(self.fwhm_dict[image_name]) + ',  Found '  +  str(int(np.sum(ref_touse_list))) + \n",
    "                           ' reference stars in ' + image_name + '\\n')\n",
    "            \n",
    "            if (self.verbose == True):\n",
    "                print('Will export ' +  str(int(np.sum(ref_touse_list))) + \n",
    "                      ' reference stars to file ' + refstar_file + '\\n')\n",
    "            for ref_id in range(0, num_sources):\n",
    "                if ( ref_touse_list[ref_id] > 0 ):\n",
    "                    outstring = ''\n",
    "                    outstring += str(file_id) + '_' + str(ref_id) + ' '\n",
    "                    outstring += str(ref_ra_list[ref_id]) + ' ' + str(ref_dec_list[ref_id]) + ' '\n",
    "                    outstring += str(refstar_color[0])+' '+ str(refstar_color[1])+' '+str(refstar_color[2])+' '\n",
    "                    outstring += '1 ' + str(refstar_symsize) + ' '\n",
    "                    outstring += band + ' ' + str(jd) + ' '\n",
    "                    outstring += str(ref_count_list[ref_id]) + ' '\n",
    "                    outstring += image_name + '\\n'\n",
    "                    F_refstar.write(outstring)\n",
    "                        \n",
    "        F_report.close()\n",
    "        F_refstar.close()\n",
    "    \n",
    "    \n",
    "        \n",
    "    def do_apt(self, crop_size=1.0/30.0,\n",
    "                     background_sub_option = 'median',\n",
    "                     apt_sigmathreshold    = 3.0,\n",
    "                     fit_fwhm              = False,\n",
    "                     use_fwhmfit           = False,\n",
    "                     fwhm                  = 0.0,\n",
    "                     skip_file_list        = []\n",
    "              ):\n",
    "        '''\n",
    "        Method to do aperture photometry for loaded markers.\n",
    "        \n",
    "        \n",
    "        Keywords : \n",
    "        \n",
    "        crop_size      [float] : size of the crops for making aperture photometry.\n",
    "                                 Default is 1/30 of the entire image.\n",
    "                                 \n",
    "        background_sub_option [str]: Keyword to specify how background subtraction is made.\n",
    "                                     See description in function: background_sub.\n",
    "                                     \n",
    "        apt_sigmathreshold    [float] : Identify stars which are brighter than the specified\n",
    "                                        sigma threshold. Default: 5-sigma.\n",
    "                                        \n",
    "        fit_fwhm         [True/False] : Specify whether or not we will fit fwhm from reference\n",
    "                                        stars. If not, will use the specified fwhm \n",
    "                                        (see the fwhm item).\n",
    "                                        \n",
    "        use_fwhmfit      [True/False] : If set to False, then it will not use the fitted fwhm\n",
    "                                        when doing aperture photometry, but will only store the\n",
    "                                        fwhm values to the class. This is useful when making a\n",
    "                                        preliminary run before running find_ref.\n",
    "                                        \n",
    "        fwhm                  [float] : fwhm of the point-spread-function in units of pixels.\n",
    "                                        If not specified, and if fit_fwhm=False, \n",
    "                                        it will take values which are obtained from\n",
    "                                        fitting reference stars.\n",
    "                                        \n",
    "        skip_file_list  [list of str] : A list of filename that we do not want to find reference stars\n",
    "                                from, for example, for some epochs which the PSFs are not round.\n",
    "                                This helps since the phoutils package is very slow when examining\n",
    "                                such images. And such images are not useful anyway.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        F_report = open(self.ascii_report,\"a+\")\n",
    "        F_report.write('\\n')\n",
    "        F_report.write('Photometry: \\n')\n",
    "        F_report.write('(only FITS images with compte header information are processed.) \\n')\n",
    "        \n",
    "        # Re-Initialize markers:\n",
    "        for marker in self.marker_list:\n",
    "            marker.band_list = []\n",
    "            marker.jd_dict   = {}\n",
    "            marker.flux_dict = {}\n",
    "      \n",
    "        # Obtaining the PSF information (fitting the reference stars if necessary)\n",
    "        if (fwhm == 0.0):\n",
    "            if (fit_fwhm == False):\n",
    "                use_fwhmfit = True\n",
    "                if (self.verbose == True):\n",
    "                    print('No input PSF fwhm. Use the fitted values from reference stars')\n",
    "            else:\n",
    "                if (self.verbose == True):\n",
    "                    print('No input PSF fwhm. Will fit fwhm from markers')                \n",
    "        \n",
    "        \n",
    "        # Doing photometry\n",
    "        for i in range(0, self.num_images):\n",
    "            \n",
    "            image_name = self.images[i]\n",
    "            if (image_name in skip_file_list):\n",
    "                print('##### skipping image : ' + image_name)\n",
    "                continue\n",
    "            \n",
    "            temp_count_list   = []\n",
    "            num_found_markers = 0\n",
    "            count_max  = 0.0\n",
    "            count_min  = 0.0\n",
    "            self.countrange_dict[image_name] = [count_min, count_max]\n",
    "            hdulist = fits.open(self.path_dict[image_name] + '/' + image_name)\n",
    "            try:\n",
    "                image  = hdulist[0].data\n",
    "                image  = np.array(image)\n",
    "                naxis1 = hdulist[0].header['naxis1']\n",
    "                naxis2 = hdulist[0].header['naxis2']                \n",
    "                w      = wcs.WCS(hdulist[0].header)\n",
    "                cropbox_halfsize_x = int((float(naxis1)/2.0) * crop_size)\n",
    "                cropbox_halfsize_y = int((float(naxis2)/2.0) * crop_size)\n",
    "            except:\n",
    "                F_report.write('Failed to load wcs for image : ' + image_name + '\\n')\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                band = self.band_dict[image_name]\n",
    "                jd   = self.jd_dict[image_name]\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            hdulist.close()\n",
    "            \n",
    "            # Obtain PSF fwhm if necessary\n",
    "            if (fit_fwhm == True):\n",
    "                temp_fwhm_list = []\n",
    "                for marker in self.marker_list:\n",
    "                    temp_fwhm = self.get_fwhm(image, w, marker.ra, marker.dec, background_sub_option,\n",
    "                                         naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y\n",
    "                                        )\n",
    "                    temp_fwhm_list.append(temp_fwhm)\n",
    "                temp_fwhm_list = np.array(temp_fwhm_list)\n",
    "                fwhm           = np.median(temp_fwhm_list)\n",
    "                if ( np.isfinite(fwhm) == True ):\n",
    "                    self.fwhm_dict[image_name] = fwhm\n",
    "                else:\n",
    "                    self.fwhm_dict[image_name] = 0.0\n",
    "\n",
    "            if (use_fwhmfit == True):\n",
    "                fwhm = self.fwhm_dict[image_name]\n",
    "                if (self.verbose==True):\n",
    "                    print('Using fwhm : ' + str(fwhm) + ' for image ' + image_name + '\\n')\n",
    "                        \n",
    "            # Process individual markers\n",
    "            for marker in self.marker_list:\n",
    "                \n",
    "                # get photometry\n",
    "                count = self.get_count(image, w, marker.ra, marker.dec, fwhm, \n",
    "                                       background_sub_option, apt_sigmathreshold,\n",
    "                                       naxis1, naxis2, cropbox_halfsize_x, cropbox_halfsize_y)\n",
    "                if (count > 0):\n",
    "                    temp_count_list.append(count)\n",
    "                    num_found_markers += 1\n",
    "                    if (band not in marker.band_list):\n",
    "                        marker.band_list.append( band )\n",
    "                        # initializing lists to store JD and counts\n",
    "                        marker.jd_dict[ band ]     = []\n",
    "                        marker.flux_dict[ band ]   = []\n",
    "                        \n",
    "                    marker.jd_dict[ band ].append( jd )\n",
    "                    marker.flux_dict[ band ].append( count )    \n",
    "                else:\n",
    "                    F_report.write(\"Cannot find \" + str(marker.label) + \" in \" + image_name + '\\n')\n",
    "              \n",
    "            # Evaluating the maximum and minimum counts from all markers\n",
    "            if (num_found_markers > 0):\n",
    "                temp_count_list = np.array(temp_count_list)\n",
    "                self.countrange_dict[image_name] = [np.min(temp_count_list), \n",
    "                                                    np.max(temp_count_list)]\n",
    "                           \n",
    "        F_report.write('\\n')\n",
    "        F_report.close()\n",
    "\n",
    "        \n",
    "\n",
    "    def get_db(self, refstar_file = '', search_radii_arcsec = 1.0, db='vizier', \n",
    "               outrefdb_file='refdb.txt'):\n",
    "        '''\n",
    "        Method to query database via SIMBAD or Vizier.\n",
    "        It reads the ASCII table of reference stars,\n",
    "        querying the database (simbad or vizier) to obtain the magnitudes of the observed bands,\n",
    "        and then output the query results to an ASCII file.\n",
    "        \n",
    "        \n",
    "        Keywords:\n",
    "        \n",
    "        refstar_file          [str]   : Filename to ASCII input the identified reference stars.\n",
    "        \n",
    "        search_radii_arcsec   [float] : search radius for finding the reference star,\n",
    "                                        in units of arcsecond. Default: 1.0\n",
    "                                        \n",
    "        db                    [str]   : Database. Either 'simbad' or 'vizier'\n",
    "        \n",
    "        outrefdb_file         [str]   : Name of the output query result. The format is similar to\n",
    "                                        that for the reference star file. But instead of tagging\n",
    "                                        the imagename at the end of each row, this method tag the\n",
    "                                        magnitudes and magnitude errors.\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        # Loading refernce star information\n",
    "        try:\n",
    "            ra               = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=1 )\n",
    "            dec              = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=2 )\n",
    "            band             = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=8, dtype=np.str)\n",
    "            jd               = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=9 )\n",
    "            count            = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=10 )\n",
    "        except:\n",
    "            print(\"Failed to open refstar_file. Return.\")\n",
    "            F_report.write(\"Failed to open refstar_file. Nothing is done.\\n\")\n",
    "            F_report.close()\n",
    "            return\n",
    "        \n",
    "        # removing the duplicated reference stars\n",
    "        unique_ra_list  = []\n",
    "        unique_dec_list = []\n",
    "        for i in range(0, len(ra) ):\n",
    "            if ( len(unique_ra_list) == 0 ):\n",
    "                unique_ra_list.append(ra[i])\n",
    "                unique_dec_list.append(dec[i])\n",
    "            else:\n",
    "                append_refstar = True\n",
    "                for j in range(0, len(unique_ra_list) ):\n",
    "                    coord_1 = [unique_ra_list[j], unique_dec_list[j]]\n",
    "                    coord_2 = [ra[i], dec[i]]\n",
    "                    temp_angoff = angoff_degree(coord_1, coord_2)\n",
    "                    if ( temp_angoff < (search_radii_arcsec / 3600.0) ):\n",
    "                        append_refstar = False\n",
    "                if (append_refstar == True):\n",
    "                    unique_ra_list.append(ra[i])\n",
    "                    unique_dec_list.append(dec[i])\n",
    "                    \n",
    "        if (self.verbose == True):\n",
    "            print('There are ', len(unique_ra_list),  ' unique reference stars')\n",
    "\n",
    "\n",
    "        \n",
    "        # Initialize a list of marker for storing output\n",
    "        dbmarker_list = []\n",
    "        \n",
    "        if ( db == 'simbad' ):\n",
    "            \n",
    "            # initializing a simbad quary object\n",
    "            customSimbad = Simbad()\n",
    "            \n",
    "            # including the bands which we want to get magnitudes\n",
    "            for band in self.filterlist:\n",
    "                field_str = 'flux(' + band + ')'\n",
    "                customSimbad.add_votable_fields(field_str)\n",
    "   \n",
    "            # try making query\n",
    "            try:\n",
    "                result_table = customSimbad.query_region(SkyCoord(ra=unique_ra_list, dec=unique_dec_list,\n",
    "                                                         unit=(u.deg, u.deg), frame='icrs'),\n",
    "                                                         radius=search_radii_arcsec * u.arcsec)\n",
    "            except:\n",
    "                print(\"Failed making query to SIMBAD. Please check network.\")\n",
    "                return\n",
    "            \n",
    "            # loading result to the list of marker to prepare for ASCII output\n",
    "            for i in range(0, len(result_table['RA']) ):\n",
    "                \n",
    "                coordstr = str(result_table['RA'][i])  + ' ' + str(result_table['DEC'][i]) + ' '\n",
    "                c = SkyCoord(coordstr, unit=(u.hourangle, u.deg))\n",
    "                \n",
    "                num_dbmarker = len(dbmarker_list)\n",
    "                if ( num_dbmarker == 0 ):\n",
    "                    new_data = False\n",
    "                    mid = 0\n",
    "                    temp_marker = marker(label='SIMBAD_' + str(mid).strip() )\n",
    "                    temp_marker.ra  = c.ra.degree\n",
    "                    temp_marker.dec = c.dec.degree\n",
    "                    \n",
    "                    # try loading flux values\n",
    "                    for band in self.filterlist:\n",
    "                        magstr    = 'FLUX_'+band\n",
    "                        try:\n",
    "                            temp_mag = float( result_table[magstr][i])\n",
    "                            if ( np.isfinite(temp_mag) == True ):\n",
    "                                new_data = True\n",
    "                                temp_marker.band_list.append(band)\n",
    "                                temp_marker.jd_dict[band]   = [0.0]\n",
    "                                temp_marker.flux_dict[band] = [0.0]\n",
    "                                temp_marker.mag_dict[band]  = [temp_mag]                \n",
    "                        except:\n",
    "                            pass\n",
    "                    if (new_data == True):\n",
    "                        dbmarker_list.append(temp_marker)\n",
    "                else:\n",
    "                    # test if marker already exist\n",
    "                    append_marker = True\n",
    "                    new_data      = False\n",
    "                    for db_marker in dbmarker_list:\n",
    "                        coord_1 = [db_marker.ra, db_marker.dec]\n",
    "                        coord_2 = [c.ra.degree, c.dec.degree]\n",
    "                        temp_angoff = angoff_degree(coord_1, coord_2)\n",
    "                        if ( temp_angoff < (search_radii_arcsec / 3600.0) ):\n",
    "                            append_marker = False\n",
    "                            # append the flux values to this marker\n",
    "                            for band in self.filterlist:\n",
    "                                magstr    = 'FLUX_'+band\n",
    "                                try:\n",
    "                                    temp_mag = float( result_table[magstr][i])\n",
    "                                    if ( np.isfinite(temp_mag) == True ):\n",
    "                                        new_data = True\n",
    "                                        if band in db_marker.band_list:\n",
    "                                            db_marker.jd_dict[band].append(0.0)\n",
    "                                            db_marker.flux_dict[band].append(0.0)\n",
    "                                            db_marker.mag_dict[band].append(temp_mag)\n",
    "                                        else:\n",
    "                                            db_marker.band_list.append(band)\n",
    "                                            db_marker.jd_dict[band]   = [0.0]\n",
    "                                            db_marker.flux_dict[band] = [0.0]\n",
    "                                            db_marker.mag_dict[band]  = [temp_mag]                                      \n",
    "                                except:\n",
    "                                    pass\n",
    "                            \n",
    "                    if (append_marker == True):\n",
    "                        mid = num_dbmarker\n",
    "                        temp_marker = marker(label='SIMBAD_' + str(mid).strip() )\n",
    "                        temp_marker.ra  = c.ra.degree\n",
    "                        temp_marker.dec = c.dec.degree\n",
    "                        for band in self.filterlist:\n",
    "                            magstr    = 'FLUX_'+band\n",
    "                            try:\n",
    "                                temp_mag = float( result_table[magstr][i])\n",
    "                                if ( np.isfinite(temp_mag) == True ):\n",
    "                                    new_data = True\n",
    "                                    temp_marker.band_list.append(band)\n",
    "                                    temp_marker.jd_dict[band]   = [0.0]\n",
    "                                    temp_marker.flux_dict[band] = [0.0]\n",
    "                                    temp_marker.mag_dict[band]  = [temp_mag]                \n",
    "                            except:\n",
    "                                pass\n",
    "                        if (new_data == True):\n",
    "                            dbmarker_list.append(temp_marker)\n",
    "\n",
    "        \n",
    "        if ( db == 'vizier' ):\n",
    "            for refstar_id in range(0, len(unique_ra_list) ):\n",
    "                unique_ra = [ unique_ra_list[refstar_id] ]\n",
    "                unique_dec = [ unique_dec_list[refstar_id] ]\n",
    "                \n",
    "                # initializing a Vizier quary object, including the bands which we want to get magnitudes\n",
    "                vizier_columns = ['RAJ2000', 'DEJ2000']\n",
    "                for band in self.filterlist:\n",
    "                    vizier_columns.append(band+'mag')\n",
    "                customVizier = Vizier(columns=vizier_columns)\n",
    "\n",
    "                # try making query\n",
    "                try:\n",
    "                    if (self.verbose == True):\n",
    "                        print('I am processing reference star', refstar_id)\n",
    "                    result_table = customVizier.query_region(SkyCoord(ra=unique_ra, dec=unique_dec,\n",
    "                                                             unit=(u.deg, u.deg), frame='icrs'),\n",
    "                                                             radius=search_radii_arcsec * u.arcsec\n",
    "                                                            )\n",
    "                except:\n",
    "                    print(\"***** Failed making query to Vizier. Please check network. *****\")\n",
    "                    continue\n",
    "\n",
    "                # loading result to the list of marker to prepare for ASCII output\n",
    "                for tabid in range(0, len(result_table) ):\n",
    "                    \n",
    "                    # checking the coordinate unit for individual tables\n",
    "                    try:\n",
    "                        raunit = result_table[tabid]['RAJ2000'].unit\n",
    "                        if ( raunit == u.degree  ):\n",
    "                                coord_unit = (u.deg, u.deg)\n",
    "                        else:\n",
    "                                coord_unit = (u.hourangle, u.deg)\n",
    "                    except:\n",
    "                        raunit = result_table[tabid]['_RAJ2000'].unit\n",
    "                        if ( raunit == u.degree  ):\n",
    "                                coord_unit = (u.deg, u.deg)\n",
    "                        else:\n",
    "                                coord_unit = (u.hourangle, u.deg)\n",
    "\n",
    "                                \n",
    "                    for i in range(0, len(result_table[tabid] ) ):\n",
    "                        try:\n",
    "                            coordstr = str(result_table[tabid]['RAJ2000'][i])  + ' ' + \\\n",
    "                                       str(result_table[tabid]['DEJ2000'][i]) + ' '\n",
    "                            c = SkyCoord(coordstr, unit=coord_unit)                            \n",
    "                        except:\n",
    "                            coordstr = str(result_table[tabid]['_RAJ2000'][i])  + ' ' + \\\n",
    "                                       str(result_table[tabid]['_DEJ2000'][i]) + ' '\n",
    "                            c = SkyCoord(coordstr, unit=coord_unit)\n",
    "\n",
    "                        num_dbmarker = len(dbmarker_list)\n",
    "                        if ( num_dbmarker == 0 ):\n",
    "                            new_data = False\n",
    "                            mid = 0\n",
    "                            temp_marker = marker(label='Vizier_' + str(mid).strip() )\n",
    "                            temp_marker.ra  = c.ra.degree\n",
    "                            temp_marker.dec = c.dec.degree\n",
    "\n",
    "                            # try loading flux values\n",
    "                            for band in self.filterlist:\n",
    "                                magstr_list    = ['_'+band, band+'mag']\n",
    "                                for magstr in magstr_list:\n",
    "                                    try:\n",
    "                                        temp_mag = float( result_table[tabid][magstr][i])\n",
    "                                        if ( np.isfinite(temp_mag) == True ):\n",
    "                                            new_data = True\n",
    "                                            temp_marker.band_list.append(band)\n",
    "                                            temp_marker.jd_dict[band]   = [0.0]\n",
    "                                            temp_marker.flux_dict[band] = [0.0]\n",
    "                                            temp_marker.mag_dict[band]  = [temp_mag]\n",
    "                                            continue\n",
    "                                    except:\n",
    "                                        pass\n",
    "                            if (new_data == True):\n",
    "                                dbmarker_list.append(temp_marker)\n",
    "                        else:\n",
    "                            # test if marker already exist\n",
    "                            append_marker = True\n",
    "                            new_data = False\n",
    "                            \n",
    "                            for db_marker in dbmarker_list:\n",
    "                                coord_1 = [db_marker.ra, db_marker.dec]\n",
    "                                coord_2 = [c.ra.degree, c.dec.degree]\n",
    "                                temp_angoff = angoff_degree(coord_1, coord_2)\n",
    "                                if ( temp_angoff < (search_radii_arcsec / 3600.0) ):\n",
    "                                    append_marker = False\n",
    "\n",
    "                                    # append the flux values to this marker\n",
    "                                    for band in self.filterlist:\n",
    "                                        magstr_list    = ['_'+band, band+'mag']\n",
    "                                        for magstr in magstr_list:\n",
    "                                            try:\n",
    "                                                temp_mag = float( result_table[tabid][magstr][i])\n",
    "                                                if ( np.isfinite(temp_mag) == True ):\n",
    "                                                    new_data = True\n",
    "                                                    if band in db_marker.band_list:\n",
    "                                                        db_marker.jd_dict[band].append(0.0)\n",
    "                                                        db_marker.flux_dict[band].append(0.0)\n",
    "                                                        db_marker.mag_dict[band].append(temp_mag)\n",
    "                                                    else:\n",
    "                                                        db_marker.band_list.append(band)\n",
    "                                                        db_marker.jd_dict[band]   = [0.0]\n",
    "                                                        db_marker.flux_dict[band] = [0.0]\n",
    "                                                        db_marker.mag_dict[band]  = [temp_mag]\n",
    "                                                    continue\n",
    "                                            except:\n",
    "                                                pass\n",
    "\n",
    "                            if (append_marker == True):\n",
    "                                mid = num_dbmarker\n",
    "                                temp_marker = marker(label='Vizier_' + str(mid).strip() )\n",
    "                                temp_marker.ra  = c.ra.degree\n",
    "                                temp_marker.dec = c.dec.degree\n",
    "                                for band in self.filterlist:\n",
    "                                    magstr_list    = ['_'+band, band+'mag']\n",
    "                                    for magstr in magstr_list:\n",
    "                                        try:\n",
    "                                            temp_mag = float( result_table[tabid][magstr][i])\n",
    "                                            if ( np.isfinite(temp_mag) == True ):\n",
    "                                                new_data = True\n",
    "                                                temp_marker.band_list.append(band)\n",
    "                                                temp_marker.jd_dict[band]   = [0.0]\n",
    "                                                temp_marker.flux_dict[band] = [0.0]\n",
    "                                                temp_marker.mag_dict[band]  = [temp_mag]\n",
    "                                                continue\n",
    "                                        except:\n",
    "                                            pass\n",
    "                                if(new_data == True):\n",
    "                                    dbmarker_list.append(temp_marker)\n",
    "        \n",
    "        \n",
    "        # ASCII output\n",
    "        if (self.verbose == True):\n",
    "            print('number of reference stars ', len(dbmarker_list))\n",
    "            \n",
    "        F_db = open(outrefdb_file,\"w+\")\n",
    "        headerstr = \"# name, ra dec R:0-1 G:0-1 B:0-1 alpha size band jd count \"\n",
    "        for band in self.filterlist:\n",
    "            headerstr += band + '_mag ' + band + '_mag_Err '\n",
    "        headerstr += '\\n'\n",
    "        F_db.write(headerstr)\n",
    "        \n",
    "        for db_marker in dbmarker_list:\n",
    "            outstring = ''\n",
    "            outstring += db_marker.label + ' '\n",
    "            outstring += str(db_marker.ra) + ' ' + str(db_marker.dec) + ' '\n",
    "            outstring += '0 1 1 1 80 X 0.0 0.0     ' # R, G, B, alpha, size, band, jd, count (place holder)\n",
    "            for band in self.filterlist:\n",
    "                if band in db_marker.band_list:\n",
    "                    mag_array    = np.array( db_marker.mag_dict[band] )\n",
    "                    reduced_flux_array = 100.0**( (-1.0/5.0) * mag_array )\n",
    "                    mean_reduced_flux   = biweight_location( reduced_flux_array )\n",
    "                    stddec_reduced_flux = biweight_scale( reduced_flux_array )\n",
    "                    mean_mag            = -2.5 * np.log10(mean_reduced_flux)\n",
    "                    stddev_mag          = -2.5 * np.log10(mean_reduced_flux + stddec_reduced_flux)\n",
    "                    stddev_mag          = mean_mag - stddev_mag\n",
    "                    outstring += str( mean_mag ) + ' '\n",
    "                    outstring += str( stddev_mag )    + ' '\n",
    "                else:\n",
    "                    outstring += 'NaN NaN '\n",
    "            outstring += '\\n'\n",
    "            F_db.write(outstring)\n",
    "        \n",
    "        F_db.close()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def cal_dbmag(self, inrefdb_file='', refstar_file='', search_radii_arcsec = 1.0):\n",
    "        '''\n",
    "        Method to convert the measurements from counts to magnitudes.\n",
    "        \n",
    "        It first reads from inrefdb_file the ASCII database of queried (from SIMBAD or Vizier) \n",
    "        magnitudes and magnitudes errors of the reference stars, \n",
    "        e.g., returned from the get_db method.\n",
    "        Then it reads all the jd and counts measurements of the reference stars from the\n",
    "        refstar_file, e.g., returned from the find_ref method.\n",
    "        Finally, it compares the counts of the reference stars and the markers in the class,\n",
    "        and then convert the counts of the markers to magnitudes (and magnitude errors).\n",
    "\n",
    "\n",
    "        Keywords:\n",
    "\n",
    "        inrefdb_file          [str]   : Name of the input database query result. The format is similar to\n",
    "                                        that for the reference star file. But instead of tagging\n",
    "                                        the imagename at the end of each row, this method tag the\n",
    "                                        magnitudes and magnitude errors.\n",
    "                                        \n",
    "        refstar_file          [str]   : Filename to ASCII input the identified reference stars.\n",
    "\n",
    "        search_radii_arcsec   [float] : search radius for finding the reference star,\n",
    "                                        in units of arcsecond. Default: 1.0        \n",
    "        '''\n",
    "        F_report = open(self.ascii_report,\"a+\")\n",
    "        F_report.write('\\n')\n",
    "        F_report.write('Calibrating from counts to magnitude: \\n')\n",
    "\n",
    "        # Loading refernce stars' database information\n",
    "        # They are maintained as arrays (one array for each quantity)\n",
    "        try:\n",
    "            db_ra               = np.loadtxt(inrefdb_file, comments='#', skiprows=0, usecols=1 )\n",
    "            db_dec              = np.loadtxt(inrefdb_file, comments='#', skiprows=0, usecols=2 )\n",
    "            \n",
    "            # Load magnitude and magnitude error for individual bands\n",
    "            read_band     = True\n",
    "            colid         = 11\n",
    "            db_mag_dict      = {}\n",
    "            db_magerr_dict   = {}\n",
    "            while (read_band == True):\n",
    "                try:\n",
    "                    # Read the name of the band\n",
    "                    rl_temp = open(inrefdb_file, \"r\")\n",
    "                    line    = rl_temp.readline()\n",
    "                    linesplit_list = line.split()\n",
    "                    bandname       =  ( (linesplit_list[colid+1]).split(\"_\") )[0] \n",
    "                    rl_temp.close()\n",
    "                    \n",
    "                    db_mag_dict[bandname]    = np.loadtxt(inrefdb_file, comments='#', skiprows=0, usecols=colid )\n",
    "                    db_magerr_dict[bandname] = np.loadtxt(inrefdb_file, comments='#', skiprows=0, usecols=(colid+1) )\n",
    "                    colid  = colid + 2\n",
    "                except:\n",
    "                    read_band = False\n",
    "                    \n",
    "        except:\n",
    "            print(\"Failed to open inrefdb_file. Return.\")\n",
    "            F_report.write(\"Failed to open inrefdb_file. Nothing is done.\\n\")\n",
    "            F_report.close()\n",
    "            return\n",
    "        \n",
    "                    \n",
    "        # Loading the measurements of individual reference stars (ra, dec, jd, band, count)\n",
    "        try:\n",
    "            ref_ra               = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=1 )\n",
    "            ref_dec              = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=2 )\n",
    "            ref_band             = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=8, dtype=np.str)\n",
    "            ref_jd               = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=9 )\n",
    "            ref_count            = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=10 )            \n",
    "        except:\n",
    "            print(\"Failed to open refstar_file. Return.\")\n",
    "            F_report.write(\"Failed to open refstar_file. Nothing is done.\\n\")\n",
    "            F_report.close()\n",
    "            return\n",
    "        \n",
    "        \n",
    "        # Iterating through individual markers to derive magnitudes (and errors)\n",
    "        for marker in self.marker_list:\n",
    "            \n",
    "            # iterate through individual bands\n",
    "            for band in marker.band_list:\n",
    "                \n",
    "                # initializing the list for storing magnitude and magnitude errors\n",
    "                marker.mag_dict[band]    = np.zeros( len(marker.jd_dict[band]) )\n",
    "                marker.magerr_dict[band] = np.zeros( len(marker.jd_dict[band]) )\n",
    "                \n",
    "                # iterating through JD\n",
    "                for jd_idx in range(0, len(marker.jd_dict[band]) ):\n",
    "                    \n",
    "                    marker_jd    = marker.jd_dict[band][jd_idx]\n",
    "                    marker_count = marker.flux_dict[band][jd_idx]\n",
    "                    \n",
    "                    #print(marker_jd, marker_count)\n",
    "                    # Load reference stars for this JD, and then reference the magnitude\n",
    "                    # of the reference stars for this JD and for this band from database (db)\n",
    "                    temp_ref_count_list  = []\n",
    "                    temp_ref_mag_list    = []\n",
    "                    temp_ref_magerr_list = []\n",
    "                    \n",
    "                    for refstar_idx in range(0, len(ref_ra) ):\n",
    "                        if ( (ref_band[refstar_idx] == band) and\n",
    "                             (ref_jd[refstar_idx] == marker_jd)\n",
    "                           ):\n",
    "                            \n",
    "                            # temp_ref_count_list.append( ref_count[refstar_idx] )\n",
    "                            \n",
    "                            # iterate through the database array to obtain the magnitude\n",
    "                            found_db = False\n",
    "                            for dbstar_idx in range(0, len(db_ra) ):\n",
    "                                \n",
    "                                # check whether or not they are the same reference star by\n",
    "                                # comparing the angular separation and search_radius.\n",
    "                                coord_1 = [db_ra[dbstar_idx], db_dec[dbstar_idx] ]\n",
    "                                coord_2 = [ref_ra[refstar_idx], ref_dec[refstar_idx] ]\n",
    "                                temp_angoff = angoff_degree(coord_1, coord_2)\n",
    "                                \n",
    "                                if ( temp_angoff < (search_radii_arcsec / 3600.0) ):\n",
    "                                    found_db = True\n",
    "                                    theid    = dbstar_idx\n",
    "                                \n",
    "                            if (found_db == True):\n",
    "                                temp_ref_mag_list.append( db_mag_dict[band][theid] )\n",
    "                                temp_ref_magerr_list.append( db_magerr_dict[band][theid] )\n",
    "                                temp_ref_count_list.append( ref_count[refstar_idx] )\n",
    "                    \n",
    "                    # Evalute the magnitude\n",
    "                    # of the marker at this band and jd, and then append to marker.mag_dict\n",
    "                    marker_mag_temp_list = []\n",
    "                    for refstar_idx in range(0, len(temp_ref_count_list) ):\n",
    "                        marker_mag_temp = temp_ref_mag_list[refstar_idx] + \\\n",
    "                                          -2.5 * np.log10( marker_count / temp_ref_count_list[refstar_idx])\n",
    "                        if ( np.isfinite(marker_mag_temp) == True ):\n",
    "                            marker_mag_temp_list.append(marker_mag_temp)\n",
    "                            \n",
    "                    # I band error is fairly large here. Need to do something to remove bad references\n",
    "                    marker.mag_dict[band][jd_idx] = biweight_location(marker_mag_temp_list)\n",
    "                    marker.magerr_dict[band][jd_idx] = biweight_scale(marker_mag_temp_list)\n",
    "                    \n",
    "                \n",
    "        #self.band_list   = []\n",
    "        #self.jd_dict     = {}\n",
    "        #self.flux_dict   = {}\n",
    "        #self.mag_dict    = {}\n",
    "        #self.magerr_dict = {}\n",
    "        \n",
    "                    \n",
    "\n",
    "        F_report.close()\n",
    "\n",
    "        \n",
    "        \n",
    "    def export_apt(self, outfile_name = 'photometry.txt'):\n",
    "        '''\n",
    "        Method to output time-sorted photometric measurements to an ascii file.\n",
    "        For a specific epoch, if a specific band was not observed, then\n",
    "        the output flux of that band will be 0.0. \n",
    "        \n",
    "        \n",
    "        Keyword:\n",
    "        \n",
    "        outfile_name      [str]  : name of the output file. Default: photometry.txt\n",
    "        '''\n",
    "\n",
    "        # Prepare output file\n",
    "        os.system('rm -rf ' + outfile_name)\n",
    "        F_out = open(outfile_name,\"a+\")\n",
    "        outheader = '# JD     source_name     fwhm     '\n",
    "        for band in self.filterlist:\n",
    "            outheader = outheader + band + '_band_counts     '\n",
    "        outheader = outheader + '\\n'\n",
    "        F_out.write(outheader)\n",
    "        \n",
    "        # collect all possible dates\n",
    "        temp_jd_list = []\n",
    "        for marker in self.marker_list:\n",
    "            for band in marker.band_list:\n",
    "                temp_jd_list += marker.jd_dict[band]\n",
    "            # avoid repetition (set) and sort()\n",
    "            temp_jd_list = list( set(temp_jd_list) )\n",
    "            temp_jd_list = np.array( temp_jd_list )\n",
    "            temp_jd_list = np.sort( temp_jd_list )\n",
    "            \n",
    "        for jd in temp_jd_list:\n",
    "            for marker in self.marker_list:\n",
    "                outstring  = str(jd) + '     ' + str(marker.label) + '     '\n",
    "                \n",
    "                fwhm_str = '0.0'\n",
    "                for image_name in self.images:\n",
    "                    try:\n",
    "                        img_jd = self.jd_dict[image_name]\n",
    "                        if (self.jd_dict[image_name] == jd):\n",
    "                            try:\n",
    "                                fwhm_str = str( self.fwhm_dict[image_name] )\n",
    "                            except:\n",
    "                                pass\n",
    "                    except:\n",
    "                        continue\n",
    "                    \n",
    "\n",
    "                outstring  = outstring + fwhm_str + '     '\n",
    "                \n",
    "                datastring = ''\n",
    "                temp_flux_dict = {}\n",
    "                to_output  = False\n",
    "                \n",
    "                for band in self.filterlist:\n",
    "                    temp_flux_dict[band] = 0.0\n",
    "                \n",
    "                for band in marker.band_list:\n",
    "                    try:\n",
    "                        for record_idx in range( len(marker.jd_dict[band]) ):\n",
    "                            epoch = marker.jd_dict[band][record_idx]\n",
    "                            if(epoch==jd):\n",
    "                                temp_flux_dict[band] = marker.flux_dict[band][record_idx] \n",
    "                                to_output = True\n",
    "                    except:\n",
    "                        pass\n",
    "                                \n",
    "                if ( to_output == True ):\n",
    "                    for band in self.filterlist:\n",
    "                        datastring = datastring + str(temp_flux_dict[band]) + '     '\n",
    "                    outstring = outstring + datastring + '\\n'\n",
    "                    F_out.write(outstring)\n",
    "        \n",
    "        F_out.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot_preview(self, output_directory='./preview_images',\n",
    "                     label_marker=True,\n",
    "                     refstar_file='',\n",
    "                     simbad_file='',\n",
    "                     fig_format='png'\n",
    "                    ):\n",
    "        '''\n",
    "        Method to plot the preview figures for FITS imagfes.\n",
    "        It will produce figures for the observed images (one sub-directory for each band),\n",
    "        and collect them into an output_directory.\n",
    "        \n",
    "        \n",
    "        Keywords:\n",
    "        \n",
    "        output_directory [string] : The directory to collect the output images.\n",
    "        \n",
    "        label_marker [True/False] : If True, label the names of the markers on the figure.\n",
    "        \n",
    "        refstar_file              : If exist, load reference stars from file and plot them.\n",
    "        \n",
    "        simbad_file              : If exist, load reference stars from file and plot them.\n",
    "        \n",
    "        fig_format   [string]     : 'png' or 'pdf'\n",
    "        '''\n",
    "        \n",
    "        F_report = open(self.ascii_report,\"a+\")\n",
    "        F_report.write('\\n')\n",
    "        F_report.write('Image preview summary: \\n')\n",
    "        \n",
    "        os.system('rm -rf ' + output_directory)\n",
    "        os.system('mkdir '  + output_directory)\n",
    "        \n",
    "        output_path_dict = {}\n",
    "        for tempstr in self.filterlist:\n",
    "            output_path_dict[tempstr] = './' + tempstr + 'band_maps'\n",
    "            \n",
    "        for key in output_path_dict.keys():\n",
    "            os.system('rm -rf ' + output_path_dict[key] )\n",
    "            os.system('mkdir '  + output_path_dict[key] )\n",
    "            \n",
    "        # plot images\n",
    "        for i in range(0, self.num_images):\n",
    "            image_name = self.images[i]\n",
    "            try:\n",
    "                band       = self.band_dict[image_name]\n",
    "                jd         = self.jd_dict[image_name]\n",
    "            except:\n",
    "                F_report.write('Warning. Image ' +  image_name + ' is not saved. \\n')\n",
    "                continue\n",
    "            \n",
    "            # plot image\n",
    "            fig = aplpy.FITSFigure( self.path_dict[image_name] + '/' + image_name)\n",
    "            fig.show_grayscale(invert=False)\n",
    "            \n",
    "            # plot symbol\n",
    "            \n",
    "            # define output figure name\n",
    "            try:\n",
    "                outfig_name = \\\n",
    "                              band + '_' + \\\n",
    "                              str( round(jd,5) ) + '.' + fig_format\n",
    "                # fig.set_xaxis_coord_type('longitude')\n",
    "                # fig.set_yaxis_coord_type('latitude')\n",
    "                fig.axis_labels.hide()\n",
    "                fig.show_grayscale(invert=False)\n",
    "            except:\n",
    "                if (self.verbose == True):\n",
    "                    F_report.write('Warning. Image ' +  image_name + ' is not saved. \\n')\n",
    "                    \n",
    "            # plot markers\n",
    "            \n",
    "            for marker in self.marker_list:\n",
    "                # plot markers in the png figure\n",
    "                fig.show_markers(\n",
    "                                 marker.ra, marker.dec, \n",
    "                                 edgecolor=marker.color, \n",
    "                                 # facecolor=facecolor[plot_id],\n",
    "                                 marker='o', s=marker.size, \n",
    "                                 alpha=marker.alpha\n",
    "                                )\n",
    "                \n",
    "                if (label_marker == True):\n",
    "                    label = marker.label\n",
    "                    fig.add_label(marker.ra, marker.dec, '  ' + label,\n",
    "                                  color=marker.color, fontsize=12, horizontalalignment='left')\n",
    "                    \n",
    "            if (len(refstar_file) > 0):\n",
    "                try:\n",
    "                    refra         = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=1 )\n",
    "                    refdec        = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=2 )\n",
    "                    refR          = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=3 )\n",
    "                    refG          = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=4 )\n",
    "                    refB          = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=5 )\n",
    "                    ref_alpha     = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=6 )\n",
    "                    ref_size      = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=7 )\n",
    "                    ref_band      = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=8, dtype=np.str)\n",
    "                    ref_jd        = np.loadtxt(refstar_file, comments='#', skiprows=0, usecols=9 )\n",
    "                    \n",
    "                    for ref_id in range(0, np.size(refra) ):\n",
    "                        \n",
    "                        if ( jd == ref_jd[ref_id] ): # separated by less than 1s\n",
    "                            if (band == ref_band[ref_id].strip() ):\n",
    "                                fig.show_markers(\n",
    "                                         refra[ref_id], refdec[ref_id], \n",
    "                                         edgecolor=(refR[ref_id], refG[ref_id], refB[ref_id]), \n",
    "                                         marker='o', s=ref_size[ref_id], \n",
    "                                         alpha=ref_alpha[ref_id]\n",
    "                                        )                           \n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                \n",
    "            if (len(simbad_file) > 0):\n",
    "                try:\n",
    "                    refra         = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=1 )\n",
    "                    refdec        = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=2 )\n",
    "                    refR          = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=3 )\n",
    "                    refG          = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=4 )\n",
    "                    refB          = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=5 )\n",
    "                    ref_alpha     = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=6 )\n",
    "                    ref_size      = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=7 )\n",
    "                    ref_band      = np.loadtxt(simbad_file, comments='#', skiprows=0, usecols=8, dtype=np.str)\n",
    "\n",
    "                    for ref_id in range(0, np.size(refra) ):\n",
    "                        \n",
    "                        fig.show_markers(\n",
    "                                 refra[ref_id], refdec[ref_id], \n",
    "                                 edgecolor=(refR[ref_id], refG[ref_id], refB[ref_id]), \n",
    "                                 marker='o', \n",
    "                                 s=ref_size[ref_id], \n",
    "                                 alpha=ref_alpha[ref_id]\n",
    "                                )                           \n",
    "                    \n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            # label date\n",
    "            try:\n",
    "                date = self.date_dict[image_name].strip()\n",
    "            except:\n",
    "                date = 'unknown_date'\n",
    "                \n",
    "            date_label = 'Date : ' + date + '  JD : ' \\\n",
    "                         +  str(jd).strip()                    \\\n",
    "                         + '   Band : ' + band  \n",
    "            fig.add_label(0.02, 0.95, date_label, relative=True, \n",
    "                         color=(0,1,1,1),\n",
    "                         fontsize=9, horizontalalignment='left')\n",
    "            \n",
    "            # label image name\n",
    "            fig.add_label(0.02, 0.92, image_name, relative=True, \n",
    "                         color=(0,1,1,1),\n",
    "                         fontsize=9, horizontalalignment='left')\n",
    "                    \n",
    "            fig.axis_labels.hide()\n",
    "            fig.save(outfig_name)    \n",
    "            os.system('mv ' + outfig_name + ' ' + output_path_dict[band] )\n",
    "            \n",
    "        # pack output maps to be under the same directory\n",
    "        for key in output_path_dict.keys():\n",
    "            os.system('mv ' + output_path_dict[key] + ' ./' +  output_directory)   \n",
    "\n",
    "        F_report.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndmtau = apt_pipe(data_path = r\"../problem_images\",\\n                 markerfile   = \\'./markers.txt\\', verbose=True)\\ndmtau.plot_preview(label_marker=False)\\n'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dmtau = apt_pipe(data_path = r\"../problem_images\",\n",
    "                 markerfile   = './markers.txt', verbose=True)\n",
    "dmtau.plot_preview(label_marker=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FITS image from : ../problem_images\n",
      "##############################################################\n",
      "Processing 13 images \n",
      "\n",
      "##############################################################\n",
      "Warning, coordinate header of dm tau_3463766_I_006.fits does not exist.\n",
      "Number of markers : 1\n",
      "##### skipping image : dm tau_3488473_R_040.fits\n",
      "##### skipping image : dm tau_3488473_I_056.fits\n",
      "##### skipping image : dm tau_3488473_V_075.fits\n",
      "##### skipping image : dm tau_3463766_I_034.fits\n",
      "##### skipping image : dm tau_3463766_R_022.fits\n",
      "##### skipping image : dm tau_3463766_V_029.fits\n",
      "##### skipping image : dm tau_3463766_I_035.fits\n",
      "No input reference image names. Searching for reference stars from all input images.\n",
      "######## Finding references from image : dm tau_3463766_I_015.fits\n",
      "Warning. Failed fitting Gaussian profile.\n",
      "Warning. Failed fitting Gaussian profile.\n",
      "Warning. Failed fitting Gaussian profile.\n",
      "Will export 21 reference stars to file reference_star.txt\n",
      "\n",
      "######## Finding references from image : dm tau_3488473_R_064.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in sqrt\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/scipy/optimize/minpack.py:795: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "WARNING: NoDetectionsWarning: No sources were found. [photutils.detection.findstars]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning. Failed fitting Gaussian profile.\n",
      "Warning. Failed fitting Gaussian profile.\n",
      "Warning. Failed fitting Gaussian profile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: NoDetectionsWarning: No sources were found. [photutils.detection.findstars]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will export 32 reference stars to file reference_star.txt\n",
      "\n",
      "######## Finding references from image : dm tau_3488473_I_038.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: NoDetectionsWarning: No sources were found. [photutils.detection.findstars]\n",
      "WARNING: NoDetectionsWarning: No sources were found. [photutils.detection.findstars]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will export 30 reference stars to file reference_star.txt\n",
      "\n",
      "######## Finding references from image : dm tau_3463766_I_006.fits\n",
      "######## Finding references from image : dm tau_3488473_V_018.fits\n",
      "Warning. Failed fitting Gaussian profile.\n",
      "Warning. Failed fitting Gaussian profile.\n",
      "Warning. Failed fitting Gaussian profile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in sqrt\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/scipy/optimize/minpack.py:795: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will export 16 reference stars to file reference_star.txt\n",
      "\n",
      "######## Finding references from image : dm tau_3488473_V_027.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in sqrt\n",
      "/home/hyliu/.conda/envs/terada2019/lib/python3.7/site-packages/scipy/optimize/minpack.py:795: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning. Failed fitting Gaussian profile.\n",
      "Warning. Failed fitting Gaussian profile.\n",
      "Will export 25 reference stars to file reference_star.txt\n",
      "\n",
      "No input PSF fwhm. Use the fitted values from reference stars\n",
      "Using fwhm : 4.036845887187906 for image dm tau_3463766_I_015.fits\n",
      "\n",
      "##### skipping image : dm tau_3488473_R_040.fits\n",
      "Using fwhm : 3.246355505835748 for image dm tau_3488473_R_064.fits\n",
      "\n",
      "Using fwhm : 4.076449279139101 for image dm tau_3488473_I_038.fits\n",
      "\n",
      "##### skipping image : dm tau_3488473_I_056.fits\n",
      "##### skipping image : dm tau_3488473_V_075.fits\n",
      "##### skipping image : dm tau_3463766_I_034.fits\n",
      "##### skipping image : dm tau_3463766_R_022.fits\n",
      "Using fwhm : 2.966284275884667 for image dm tau_3488473_V_018.fits\n",
      "\n",
      "##### skipping image : dm tau_3463766_V_029.fits\n",
      "##### skipping image : dm tau_3463766_I_035.fits\n",
      "Using fwhm : 3.3070812575417827 for image dm tau_3488473_V_027.fits\n",
      "\n",
      "2458491.56799249 I 12.663646531902218 0.7879168508041758\n",
      "\n",
      "\n",
      "2458508.63674647 I 13.551628012217991 0.24577186244605542\n",
      "\n",
      "\n",
      "2458521.55098513 R 12.90805068767839 0.08982456148908224\n",
      "\n",
      "\n",
      "2458502.61388679 V 14.252679626549362 0.032532065725594334\n",
      "\n",
      "\n",
      "2458505.60686772 V 14.015957545443571 0.02472622592760269\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dmtau = apt_pipe(data_path = [\n",
    "                              #r\"../3463766-dm tau\",\n",
    "                              #r\"../3486034-dm tau\",\n",
    "                              #r\"../3488473-dm tau\",\n",
    "                              r\"../problem_images\",\n",
    "                             ],\n",
    "                 markerfile   = './markers.txt', verbose=True)\n",
    "\n",
    "skip_file_list = [\n",
    "                 'dm tau_3463766_R_022.fits',  # PSF not round\n",
    "                 'dm tau_3463766_I_033.fits',  # PSF not round\n",
    "                 'dm tau_3463766_I_034.fits',  # PSF not round\n",
    "                 'dm tau_3463766_I_035.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_018.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_019.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_020.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_027.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_028.fits',  # PSF not round\n",
    "                 'dm tau_3463766_V_029.fits',  # PSF not round\n",
    "                 'dm tau_3488473_V_024.fits',  # Very extended bright emission. Crashed DAOStarFinder.\n",
    "                 'dm tau_3488473_V_075.fits',  # Very bright sky and not round PSF. Crashed DAOStarFinder.\n",
    "                 'dm tau_3488473_V_075.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_I_014.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_I_041.fits',  # Very elongated PSF.\n",
    "                 'dm tau_3488473_I_044.fits',  # Very elongated PSF.\n",
    "                 'dm tau_3488473_I_050.fits',  # High noise. Target not detected.\n",
    "                 'dm tau_3488473_I_053.fits',  # High noise. Target not detected.\n",
    "                 'dm tau_3488473_I_056.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_I_059.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_013.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_R_040.fits',  # Very elongated PSF. Crashed DAOStarFinder.\n",
    "                 'dm tau_3488473_R_046.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_049.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_052.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_055.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_R_058.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_V_012.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_V_015.fits',  # Very bright sky\n",
    "                 'dm tau_3488473_V_039.fits',  # Very elongated PSF.\n",
    "                 'dm tau_3488473_V_042.fits',  # Very elongated PSF.\n",
    "                 'dm tau_3488473_V_045.fits',  # High noise. Target barely detected.\n",
    "                 'dm tau_3488473_V_048.fits',  # High noise. No reference star detected.\n",
    "                 'dm tau_3488473_V_054.fits',  # High noise. No reference star detected.\n",
    "                 'dm tau_3488473_V_057.fits',  # High noise. No reference star detected.\n",
    "                ]\n",
    "\n",
    "# preliminary run on target sources to obtain count range\n",
    "dmtau.do_apt(fwhm=5.0, fit_fwhm=True, use_fwhmfit=False, skip_file_list = skip_file_list)\n",
    "\n",
    "\n",
    "# Finding reference stars and measure their counts\n",
    "dmtau.find_ref(fit_fwhm=True, fwhm=0.0, apt_sigmathreshold=100,\n",
    "                refstar_file ='reference_star.txt',\n",
    "                skip_file_list = skip_file_list)\n",
    "\n",
    "# Plotting preview images\n",
    "# dmtau.plot_preview(label_marker=False,\n",
    "#                   refstar_file='reference_star.txt',\n",
    "                   # simbad_file='refdb_simbad.txt'\n",
    "#                    simbad_file='refdb_vizier.txt'\n",
    "#                    )\n",
    "\n",
    "# Doing aperture photometry (i.e., measuring counts)\n",
    "dmtau.do_apt(fwhm=0.0, fit_fwhm=False, skip_file_list=skip_file_list)\n",
    "\n",
    "# Converting counts to magnitudes based on making query to SIMBAD or Vizier\n",
    "# *** This step is very time consuming if using Vizier. Excuete only when it is definitely necessary\n",
    "#     to update the table.\n",
    "#dmtau.get_db(refstar_file = 'reference_star.txt', search_radii_arcsec = 3.0, \n",
    "# #             #db='simbad', outrefdb_file='refdb_simbad.txt'\n",
    "#               db='vizier',  outrefdb_file='refdb_vizier.txt'\n",
    "#              )\n",
    "\n",
    "# Plotting preview images\n",
    "# dmtau.plot_preview(label_marker=False,\n",
    "#                    refstar_file='reference_star.txt',\n",
    "#                    # simbad_file='refdb_simbad.txt'\n",
    "#                     simbad_file='refdb_vizier.txt'\n",
    "#                     )\n",
    "\n",
    "# Converting from counts to magnitudes\n",
    "dmtau.cal_dbmag(inrefdb_file='refdb_vizier.txt', refstar_file ='reference_star.txt', \n",
    "                search_radii_arcsec = 3.0)\n",
    "\n",
    "\n",
    "\n",
    "# Export photometry\n",
    "dmtau.export_apt()\n",
    "\n",
    "\n",
    "\n",
    "#for marker in dmtau.marker_list:\n",
    "#    print(marker.label, ':', marker.band_list)\n",
    "#    for band in marker.band_list:\n",
    "#        print('Band : ', band)\n",
    "#        print(marker.jd_dict[band])\n",
    "#        print(marker.flux_dict[band])\n",
    "#        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Directory for input image\\ndata_path   = r\"../3488473-dm tau\"\\n\\n# Defining output directories\\noutput_path_dict = {}\\noutput_path_dict[\\'R\\'] = \\'./R_maps\\'\\noutput_path_dict[\\'V\\'] = \\'./V_maps\\'\\noutput_path_dict[\\'I\\'] = \\'./I_maps\\'\\n\\n# set if we want to do photometry for objects in the markers list\\ndophotometry     = True\\naperature_r_pix  = 10.0 # pixels\\nif (dophotometry == True):\\n    print(\"Will output photometry. Please define the output filename if not yet.\")\\n    photometry_file_dict = {}\\n    photometry_file_dict[\\'R\\'] = \\'./R_phot.txt\\'\\n    photometry_file_dict[\\'V\\'] = \\'./V_phot.txt\\'\\n    photometry_file_dict[\\'I\\'] = \\'./I_phot.txt\\'\\n    \\n\\n# Output ASCII list for FITS images which do not possess coordinate headers\\nf = open(\"NO_COORD_HEADER_list.txt\",\"w\")    \\n    \\nmarkerfile = \\'./markers.txt\\'\\n    \\n# Preparation ##############################################################\\nfor key in output_path_dict.keys():\\n    os.system(\\'rm -rf \\' + output_path_dict[key] )\\n    os.system(\\'mkdir \\'  + output_path_dict[key] )\\n    \\nif (dophotometry == True):\\n    for key in photometry_file_dict.keys():\\n        os.system(\\'rm -rf \\' + photometry_file_dict[key] )\\n        photo_file = open(photometry_file_dict[key],\"a+\")\\n        photo_file.write(\"# Data  target_name  JD  Counts\")\\n\\nnum_markers = 0\\ntry:\\n    marker_label = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=0, dtype=np.str)\\n    rah, ram, ras = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=(1,2,3) )\\n    decd, decm, decs = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=(4,5,6) )\\n    markerR, markerG, markerB = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=(7,8,9) )\\n    marker_alpha = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=10)\\n    marker_size  = np.loadtxt(markerfile, comments=\\'#\\', skiprows=0, usecols=11)\\n    \\n    ra  = ( rah + ram / 60.0 + ras / 3600.0 ) * 15.0\\n    if (decd > 0 ):\\n        dec = decd + decm / 60.0 + decs / 3600.0\\n    else:\\n        dec = decd - decm / 60.0 - decs / 3600.0\\n    num_markers = np.size(ra)\\n    \\nexcept:\\n    print(\\'No markers found\\')\\n    \\nimages     = os.listdir( data_path )\\nnum_images = len(images)\\n############################################################################\\n    \\n\\nfor i in range(0, num_images):\\n    image_name = images[i]\\n    \\n    info = image_name.strip(\\'.fits\\').split(\\'_\\')\\n    target_name    = info[0]\\n    directory_name = info[1]\\n    band           = info[2]\\n    epoch_idx      = info[3]\\n    \\n    # open FITS image\\n    hdulist = fits.open(data_path + \\'/\\' + image_name)\\n    try:\\n        crval1 = hdulist[0].header[\\'crval1\\']\\n        crval2 = hdulist[0].header[\\'crval2\\']\\n        date   = hdulist[0].header[\\'date-obs\\']\\n        jd     = hdulist[0].header[\\'jd\\']\\n    except:\\n        print(\\'Error, coordinate header of \\' + image_name + \\' does not exist.\\')\\n        f.write( image_name + \\'\\n\\' )\\n        continue\\n\\n    # loading image\\n    if (dophotometry == True):\\n        try:\\n            image = hdulist[0].data\\n            w = wcs.WCS(hdulist[0].header)\\n        except:\\n            print(\"Error loading image \" + directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n        \\n    \\n    fig = aplpy.FITSFigure(data_path + \\'/\\' + image_name)\\n    #fig.set_xaxis_coord_type(\\'longitude\\')\\n    #fig.set_yaxis_coord_type(\\'latitude\\')\\n    fig.axis_labels.hide()\\n    fig.show_grayscale(invert=False)\\n    \\n    # mark stars\\n    for j in range(0, num_markers):\\n        # plot markers in the png figure\\n        if (num_markers==1):\\n            x, y = ra, dec\\n            pixcrd2 = w.wcs_world2pix([ [x,y] ], 0)\\n            xpix = pixcrd2[0][0]\\n            ypix = pixcrd2[0][1]\\n            mcolor = (markerR, markerG, markerB)\\n            malpha = marker_alpha\\n            msize  = marker_size\\n            mlabel = str(marker_label)\\n        else:\\n            x, y = ra[j], dec[j]\\n            mcolor = (markerR[j], markerG[j], markerB[j])\\n            malpha = marker_alpha[j]\\n            msize = marker_size[j]\\n            mlabel = str(marker_label[j])\\n        \\n        fig.show_markers(\\n                         x, y, \\n                         edgecolor=mcolor, \\n                         # facecolor=facecolor[plot_id],\\n                         marker=\\'o\\', s=msize, \\n                         alpha=malpha\\n                        )\\n        fig.add_label(x, y, \\'  \\' + mlabel, \\n                      color=mcolor, fontsize=12, horizontalalignment=\\'left\\')\\n        \\n        # optionally, do aperture photometry\\n        if (dophotometry == True):              \\n            # making photometry\\n            xpix_min = int(round(xpix - aperature_r_pix*3) )\\n            xpix_max = int(round(xpix + aperature_r_pix*3) )\\n            ypix_min = int(round(ypix - aperature_r_pix*3) )\\n            ypix_max = int(round(ypix + aperature_r_pix*3) )\\n            try:\\n                print(directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n                crop = image[ypix_min:ypix_max, xpix_min:xpix_max].astype(float)\\n                \\n                # background subtraction\\n                crop -= np.median(crop)\\n                \\n                # estimate pixel statistics\\n                bkg_sigma = mad_std(crop)\\n                \\n                # find stars\\n                daofind = DAOStarFinder(fwhm= aperature_r_pix/2.0, threshold=5.*bkg_sigma)\\n                sources = daofind(crop)\\n\\n                \\n                mxcentroid_array = np.array( sources[\\'xcentroid\\'] )\\n                mycentroid_array = np.array( sources[\\'ycentroid\\'] )\\n                mpeak_array      = np.array( sources[\\'peak\\']      )\\n                \\n                if ( len(mpeak_array) > 0 ):\\n                    # Very ugly code here due to unfamiliar with python.\\n                    # need to update. Baobab, 2019.Dec.25\\n                    index_array = range(0, len(mpeak_array) )\\n                    xindex = np.max(np.where( mpeak_array == np.max(mpeak_array), index_array, -1))\\n                    yindex = np.max(np.where( mpeak_array == np.max(mpeak_array), index_array, -1))\\n                    mxcentroid = mxcentroid_array[xindex]\\n                    mycentroid = mycentroid_array[yindex]\\n                    positions = np.transpose((mxcentroid, mycentroid))\\n                    apertures = CircularAperture(positions, aperature_r_pix)\\n                    phot_table = aperture_photometry(crop, apertures)\\n                    counts    = phot_table[\\'aperture_sum\\'][0]\\n\\n                    try:\\n                        photo_file = open(photometry_file_dict[band],\"a+\")\\n                        outtext     = directory_name + \\'_\\' + band + \\'_\\' + epoch_idx + \\'  \\' +                                       str(marker_label) + \\'   \\' +                                       str(jd).strip() + \\'   \\' +                                       str(counts) + \\'   \\n\\'\\n                        photo_file.write(outtext)\\n                        photo_file.close()\\n                    except:\\n                        print(\\'Error opening output file. \\' + directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n                    \\n                else:\\n                    print(\"No source found in\" + directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n                    \\n                \\n            except:\\n                print(\"Error making photometry \" + directory_name + \\'_\\' + band + \\'_\\' + epoch_idx)\\n                \\n            \\n        \\n    # label date\\n    date_label = \\'Date : \\' + date + \\'  JD : \\' + str(jd).strip() + \\'   Band : \\' + band  \\n    fig.add_label(0.02, 0.95, date_label, relative=True, \\n                  color=(0,1,1,1),\\n                  fontsize=9, horizontalalignment=\\'left\\')\\n\\n\\n    \\n    outfig_name = directory_name + \\'_\\' + band + \\'_\\' + epoch_idx + \\'.png\\'\\n    \\n    fig.save(outfig_name)    \\n    os.system(\\'mv \\' + outfig_name + \\' \\' + output_path_dict[band] )\\n    \\n    # close FITS image\\n    hdulist.close()\\n    \\nf.close()\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Directory for input image\n",
    "data_path   = r\"../3488473-dm tau\"\n",
    "\n",
    "# Defining output directories\n",
    "output_path_dict = {}\n",
    "output_path_dict['R'] = './R_maps'\n",
    "output_path_dict['V'] = './V_maps'\n",
    "output_path_dict['I'] = './I_maps'\n",
    "\n",
    "# set if we want to do photometry for objects in the markers list\n",
    "dophotometry     = True\n",
    "aperature_r_pix  = 10.0 # pixels\n",
    "if (dophotometry == True):\n",
    "    print(\"Will output photometry. Please define the output filename if not yet.\")\n",
    "    photometry_file_dict = {}\n",
    "    photometry_file_dict['R'] = './R_phot.txt'\n",
    "    photometry_file_dict['V'] = './V_phot.txt'\n",
    "    photometry_file_dict['I'] = './I_phot.txt'\n",
    "    \n",
    "\n",
    "# Output ASCII list for FITS images which do not possess coordinate headers\n",
    "f = open(\"NO_COORD_HEADER_list.txt\",\"w\")    \n",
    "    \n",
    "markerfile = './markers.txt'\n",
    "    \n",
    "# Preparation ##############################################################\n",
    "for key in output_path_dict.keys():\n",
    "    os.system('rm -rf ' + output_path_dict[key] )\n",
    "    os.system('mkdir '  + output_path_dict[key] )\n",
    "    \n",
    "if (dophotometry == True):\n",
    "    for key in photometry_file_dict.keys():\n",
    "        os.system('rm -rf ' + photometry_file_dict[key] )\n",
    "        photo_file = open(photometry_file_dict[key],\"a+\")\n",
    "        photo_file.write(\"# Data  target_name  JD  Counts\")\n",
    "\n",
    "num_markers = 0\n",
    "try:\n",
    "    marker_label = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=0, dtype=np.str)\n",
    "    rah, ram, ras = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=(1,2,3) )\n",
    "    decd, decm, decs = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=(4,5,6) )\n",
    "    markerR, markerG, markerB = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=(7,8,9) )\n",
    "    marker_alpha = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=10)\n",
    "    marker_size  = np.loadtxt(markerfile, comments='#', skiprows=0, usecols=11)\n",
    "    \n",
    "    ra  = ( rah + ram / 60.0 + ras / 3600.0 ) * 15.0\n",
    "    if (decd > 0 ):\n",
    "        dec = decd + decm / 60.0 + decs / 3600.0\n",
    "    else:\n",
    "        dec = decd - decm / 60.0 - decs / 3600.0\n",
    "    num_markers = np.size(ra)\n",
    "    \n",
    "except:\n",
    "    print('No markers found')\n",
    "    \n",
    "images     = os.listdir( data_path )\n",
    "num_images = len(images)\n",
    "############################################################################\n",
    "    \n",
    "\n",
    "for i in range(0, num_images):\n",
    "    image_name = images[i]\n",
    "    \n",
    "    info = image_name.strip('.fits').split('_')\n",
    "    target_name    = info[0]\n",
    "    directory_name = info[1]\n",
    "    band           = info[2]\n",
    "    epoch_idx      = info[3]\n",
    "    \n",
    "    # open FITS image\n",
    "    hdulist = fits.open(data_path + '/' + image_name)\n",
    "    try:\n",
    "        crval1 = hdulist[0].header['crval1']\n",
    "        crval2 = hdulist[0].header['crval2']\n",
    "        date   = hdulist[0].header['date-obs']\n",
    "        jd     = hdulist[0].header['jd']\n",
    "    except:\n",
    "        print('Error, coordinate header of ' + image_name + ' does not exist.')\n",
    "        f.write( image_name + '\\n' )\n",
    "        continue\n",
    "\n",
    "    # loading image\n",
    "    if (dophotometry == True):\n",
    "        try:\n",
    "            image = hdulist[0].data\n",
    "            w = wcs.WCS(hdulist[0].header)\n",
    "        except:\n",
    "            print(\"Error loading image \" + directory_name + '_' + band + '_' + epoch_idx)\n",
    "        \n",
    "    \n",
    "    fig = aplpy.FITSFigure(data_path + '/' + image_name)\n",
    "    #fig.set_xaxis_coord_type('longitude')\n",
    "    #fig.set_yaxis_coord_type('latitude')\n",
    "    fig.axis_labels.hide()\n",
    "    fig.show_grayscale(invert=False)\n",
    "    \n",
    "    # mark stars\n",
    "    for j in range(0, num_markers):\n",
    "        # plot markers in the png figure\n",
    "        if (num_markers==1):\n",
    "            x, y = ra, dec\n",
    "            pixcrd2 = w.wcs_world2pix([ [x,y] ], 0)\n",
    "            xpix = pixcrd2[0][0]\n",
    "            ypix = pixcrd2[0][1]\n",
    "            mcolor = (markerR, markerG, markerB)\n",
    "            malpha = marker_alpha\n",
    "            msize  = marker_size\n",
    "            mlabel = str(marker_label)\n",
    "        else:\n",
    "            x, y = ra[j], dec[j]\n",
    "            mcolor = (markerR[j], markerG[j], markerB[j])\n",
    "            malpha = marker_alpha[j]\n",
    "            msize = marker_size[j]\n",
    "            mlabel = str(marker_label[j])\n",
    "        \n",
    "        fig.show_markers(\n",
    "                         x, y, \n",
    "                         edgecolor=mcolor, \n",
    "                         # facecolor=facecolor[plot_id],\n",
    "                         marker='o', s=msize, \n",
    "                         alpha=malpha\n",
    "                        )\n",
    "        fig.add_label(x, y, '  ' + mlabel, \n",
    "                      color=mcolor, fontsize=12, horizontalalignment='left')\n",
    "        \n",
    "        # optionally, do aperture photometry\n",
    "        if (dophotometry == True):              \n",
    "            # making photometry\n",
    "            xpix_min = int(round(xpix - aperature_r_pix*3) )\n",
    "            xpix_max = int(round(xpix + aperature_r_pix*3) )\n",
    "            ypix_min = int(round(ypix - aperature_r_pix*3) )\n",
    "            ypix_max = int(round(ypix + aperature_r_pix*3) )\n",
    "            try:\n",
    "                print(directory_name + '_' + band + '_' + epoch_idx)\n",
    "                crop = image[ypix_min:ypix_max, xpix_min:xpix_max].astype(float)\n",
    "                \n",
    "                # background subtraction\n",
    "                crop -= np.median(crop)\n",
    "                \n",
    "                # estimate pixel statistics\n",
    "                bkg_sigma = mad_std(crop)\n",
    "                \n",
    "                # find stars\n",
    "                daofind = DAOStarFinder(fwhm= aperature_r_pix/2.0, threshold=5.*bkg_sigma)\n",
    "                sources = daofind(crop)\n",
    "\n",
    "                \n",
    "                mxcentroid_array = np.array( sources['xcentroid'] )\n",
    "                mycentroid_array = np.array( sources['ycentroid'] )\n",
    "                mpeak_array      = np.array( sources['peak']      )\n",
    "                \n",
    "                if ( len(mpeak_array) > 0 ):\n",
    "                    # Very ugly code here due to unfamiliar with python.\n",
    "                    # need to update. Baobab, 2019.Dec.25\n",
    "                    index_array = range(0, len(mpeak_array) )\n",
    "                    xindex = np.max(np.where( mpeak_array == np.max(mpeak_array), index_array, -1))\n",
    "                    yindex = np.max(np.where( mpeak_array == np.max(mpeak_array), index_array, -1))\n",
    "                    mxcentroid = mxcentroid_array[xindex]\n",
    "                    mycentroid = mycentroid_array[yindex]\n",
    "                    positions = np.transpose((mxcentroid, mycentroid))\n",
    "                    apertures = CircularAperture(positions, aperature_r_pix)\n",
    "                    phot_table = aperture_photometry(crop, apertures)\n",
    "                    counts    = phot_table['aperture_sum'][0]\n",
    "\n",
    "                    try:\n",
    "                        photo_file = open(photometry_file_dict[band],\"a+\")\n",
    "                        outtext     = directory_name + '_' + band + '_' + epoch_idx + '  ' + \\\n",
    "                                      str(marker_label) + '   ' + \\\n",
    "                                      str(jd).strip() + '   ' + \\\n",
    "                                      str(counts) + '   \\n'\n",
    "                        photo_file.write(outtext)\n",
    "                        photo_file.close()\n",
    "                    except:\n",
    "                        print('Error opening output file. ' + directory_name + '_' + band + '_' + epoch_idx)\n",
    "                    \n",
    "                else:\n",
    "                    print(\"No source found in\" + directory_name + '_' + band + '_' + epoch_idx)\n",
    "                    \n",
    "                \n",
    "            except:\n",
    "                print(\"Error making photometry \" + directory_name + '_' + band + '_' + epoch_idx)\n",
    "                \n",
    "            \n",
    "        \n",
    "    # label date\n",
    "    date_label = 'Date : ' + date + '  JD : ' + str(jd).strip() + '   Band : ' + band  \n",
    "    fig.add_label(0.02, 0.95, date_label, relative=True, \n",
    "                  color=(0,1,1,1),\n",
    "                  fontsize=9, horizontalalignment='left')\n",
    "\n",
    "\n",
    "    \n",
    "    outfig_name = directory_name + '_' + band + '_' + epoch_idx + '.png'\n",
    "    \n",
    "    fig.save(outfig_name)    \n",
    "    os.system('mv ' + outfig_name + ' ' + output_path_dict[band] )\n",
    "    \n",
    "    # close FITS image\n",
    "    hdulist.close()\n",
    "    \n",
    "f.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.65625\n"
     ]
    }
   ],
   "source": [
    "print(2.5**5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
